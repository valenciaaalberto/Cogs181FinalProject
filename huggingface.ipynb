{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = load_dataset('Maysee/tiny-imagenet', split='train')\n",
    "testset = load_dataset('Maysee/tiny-imagenet', split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.set_format(type=\"torch\", columns=[\"image\", \"label\"])\n",
    "testset.set_format(type=\"torch\", columns=[\"image\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_odd_shape = []\n",
    "for i in range(len(trainset)):\n",
    "    shape = trainset[i]['image'].shape\n",
    "    if shape == torch.Size([64, 64]):\n",
    "        idx_odd_shape.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[101, 142, 208],\n",
      "          [101, 142, 208],\n",
      "          [101, 142, 208],\n",
      "          ...,\n",
      "          [154, 187, 238],\n",
      "          [154, 188, 236],\n",
      "          [155, 189, 237]],\n",
      "\n",
      "         [[102, 143, 209],\n",
      "          [102, 143, 209],\n",
      "          [102, 143, 209],\n",
      "          ...,\n",
      "          [155, 188, 239],\n",
      "          [156, 190, 238],\n",
      "          [157, 191, 239]],\n",
      "\n",
      "         [[103, 144, 210],\n",
      "          [103, 144, 210],\n",
      "          [103, 144, 210],\n",
      "          ...,\n",
      "          [157, 191, 239],\n",
      "          [158, 192, 240],\n",
      "          [159, 193, 241]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 82,  80,  81],\n",
      "          [ 81,  80,  78],\n",
      "          [ 81,  79,  80],\n",
      "          ...,\n",
      "          [101, 102,  96],\n",
      "          [ 97,  98,  92],\n",
      "          [ 92,  95,  88]],\n",
      "\n",
      "         [[ 79,  79,  77],\n",
      "          [ 79,  80,  75],\n",
      "          [ 81,  81,  79],\n",
      "          ...,\n",
      "          [101, 100,  95],\n",
      "          [106, 105, 100],\n",
      "          [108, 109, 101]],\n",
      "\n",
      "         [[ 86,  87,  82],\n",
      "          [ 87,  88,  83],\n",
      "          [ 89,  90,  85],\n",
      "          ...,\n",
      "          [100,  99,  94],\n",
      "          [ 92,  92,  84],\n",
      "          [ 88,  88,  80]]],\n",
      "\n",
      "\n",
      "        [[[254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          ...,\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218]],\n",
      "\n",
      "         [[254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          ...,\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218]],\n",
      "\n",
      "         [[254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          ...,\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218],\n",
      "          [254, 254, 218]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 80,  69,  39],\n",
      "          [126, 117,  86],\n",
      "          [246, 235, 207],\n",
      "          ...,\n",
      "          [225, 208, 182],\n",
      "          [157, 140, 112],\n",
      "          [187, 170, 142]],\n",
      "\n",
      "         [[178, 148, 120],\n",
      "          [238, 211, 182],\n",
      "          [232, 202, 176],\n",
      "          ...,\n",
      "          [225, 201, 167],\n",
      "          [161, 138, 104],\n",
      "          [145, 122,  88]],\n",
      "\n",
      "         [[148, 111,  84],\n",
      "          [143, 106,  79],\n",
      "          [153, 116,  90],\n",
      "          ...,\n",
      "          [128, 100,  63],\n",
      "          [139, 113,  76],\n",
      "          [131, 105,  68]]],\n",
      "\n",
      "\n",
      "        [[[195, 208, 240],\n",
      "          [190, 203, 235],\n",
      "          [189, 202, 234],\n",
      "          ...,\n",
      "          [204, 216, 242],\n",
      "          [191, 203, 229],\n",
      "          [206, 218, 244]],\n",
      "\n",
      "         [[204, 217, 249],\n",
      "          [198, 211, 243],\n",
      "          [194, 207, 239],\n",
      "          ...,\n",
      "          [200, 212, 238],\n",
      "          [208, 220, 246],\n",
      "          [211, 223, 249]],\n",
      "\n",
      "         [[196, 209, 241],\n",
      "          [191, 204, 236],\n",
      "          [190, 203, 235],\n",
      "          ...,\n",
      "          [220, 231, 255],\n",
      "          [240, 251, 255],\n",
      "          [193, 204, 232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[179, 190, 220],\n",
      "          [197, 208, 238],\n",
      "          [195, 206, 236],\n",
      "          ...,\n",
      "          [182, 195, 229],\n",
      "          [182, 195, 229],\n",
      "          [181, 194, 228]],\n",
      "\n",
      "         [[188, 199, 229],\n",
      "          [178, 189, 219],\n",
      "          [170, 181, 211],\n",
      "          ...,\n",
      "          [182, 195, 229],\n",
      "          [181, 194, 228],\n",
      "          [181, 194, 228]],\n",
      "\n",
      "         [[186, 197, 227],\n",
      "          [182, 193, 223],\n",
      "          [185, 196, 226],\n",
      "          ...,\n",
      "          [181, 194, 228],\n",
      "          [181, 194, 228],\n",
      "          [181, 194, 228]]],\n",
      "\n",
      "\n",
      "        [[[ 73,  66,  73],\n",
      "          [ 84,  77,  84],\n",
      "          [ 74,  67,  74],\n",
      "          ...,\n",
      "          [ 58,  49,  42],\n",
      "          [ 31,  22,  17],\n",
      "          [  7,   0,   0]],\n",
      "\n",
      "         [[ 25,  19,  23],\n",
      "          [ 33,  27,  31],\n",
      "          [ 39,  33,  37],\n",
      "          ...,\n",
      "          [ 74,  65,  58],\n",
      "          [  7,   0,   0],\n",
      "          [ 22,  13,   8]],\n",
      "\n",
      "         [[ 51,  43,  41],\n",
      "          [ 36,  28,  26],\n",
      "          [ 30,  22,  20],\n",
      "          ...,\n",
      "          [133, 124, 117],\n",
      "          [  9,   0,   0],\n",
      "          [  7,   0,   0]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[180, 178, 183],\n",
      "          [ 73,  71,  74],\n",
      "          [ 59,  57,  62],\n",
      "          ...,\n",
      "          [102,  99, 106],\n",
      "          [ 90,  87,  94],\n",
      "          [ 80,  78,  83]],\n",
      "\n",
      "         [[208, 207, 213],\n",
      "          [162, 161, 166],\n",
      "          [ 77,  76,  82],\n",
      "          ...,\n",
      "          [ 96,  95, 103],\n",
      "          [ 93,  92, 100],\n",
      "          [ 83,  82,  88]],\n",
      "\n",
      "         [[188, 189, 194],\n",
      "          [196, 197, 202],\n",
      "          [ 69,  68,  74],\n",
      "          ...,\n",
      "          [ 75,  74,  82],\n",
      "          [ 95,  94, 102],\n",
      "          [ 73,  72,  80]]]], dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [64, 64, 3] at entry 0 and [64, 64] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      2\u001b[0m     image \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:129\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:129\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [64, 64, 3] at entry 0 and [64, 64] at entry 2"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    image = data['image']\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=3,out_channels=1024,kernel_size=3 , stride=1, padding=1)\n",
    "        self.conv_layer_two = nn.Conv2d(in_channels=1024,out_channels=720,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_three = nn.Conv2d(in_channels=720,out_channels=440,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_four = nn.Conv2d(in_channels=440,out_channels=200,kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(3200,2480)\n",
    "        self.fc2 = nn.Linear(2480,1680)\n",
    "        self.fc3 = nn.Linear(1680,980)\n",
    "        self.fc4 = nn.Linear(980,640)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_three(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_four(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 25       # Total epochs.\n",
    "print_freq = 10000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(\"predicted\")\n",
    "        print(predicted)\n",
    "        print(\"labels\")\n",
    "        print(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
