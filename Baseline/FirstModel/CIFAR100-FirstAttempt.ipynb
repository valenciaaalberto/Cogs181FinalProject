{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4952843",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a702576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', \n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', \n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', \n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', \n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', \n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4fa4a",
   "metadata": {},
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6776c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36acbe",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c4c8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_layer_one): Conv2d(3, 1100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_two): Conv2d(1100, 740, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_three): Conv2d(740, 380, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_four): Conv2d(380, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=260, bias=True)\n",
       "  (fc2): Linear(in_features=260, out_features=1280, bias=True)\n",
       "  (fc3): Linear(in_features=1280, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=3,out_channels=1100,kernel_size=3 , stride=1, padding=1)\n",
    "        self.conv_layer_two = nn.Conv2d(in_channels=1100,out_channels=740,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_three = nn.Conv2d(in_channels=740,out_channels=380,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_four = nn.Conv2d(in_channels=380,out_channels=100,kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(400, 260)\n",
    "        self.fc2 = nn.Linear(260, 1280)\n",
    "        self.fc3 = nn.Linear(1280, 100)\n",
    "  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        \n",
    "        x = self.conv_layer_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        \n",
    "        x = self.conv_layer_three(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        \n",
    "        x = self.conv_layer_four(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f802792",
   "metadata": {},
   "source": [
    "## Select Loss Function And Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d8556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800c6aa8",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d17361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 4.605\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 4.602\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 4.556\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 4.368\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 4.220\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 4.144\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 4.094\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 4.011\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 3.961\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 3.908\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 3.793\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 3.781\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 3.745\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 3.730\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 3.735\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 3.629\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 3.631\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 3.580\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 3.573\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 3.526\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 3.481\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 3.455\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 3.340\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 3.354\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 3.303\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 3.304\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 3.295\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 3.237\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 3.221\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 3.193\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 3.198\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 3.160\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 3.149\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 3.126\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 3.034\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 2.973\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 2.986\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 2.962\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 2.958\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 2.965\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 2.936\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 2.866\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 2.926\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 2.894\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 2.884\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 2.883\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 2.722\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 2.693\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 2.727\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 2.736\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 2.698\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 2.689\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 2.691\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 2.648\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 2.631\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 2.668\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 2.648\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 2.630\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 2.482\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 2.478\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 2.436\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 2.457\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 2.431\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 2.460\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 2.482\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 2.461\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 2.464\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 2.440\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 2.403\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 2.442\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 2.214\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 2.236\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 2.268\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 2.238\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 2.205\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 2.285\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 2.266\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 2.232\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 2.270\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 2.229\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 2.192\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 2.246\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 2.015\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 2.053\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 2.014\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 2.044\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 2.053\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 2.020\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 2.079\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 2.095\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 2.076\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 2.073\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 2.032\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 2.045\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 1.768\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 1.837\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 1.799\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 1.909\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 1.895\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 1.895\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 1.854\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 1.890\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 1.891\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 1.864\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 1.914\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 1.903\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 1.624\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 1.675\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 1.646\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 1.687\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 1.719\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 1.677\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 1.720\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 1.739\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 1.747\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 1.744\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 1.723\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 1.765\n",
      "[epoch: 10, i:   999] avg mini-batch loss: 1.469\n",
      "[epoch: 10, i:  1999] avg mini-batch loss: 1.530\n",
      "[epoch: 10, i:  2999] avg mini-batch loss: 1.479\n",
      "[epoch: 10, i:  3999] avg mini-batch loss: 1.484\n",
      "[epoch: 10, i:  4999] avg mini-batch loss: 1.545\n",
      "[epoch: 10, i:  5999] avg mini-batch loss: 1.568\n",
      "[epoch: 10, i:  6999] avg mini-batch loss: 1.607\n",
      "[epoch: 10, i:  7999] avg mini-batch loss: 1.511\n",
      "[epoch: 10, i:  8999] avg mini-batch loss: 1.591\n",
      "[epoch: 10, i:  9999] avg mini-batch loss: 1.594\n",
      "[epoch: 10, i: 10999] avg mini-batch loss: 1.607\n",
      "[epoch: 10, i: 11999] avg mini-batch loss: 1.586\n",
      "[epoch: 11, i:   999] avg mini-batch loss: 1.272\n",
      "[epoch: 11, i:  1999] avg mini-batch loss: 1.285\n",
      "[epoch: 11, i:  2999] avg mini-batch loss: 1.330\n",
      "[epoch: 11, i:  3999] avg mini-batch loss: 1.377\n",
      "[epoch: 11, i:  4999] avg mini-batch loss: 1.323\n",
      "[epoch: 11, i:  5999] avg mini-batch loss: 1.421\n",
      "[epoch: 11, i:  6999] avg mini-batch loss: 1.423\n",
      "[epoch: 11, i:  7999] avg mini-batch loss: 1.439\n",
      "[epoch: 11, i:  8999] avg mini-batch loss: 1.462\n",
      "[epoch: 11, i:  9999] avg mini-batch loss: 1.452\n",
      "[epoch: 11, i: 10999] avg mini-batch loss: 1.458\n",
      "[epoch: 11, i: 11999] avg mini-batch loss: 1.450\n",
      "[epoch: 12, i:   999] avg mini-batch loss: 1.142\n",
      "[epoch: 12, i:  1999] avg mini-batch loss: 1.157\n",
      "[epoch: 12, i:  2999] avg mini-batch loss: 1.220\n",
      "[epoch: 12, i:  3999] avg mini-batch loss: 1.218\n",
      "[epoch: 12, i:  4999] avg mini-batch loss: 1.249\n",
      "[epoch: 12, i:  5999] avg mini-batch loss: 1.231\n",
      "[epoch: 12, i:  6999] avg mini-batch loss: 1.250\n",
      "[epoch: 12, i:  7999] avg mini-batch loss: 1.246\n",
      "[epoch: 12, i:  8999] avg mini-batch loss: 1.333\n",
      "[epoch: 12, i:  9999] avg mini-batch loss: 1.304\n",
      "[epoch: 12, i: 10999] avg mini-batch loss: 1.329\n",
      "[epoch: 12, i: 11999] avg mini-batch loss: 1.314\n",
      "[epoch: 13, i:   999] avg mini-batch loss: 0.952\n",
      "[epoch: 13, i:  1999] avg mini-batch loss: 1.006\n",
      "[epoch: 13, i:  2999] avg mini-batch loss: 1.073\n",
      "[epoch: 13, i:  3999] avg mini-batch loss: 1.099\n",
      "[epoch: 13, i:  4999] avg mini-batch loss: 1.111\n",
      "[epoch: 13, i:  5999] avg mini-batch loss: 1.138\n",
      "[epoch: 13, i:  6999] avg mini-batch loss: 1.154\n",
      "[epoch: 13, i:  7999] avg mini-batch loss: 1.149\n",
      "[epoch: 13, i:  8999] avg mini-batch loss: 1.179\n",
      "[epoch: 13, i:  9999] avg mini-batch loss: 1.174\n",
      "[epoch: 13, i: 10999] avg mini-batch loss: 1.188\n",
      "[epoch: 13, i: 11999] avg mini-batch loss: 1.204\n",
      "[epoch: 14, i:   999] avg mini-batch loss: 0.819\n",
      "[epoch: 14, i:  1999] avg mini-batch loss: 0.878\n",
      "[epoch: 14, i:  2999] avg mini-batch loss: 0.914\n",
      "[epoch: 14, i:  3999] avg mini-batch loss: 0.949\n",
      "[epoch: 14, i:  4999] avg mini-batch loss: 0.966\n",
      "[epoch: 14, i:  5999] avg mini-batch loss: 0.996\n",
      "[epoch: 14, i:  6999] avg mini-batch loss: 1.013\n",
      "[epoch: 14, i:  7999] avg mini-batch loss: 1.032\n",
      "[epoch: 14, i:  8999] avg mini-batch loss: 1.037\n",
      "[epoch: 14, i:  9999] avg mini-batch loss: 1.051\n",
      "[epoch: 14, i: 10999] avg mini-batch loss: 1.090\n",
      "[epoch: 14, i: 11999] avg mini-batch loss: 1.060\n",
      "[epoch: 15, i:   999] avg mini-batch loss: 0.718\n",
      "[epoch: 15, i:  1999] avg mini-batch loss: 0.761\n",
      "[epoch: 15, i:  2999] avg mini-batch loss: 0.789\n",
      "[epoch: 15, i:  3999] avg mini-batch loss: 0.826\n",
      "[epoch: 15, i:  4999] avg mini-batch loss: 0.837\n",
      "[epoch: 15, i:  5999] avg mini-batch loss: 0.867\n",
      "[epoch: 15, i:  6999] avg mini-batch loss: 0.865\n",
      "[epoch: 15, i:  7999] avg mini-batch loss: 0.955\n",
      "[epoch: 15, i:  8999] avg mini-batch loss: 0.932\n",
      "[epoch: 15, i:  9999] avg mini-batch loss: 0.937\n",
      "[epoch: 15, i: 10999] avg mini-batch loss: 0.960\n",
      "[epoch: 15, i: 11999] avg mini-batch loss: 0.944\n",
      "[epoch: 16, i:   999] avg mini-batch loss: 0.588\n",
      "[epoch: 16, i:  1999] avg mini-batch loss: 0.697\n",
      "[epoch: 16, i:  2999] avg mini-batch loss: 0.693\n",
      "[epoch: 16, i:  3999] avg mini-batch loss: 0.731\n",
      "[epoch: 16, i:  4999] avg mini-batch loss: 0.744\n",
      "[epoch: 16, i:  5999] avg mini-batch loss: 0.767\n",
      "[epoch: 16, i:  6999] avg mini-batch loss: 0.796\n",
      "[epoch: 16, i:  7999] avg mini-batch loss: 0.788\n",
      "[epoch: 16, i:  8999] avg mini-batch loss: 0.817\n",
      "[epoch: 16, i:  9999] avg mini-batch loss: 0.807\n",
      "[epoch: 16, i: 10999] avg mini-batch loss: 0.877\n",
      "[epoch: 16, i: 11999] avg mini-batch loss: 0.911\n",
      "[epoch: 17, i:   999] avg mini-batch loss: 0.524\n",
      "[epoch: 17, i:  1999] avg mini-batch loss: 0.572\n",
      "[epoch: 17, i:  2999] avg mini-batch loss: 0.625\n",
      "[epoch: 17, i:  3999] avg mini-batch loss: 0.636\n",
      "[epoch: 17, i:  4999] avg mini-batch loss: 0.641\n",
      "[epoch: 17, i:  5999] avg mini-batch loss: 0.681\n",
      "[epoch: 17, i:  6999] avg mini-batch loss: 0.723\n",
      "[epoch: 17, i:  7999] avg mini-batch loss: 0.728\n",
      "[epoch: 17, i:  8999] avg mini-batch loss: 0.697\n",
      "[epoch: 17, i:  9999] avg mini-batch loss: 0.689\n",
      "[epoch: 17, i: 10999] avg mini-batch loss: 0.742\n",
      "[epoch: 17, i: 11999] avg mini-batch loss: 0.761\n",
      "[epoch: 18, i:   999] avg mini-batch loss: 0.444\n",
      "[epoch: 18, i:  1999] avg mini-batch loss: 0.470\n",
      "[epoch: 18, i:  2999] avg mini-batch loss: 0.551\n",
      "[epoch: 18, i:  3999] avg mini-batch loss: 0.536\n",
      "[epoch: 18, i:  4999] avg mini-batch loss: 0.583\n",
      "[epoch: 18, i:  5999] avg mini-batch loss: 0.611\n",
      "[epoch: 18, i:  6999] avg mini-batch loss: 0.628\n",
      "[epoch: 18, i:  7999] avg mini-batch loss: 0.630\n",
      "[epoch: 18, i:  8999] avg mini-batch loss: 0.649\n",
      "[epoch: 18, i:  9999] avg mini-batch loss: 0.632\n",
      "[epoch: 18, i: 10999] avg mini-batch loss: 0.673\n",
      "[epoch: 18, i: 11999] avg mini-batch loss: 0.694\n",
      "[epoch: 19, i:   999] avg mini-batch loss: 0.433\n",
      "[epoch: 19, i:  1999] avg mini-batch loss: 0.424\n",
      "[epoch: 19, i:  2999] avg mini-batch loss: 0.470\n",
      "[epoch: 19, i:  3999] avg mini-batch loss: 0.469\n",
      "[epoch: 19, i:  4999] avg mini-batch loss: 0.536\n",
      "[epoch: 19, i:  5999] avg mini-batch loss: 0.548\n",
      "[epoch: 19, i:  6999] avg mini-batch loss: 0.516\n",
      "[epoch: 19, i:  7999] avg mini-batch loss: 0.560\n",
      "[epoch: 19, i:  8999] avg mini-batch loss: 0.584\n",
      "[epoch: 19, i:  9999] avg mini-batch loss: 0.583\n",
      "[epoch: 19, i: 10999] avg mini-batch loss: 0.591\n",
      "[epoch: 19, i: 11999] avg mini-batch loss: 0.616\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 20       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e936ee",
   "metadata": {},
   "source": [
    "## Plotting Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef7844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09a649",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f3a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 43 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe6b2c",
   "metadata": {},
   "source": [
    "## Evaluate Test Accuracy Across Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd9b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of apple : 54 %\n",
      "Accuracy of aquarium_fish : 57 %\n",
      "Accuracy of  baby : 26 %\n",
      "Accuracy of  bear : 36 %\n",
      "Accuracy of beaver : 20 %\n",
      "Accuracy of   bed : 36 %\n",
      "Accuracy of   bee : 59 %\n",
      "Accuracy of beetle : 49 %\n",
      "Accuracy of bicycle : 49 %\n",
      "Accuracy of bottle : 61 %\n",
      "Accuracy of  bowl : 24 %\n",
      "Accuracy of   boy : 42 %\n",
      "Accuracy of bridge : 43 %\n",
      "Accuracy of   bus : 27 %\n",
      "Accuracy of butterfly : 32 %\n",
      "Accuracy of camel : 55 %\n",
      "Accuracy of   can : 42 %\n",
      "Accuracy of castle : 61 %\n",
      "Accuracy of caterpillar : 40 %\n",
      "Accuracy of cattle : 48 %\n",
      "Accuracy of chair : 65 %\n",
      "Accuracy of chimpanzee : 57 %\n",
      "Accuracy of clock : 44 %\n",
      "Accuracy of cloud : 53 %\n",
      "Accuracy of cockroach : 66 %\n",
      "Accuracy of couch : 30 %\n",
      "Accuracy of  crab : 26 %\n",
      "Accuracy of crocodile : 18 %\n",
      "Accuracy of   cup : 57 %\n",
      "Accuracy of dinosaur : 38 %\n",
      "Accuracy of dolphin : 36 %\n",
      "Accuracy of elephant : 46 %\n",
      "Accuracy of flatfish : 37 %\n",
      "Accuracy of forest : 34 %\n",
      "Accuracy of   fox : 42 %\n",
      "Accuracy of  girl : 33 %\n",
      "Accuracy of hamster : 35 %\n",
      "Accuracy of house : 64 %\n",
      "Accuracy of kangaroo : 31 %\n",
      "Accuracy of keyboard : 52 %\n",
      "Accuracy of  lamp : 37 %\n",
      "Accuracy of lawn_mower : 67 %\n",
      "Accuracy of leopard : 38 %\n",
      "Accuracy of  lion : 58 %\n",
      "Accuracy of lizard : 18 %\n",
      "Accuracy of lobster : 29 %\n",
      "Accuracy of   man : 22 %\n",
      "Accuracy of maple_tree : 52 %\n",
      "Accuracy of motorcycle : 59 %\n",
      "Accuracy of mountain : 37 %\n",
      "Accuracy of mouse : 37 %\n",
      "Accuracy of mushroom : 41 %\n",
      "Accuracy of oak_tree : 50 %\n",
      "Accuracy of orange : 68 %\n",
      "Accuracy of orchid : 61 %\n",
      "Accuracy of otter :  9 %\n",
      "Accuracy of palm_tree : 61 %\n",
      "Accuracy of  pear : 46 %\n",
      "Accuracy of pickup_truck : 62 %\n",
      "Accuracy of pine_tree : 34 %\n",
      "Accuracy of plain : 70 %\n",
      "Accuracy of plate : 45 %\n",
      "Accuracy of poppy : 50 %\n",
      "Accuracy of porcupine : 37 %\n",
      "Accuracy of possum : 16 %\n",
      "Accuracy of rabbit : 19 %\n",
      "Accuracy of raccoon : 42 %\n",
      "Accuracy of   ray : 36 %\n",
      "Accuracy of  road : 71 %\n",
      "Accuracy of rocket : 52 %\n",
      "Accuracy of  rose : 51 %\n",
      "Accuracy of   sea : 59 %\n",
      "Accuracy of  seal : 14 %\n",
      "Accuracy of shark : 30 %\n",
      "Accuracy of shrew : 29 %\n",
      "Accuracy of skunk : 69 %\n",
      "Accuracy of skyscraper : 63 %\n",
      "Accuracy of snail : 32 %\n",
      "Accuracy of snake : 29 %\n",
      "Accuracy of spider : 49 %\n",
      "Accuracy of squirrel : 34 %\n",
      "Accuracy of streetcar : 48 %\n",
      "Accuracy of sunflower : 74 %\n",
      "Accuracy of sweet_pepper : 48 %\n",
      "Accuracy of table : 32 %\n",
      "Accuracy of  tank : 50 %\n",
      "Accuracy of telephone : 56 %\n",
      "Accuracy of television : 58 %\n",
      "Accuracy of tiger : 52 %\n",
      "Accuracy of tractor : 46 %\n",
      "Accuracy of train : 56 %\n",
      "Accuracy of trout : 49 %\n",
      "Accuracy of tulip : 28 %\n",
      "Accuracy of turtle : 17 %\n",
      "Accuracy of wardrobe : 73 %\n",
      "Accuracy of whale : 43 %\n",
      "Accuracy of willow_tree : 37 %\n",
      "Accuracy of  wolf : 48 %\n",
      "Accuracy of woman : 25 %\n",
      "Accuracy of  worm : 42 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(100))\n",
    "class_total = list(0. for i in range(100))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(100):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
