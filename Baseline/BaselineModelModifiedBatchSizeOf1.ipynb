{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d7a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da4c56",
   "metadata": {},
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6117c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', \n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', \n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', \n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', \n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', \n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b170b",
   "metadata": {},
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b574a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8336a6dc",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc14492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_layer_one): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_two): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_three): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_four): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_five): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_six): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchNorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3 , stride=1, padding=1)\n",
    "        self.conv_layer_two = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_three = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_four = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_five = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_six = nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "        self.batchNorm = nn.BatchNorm2d(3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 100)\n",
    "  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.conv_layer_one(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_two(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_three(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_four(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_five(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_six(x)\n",
    "        x = F.elu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904d075",
   "metadata": {},
   "source": [
    "## Select Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "247b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857ce00",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "211ff432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 4.605\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 4.609\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 4.605\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 4.612\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 4.608\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 4.611\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 4.613\n",
      "[epoch: 0, i: 12999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i: 13999] avg mini-batch loss: 4.609\n",
      "[epoch: 0, i: 14999] avg mini-batch loss: 4.614\n",
      "[epoch: 0, i: 15999] avg mini-batch loss: 4.609\n",
      "[epoch: 0, i: 16999] avg mini-batch loss: 4.608\n",
      "[epoch: 0, i: 17999] avg mini-batch loss: 4.609\n",
      "[epoch: 0, i: 18999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i: 19999] avg mini-batch loss: 4.609\n",
      "[epoch: 0, i: 20999] avg mini-batch loss: 4.607\n",
      "[epoch: 0, i: 21999] avg mini-batch loss: 4.614\n",
      "[epoch: 0, i: 22999] avg mini-batch loss: 4.605\n",
      "[epoch: 0, i: 23999] avg mini-batch loss: 4.611\n",
      "[epoch: 0, i: 24999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i: 25999] avg mini-batch loss: 4.604\n",
      "[epoch: 0, i: 26999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i: 27999] avg mini-batch loss: 4.579\n",
      "[epoch: 0, i: 28999] avg mini-batch loss: 4.551\n",
      "[epoch: 0, i: 29999] avg mini-batch loss: 4.528\n",
      "[epoch: 0, i: 30999] avg mini-batch loss: 4.494\n",
      "[epoch: 0, i: 31999] avg mini-batch loss: 4.491\n",
      "[epoch: 0, i: 32999] avg mini-batch loss: 4.467\n",
      "[epoch: 0, i: 33999] avg mini-batch loss: 4.436\n",
      "[epoch: 0, i: 34999] avg mini-batch loss: 4.397\n",
      "[epoch: 0, i: 35999] avg mini-batch loss: 4.418\n",
      "[epoch: 0, i: 36999] avg mini-batch loss: 4.405\n",
      "[epoch: 0, i: 37999] avg mini-batch loss: 4.381\n",
      "[epoch: 0, i: 38999] avg mini-batch loss: 4.369\n",
      "[epoch: 0, i: 39999] avg mini-batch loss: 4.366\n",
      "[epoch: 0, i: 40999] avg mini-batch loss: 4.341\n",
      "[epoch: 0, i: 41999] avg mini-batch loss: 4.331\n",
      "[epoch: 0, i: 42999] avg mini-batch loss: 4.294\n",
      "[epoch: 0, i: 43999] avg mini-batch loss: 4.313\n",
      "[epoch: 0, i: 44999] avg mini-batch loss: 4.247\n",
      "[epoch: 0, i: 45999] avg mini-batch loss: 4.191\n",
      "[epoch: 0, i: 46999] avg mini-batch loss: 4.187\n",
      "[epoch: 0, i: 47999] avg mini-batch loss: 4.177\n",
      "[epoch: 0, i: 48999] avg mini-batch loss: 4.225\n",
      "[epoch: 0, i: 49999] avg mini-batch loss: 4.147\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 4.120\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 4.116\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 4.062\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 4.056\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 4.040\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 4.055\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 4.076\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 4.005\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 4.011\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 3.970\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 3.992\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 3.947\n",
      "[epoch: 1, i: 12999] avg mini-batch loss: 3.957\n",
      "[epoch: 1, i: 13999] avg mini-batch loss: 3.922\n",
      "[epoch: 1, i: 14999] avg mini-batch loss: 3.872\n",
      "[epoch: 1, i: 15999] avg mini-batch loss: 3.906\n",
      "[epoch: 1, i: 16999] avg mini-batch loss: 3.871\n",
      "[epoch: 1, i: 17999] avg mini-batch loss: 3.870\n",
      "[epoch: 1, i: 18999] avg mini-batch loss: 3.837\n",
      "[epoch: 1, i: 19999] avg mini-batch loss: 3.870\n",
      "[epoch: 1, i: 20999] avg mini-batch loss: 3.835\n",
      "[epoch: 1, i: 21999] avg mini-batch loss: 3.886\n",
      "[epoch: 1, i: 22999] avg mini-batch loss: 3.808\n",
      "[epoch: 1, i: 23999] avg mini-batch loss: 3.785\n",
      "[epoch: 1, i: 24999] avg mini-batch loss: 3.817\n",
      "[epoch: 1, i: 25999] avg mini-batch loss: 3.819\n",
      "[epoch: 1, i: 26999] avg mini-batch loss: 3.761\n",
      "[epoch: 1, i: 27999] avg mini-batch loss: 3.726\n",
      "[epoch: 1, i: 28999] avg mini-batch loss: 3.713\n",
      "[epoch: 1, i: 29999] avg mini-batch loss: 3.703\n",
      "[epoch: 1, i: 30999] avg mini-batch loss: 3.715\n",
      "[epoch: 1, i: 31999] avg mini-batch loss: 3.668\n",
      "[epoch: 1, i: 32999] avg mini-batch loss: 3.698\n",
      "[epoch: 1, i: 33999] avg mini-batch loss: 3.647\n",
      "[epoch: 1, i: 34999] avg mini-batch loss: 3.691\n",
      "[epoch: 1, i: 35999] avg mini-batch loss: 3.603\n",
      "[epoch: 1, i: 36999] avg mini-batch loss: 3.610\n",
      "[epoch: 1, i: 37999] avg mini-batch loss: 3.574\n",
      "[epoch: 1, i: 38999] avg mini-batch loss: 3.603\n",
      "[epoch: 1, i: 39999] avg mini-batch loss: 3.533\n",
      "[epoch: 1, i: 40999] avg mini-batch loss: 3.659\n",
      "[epoch: 1, i: 41999] avg mini-batch loss: 3.489\n",
      "[epoch: 1, i: 42999] avg mini-batch loss: 3.575\n",
      "[epoch: 1, i: 43999] avg mini-batch loss: 3.511\n",
      "[epoch: 1, i: 44999] avg mini-batch loss: 3.603\n",
      "[epoch: 1, i: 45999] avg mini-batch loss: 3.484\n",
      "[epoch: 1, i: 46999] avg mini-batch loss: 3.558\n",
      "[epoch: 1, i: 47999] avg mini-batch loss: 3.551\n",
      "[epoch: 1, i: 48999] avg mini-batch loss: 3.527\n",
      "[epoch: 1, i: 49999] avg mini-batch loss: 3.402\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 3.387\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 3.398\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 3.382\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 3.287\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 3.378\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 3.317\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 3.350\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 3.419\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 3.339\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 3.303\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 3.292\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 3.398\n",
      "[epoch: 2, i: 12999] avg mini-batch loss: 3.244\n",
      "[epoch: 2, i: 13999] avg mini-batch loss: 3.301\n",
      "[epoch: 2, i: 14999] avg mini-batch loss: 3.240\n",
      "[epoch: 2, i: 15999] avg mini-batch loss: 3.273\n",
      "[epoch: 2, i: 16999] avg mini-batch loss: 3.298\n",
      "[epoch: 2, i: 17999] avg mini-batch loss: 3.270\n",
      "[epoch: 2, i: 18999] avg mini-batch loss: 3.220\n",
      "[epoch: 2, i: 19999] avg mini-batch loss: 3.263\n",
      "[epoch: 2, i: 20999] avg mini-batch loss: 3.211\n",
      "[epoch: 2, i: 21999] avg mini-batch loss: 3.197\n",
      "[epoch: 2, i: 22999] avg mini-batch loss: 3.203\n",
      "[epoch: 2, i: 23999] avg mini-batch loss: 3.382\n",
      "[epoch: 2, i: 24999] avg mini-batch loss: 3.143\n",
      "[epoch: 2, i: 25999] avg mini-batch loss: 3.207\n",
      "[epoch: 2, i: 26999] avg mini-batch loss: 3.183\n",
      "[epoch: 2, i: 27999] avg mini-batch loss: 3.152\n",
      "[epoch: 2, i: 28999] avg mini-batch loss: 3.169\n",
      "[epoch: 2, i: 29999] avg mini-batch loss: 3.168\n",
      "[epoch: 2, i: 30999] avg mini-batch loss: 3.140\n",
      "[epoch: 2, i: 31999] avg mini-batch loss: 3.150\n",
      "[epoch: 2, i: 32999] avg mini-batch loss: 3.184\n",
      "[epoch: 2, i: 33999] avg mini-batch loss: 3.044\n",
      "[epoch: 2, i: 34999] avg mini-batch loss: 3.124\n",
      "[epoch: 2, i: 35999] avg mini-batch loss: 2.998\n",
      "[epoch: 2, i: 36999] avg mini-batch loss: 3.167\n",
      "[epoch: 2, i: 37999] avg mini-batch loss: 3.134\n",
      "[epoch: 2, i: 38999] avg mini-batch loss: 2.998\n",
      "[epoch: 2, i: 39999] avg mini-batch loss: 3.063\n",
      "[epoch: 2, i: 40999] avg mini-batch loss: 3.061\n",
      "[epoch: 2, i: 41999] avg mini-batch loss: 3.088\n",
      "[epoch: 2, i: 42999] avg mini-batch loss: 3.071\n",
      "[epoch: 2, i: 43999] avg mini-batch loss: 3.094\n",
      "[epoch: 2, i: 44999] avg mini-batch loss: 3.037\n",
      "[epoch: 2, i: 45999] avg mini-batch loss: 2.978\n",
      "[epoch: 2, i: 46999] avg mini-batch loss: 2.985\n",
      "[epoch: 2, i: 47999] avg mini-batch loss: 3.107\n",
      "[epoch: 2, i: 48999] avg mini-batch loss: 3.041\n",
      "[epoch: 2, i: 49999] avg mini-batch loss: 3.031\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 2.920\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 2.948\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 2.896\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 2.888\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 2.969\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 2.861\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 2.942\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 2.876\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 2.915\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 2.891\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 2.836\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 2.855\n",
      "[epoch: 3, i: 12999] avg mini-batch loss: 2.952\n",
      "[epoch: 3, i: 13999] avg mini-batch loss: 2.870\n",
      "[epoch: 3, i: 14999] avg mini-batch loss: 2.942\n",
      "[epoch: 3, i: 15999] avg mini-batch loss: 2.857\n",
      "[epoch: 3, i: 16999] avg mini-batch loss: 2.910\n",
      "[epoch: 3, i: 17999] avg mini-batch loss: 2.831\n",
      "[epoch: 3, i: 18999] avg mini-batch loss: 2.893\n",
      "[epoch: 3, i: 19999] avg mini-batch loss: 2.846\n",
      "[epoch: 3, i: 20999] avg mini-batch loss: 2.812\n",
      "[epoch: 3, i: 21999] avg mini-batch loss: 2.803\n",
      "[epoch: 3, i: 22999] avg mini-batch loss: 2.818\n",
      "[epoch: 3, i: 23999] avg mini-batch loss: 2.881\n",
      "[epoch: 3, i: 24999] avg mini-batch loss: 2.928\n",
      "[epoch: 3, i: 25999] avg mini-batch loss: 2.827\n",
      "[epoch: 3, i: 26999] avg mini-batch loss: 2.857\n",
      "[epoch: 3, i: 27999] avg mini-batch loss: 2.898\n",
      "[epoch: 3, i: 28999] avg mini-batch loss: 2.718\n",
      "[epoch: 3, i: 29999] avg mini-batch loss: 2.854\n",
      "[epoch: 3, i: 30999] avg mini-batch loss: 2.932\n",
      "[epoch: 3, i: 31999] avg mini-batch loss: 2.833\n",
      "[epoch: 3, i: 32999] avg mini-batch loss: 2.806\n",
      "[epoch: 3, i: 33999] avg mini-batch loss: 2.783\n",
      "[epoch: 3, i: 34999] avg mini-batch loss: 2.791\n",
      "[epoch: 3, i: 35999] avg mini-batch loss: 2.869\n",
      "[epoch: 3, i: 36999] avg mini-batch loss: 2.807\n",
      "[epoch: 3, i: 37999] avg mini-batch loss: 2.771\n",
      "[epoch: 3, i: 38999] avg mini-batch loss: 2.633\n",
      "[epoch: 3, i: 39999] avg mini-batch loss: 2.843\n",
      "[epoch: 3, i: 40999] avg mini-batch loss: 2.823\n",
      "[epoch: 3, i: 41999] avg mini-batch loss: 2.779\n",
      "[epoch: 3, i: 42999] avg mini-batch loss: 2.828\n",
      "[epoch: 3, i: 43999] avg mini-batch loss: 2.861\n",
      "[epoch: 3, i: 44999] avg mini-batch loss: 2.717\n",
      "[epoch: 3, i: 45999] avg mini-batch loss: 2.705\n",
      "[epoch: 3, i: 46999] avg mini-batch loss: 2.865\n",
      "[epoch: 3, i: 47999] avg mini-batch loss: 2.724\n",
      "[epoch: 3, i: 48999] avg mini-batch loss: 2.763\n",
      "[epoch: 3, i: 49999] avg mini-batch loss: 2.706\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 2.534\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 2.651\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 2.575\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 2.582\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 2.575\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 2.533\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 2.557\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 2.570\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 2.590\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 2.732\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 2.541\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 2.690\n",
      "[epoch: 4, i: 12999] avg mini-batch loss: 2.704\n",
      "[epoch: 4, i: 13999] avg mini-batch loss: 2.637\n",
      "[epoch: 4, i: 14999] avg mini-batch loss: 2.621\n",
      "[epoch: 4, i: 15999] avg mini-batch loss: 2.642\n",
      "[epoch: 4, i: 16999] avg mini-batch loss: 2.626\n",
      "[epoch: 4, i: 17999] avg mini-batch loss: 2.647\n",
      "[epoch: 4, i: 18999] avg mini-batch loss: 2.619\n",
      "[epoch: 4, i: 19999] avg mini-batch loss: 2.562\n",
      "[epoch: 4, i: 20999] avg mini-batch loss: 2.574\n",
      "[epoch: 4, i: 21999] avg mini-batch loss: 2.650\n",
      "[epoch: 4, i: 22999] avg mini-batch loss: 2.529\n",
      "[epoch: 4, i: 23999] avg mini-batch loss: 2.555\n",
      "[epoch: 4, i: 24999] avg mini-batch loss: 2.584\n",
      "[epoch: 4, i: 25999] avg mini-batch loss: 2.630\n",
      "[epoch: 4, i: 26999] avg mini-batch loss: 2.583\n",
      "[epoch: 4, i: 27999] avg mini-batch loss: 2.569\n",
      "[epoch: 4, i: 28999] avg mini-batch loss: 2.660\n",
      "[epoch: 4, i: 29999] avg mini-batch loss: 2.666\n",
      "[epoch: 4, i: 30999] avg mini-batch loss: 2.671\n",
      "[epoch: 4, i: 31999] avg mini-batch loss: 2.618\n",
      "[epoch: 4, i: 32999] avg mini-batch loss: 2.579\n",
      "[epoch: 4, i: 33999] avg mini-batch loss: 2.566\n",
      "[epoch: 4, i: 34999] avg mini-batch loss: 2.607\n",
      "[epoch: 4, i: 35999] avg mini-batch loss: 2.533\n",
      "[epoch: 4, i: 36999] avg mini-batch loss: 2.625\n",
      "[epoch: 4, i: 37999] avg mini-batch loss: 2.560\n",
      "[epoch: 4, i: 38999] avg mini-batch loss: 2.687\n",
      "[epoch: 4, i: 39999] avg mini-batch loss: 2.669\n",
      "[epoch: 4, i: 40999] avg mini-batch loss: 2.615\n",
      "[epoch: 4, i: 41999] avg mini-batch loss: 2.578\n",
      "[epoch: 4, i: 42999] avg mini-batch loss: 2.698\n",
      "[epoch: 4, i: 43999] avg mini-batch loss: 2.582\n",
      "[epoch: 4, i: 44999] avg mini-batch loss: 2.629\n",
      "[epoch: 4, i: 45999] avg mini-batch loss: 2.651\n",
      "[epoch: 4, i: 46999] avg mini-batch loss: 2.580\n",
      "[epoch: 4, i: 47999] avg mini-batch loss: 2.658\n",
      "[epoch: 4, i: 48999] avg mini-batch loss: 2.561\n",
      "[epoch: 4, i: 49999] avg mini-batch loss: 2.636\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 2.282\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 2.303\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 2.300\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 2.363\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 2.397\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 2.323\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 2.393\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 2.432\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 2.462\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 2.301\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 2.546\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 2.420\n",
      "[epoch: 5, i: 12999] avg mini-batch loss: 2.375\n",
      "[epoch: 5, i: 13999] avg mini-batch loss: 2.450\n",
      "[epoch: 5, i: 14999] avg mini-batch loss: 2.540\n",
      "[epoch: 5, i: 15999] avg mini-batch loss: 2.469\n",
      "[epoch: 5, i: 16999] avg mini-batch loss: 2.439\n",
      "[epoch: 5, i: 17999] avg mini-batch loss: 2.379\n",
      "[epoch: 5, i: 18999] avg mini-batch loss: 2.497\n",
      "[epoch: 5, i: 19999] avg mini-batch loss: 2.350\n",
      "[epoch: 5, i: 20999] avg mini-batch loss: 2.441\n",
      "[epoch: 5, i: 21999] avg mini-batch loss: 2.278\n",
      "[epoch: 5, i: 22999] avg mini-batch loss: 2.449\n",
      "[epoch: 5, i: 23999] avg mini-batch loss: 2.388\n",
      "[epoch: 5, i: 24999] avg mini-batch loss: 2.481\n",
      "[epoch: 5, i: 25999] avg mini-batch loss: 2.433\n",
      "[epoch: 5, i: 26999] avg mini-batch loss: 2.490\n",
      "[epoch: 5, i: 27999] avg mini-batch loss: 2.464\n",
      "[epoch: 5, i: 28999] avg mini-batch loss: 2.486\n",
      "[epoch: 5, i: 29999] avg mini-batch loss: 2.376\n",
      "[epoch: 5, i: 30999] avg mini-batch loss: 2.491\n",
      "[epoch: 5, i: 31999] avg mini-batch loss: 2.609\n",
      "[epoch: 5, i: 32999] avg mini-batch loss: 2.473\n",
      "[epoch: 5, i: 33999] avg mini-batch loss: 2.465\n",
      "[epoch: 5, i: 34999] avg mini-batch loss: 2.468\n",
      "[epoch: 5, i: 35999] avg mini-batch loss: 2.587\n",
      "[epoch: 5, i: 36999] avg mini-batch loss: 2.453\n",
      "[epoch: 5, i: 37999] avg mini-batch loss: 2.524\n",
      "[epoch: 5, i: 38999] avg mini-batch loss: 2.432\n",
      "[epoch: 5, i: 39999] avg mini-batch loss: 2.510\n",
      "[epoch: 5, i: 40999] avg mini-batch loss: 2.571\n",
      "[epoch: 5, i: 41999] avg mini-batch loss: 2.349\n",
      "[epoch: 5, i: 42999] avg mini-batch loss: 2.436\n",
      "[epoch: 5, i: 43999] avg mini-batch loss: 2.450\n",
      "[epoch: 5, i: 44999] avg mini-batch loss: 2.518\n",
      "[epoch: 5, i: 45999] avg mini-batch loss: 2.579\n",
      "[epoch: 5, i: 46999] avg mini-batch loss: 2.380\n",
      "[epoch: 5, i: 47999] avg mini-batch loss: 2.474\n",
      "[epoch: 5, i: 48999] avg mini-batch loss: 2.451\n",
      "[epoch: 5, i: 49999] avg mini-batch loss: 2.550\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 2.124\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 2.086\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 2.218\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 2.127\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 2.191\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 2.194\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 2.387\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 2.206\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 2.247\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 2.385\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 2.353\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 2.179\n",
      "[epoch: 6, i: 12999] avg mini-batch loss: 2.321\n",
      "[epoch: 6, i: 13999] avg mini-batch loss: 2.260\n",
      "[epoch: 6, i: 14999] avg mini-batch loss: 2.244\n",
      "[epoch: 6, i: 15999] avg mini-batch loss: 2.399\n",
      "[epoch: 6, i: 16999] avg mini-batch loss: 2.283\n",
      "[epoch: 6, i: 17999] avg mini-batch loss: 2.259\n",
      "[epoch: 6, i: 18999] avg mini-batch loss: 2.356\n",
      "[epoch: 6, i: 19999] avg mini-batch loss: 2.460\n",
      "[epoch: 6, i: 20999] avg mini-batch loss: 2.365\n",
      "[epoch: 6, i: 21999] avg mini-batch loss: 2.321\n",
      "[epoch: 6, i: 22999] avg mini-batch loss: 2.380\n",
      "[epoch: 6, i: 23999] avg mini-batch loss: 2.348\n",
      "[epoch: 6, i: 24999] avg mini-batch loss: 2.282\n",
      "[epoch: 6, i: 25999] avg mini-batch loss: 2.285\n",
      "[epoch: 6, i: 26999] avg mini-batch loss: 2.423\n",
      "[epoch: 6, i: 27999] avg mini-batch loss: 2.471\n",
      "[epoch: 6, i: 28999] avg mini-batch loss: 2.404\n",
      "[epoch: 6, i: 29999] avg mini-batch loss: 2.344\n",
      "[epoch: 6, i: 30999] avg mini-batch loss: 2.372\n",
      "[epoch: 6, i: 31999] avg mini-batch loss: 2.462\n",
      "[epoch: 6, i: 32999] avg mini-batch loss: 2.407\n",
      "[epoch: 6, i: 33999] avg mini-batch loss: 2.407\n",
      "[epoch: 6, i: 34999] avg mini-batch loss: 2.379\n",
      "[epoch: 6, i: 35999] avg mini-batch loss: 2.393\n",
      "[epoch: 6, i: 36999] avg mini-batch loss: 2.373\n",
      "[epoch: 6, i: 37999] avg mini-batch loss: 2.364\n",
      "[epoch: 6, i: 38999] avg mini-batch loss: 2.490\n",
      "[epoch: 6, i: 39999] avg mini-batch loss: 2.361\n",
      "[epoch: 6, i: 40999] avg mini-batch loss: 2.594\n",
      "[epoch: 6, i: 41999] avg mini-batch loss: 2.428\n",
      "[epoch: 6, i: 42999] avg mini-batch loss: 2.340\n",
      "[epoch: 6, i: 43999] avg mini-batch loss: 2.468\n",
      "[epoch: 6, i: 44999] avg mini-batch loss: 2.336\n",
      "[epoch: 6, i: 45999] avg mini-batch loss: 2.458\n",
      "[epoch: 6, i: 46999] avg mini-batch loss: 2.498\n",
      "[epoch: 6, i: 47999] avg mini-batch loss: 2.376\n",
      "[epoch: 6, i: 48999] avg mini-batch loss: 2.422\n",
      "[epoch: 6, i: 49999] avg mini-batch loss: 2.326\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 2.030\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 2.061\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 2.023\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 2.156\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 2.089\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 2.205\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 2.191\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 2.201\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 2.217\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 2.104\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 2.211\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 2.222\n",
      "[epoch: 7, i: 12999] avg mini-batch loss: 2.206\n",
      "[epoch: 7, i: 13999] avg mini-batch loss: 2.238\n",
      "[epoch: 7, i: 14999] avg mini-batch loss: 2.256\n",
      "[epoch: 7, i: 15999] avg mini-batch loss: 2.207\n",
      "[epoch: 7, i: 16999] avg mini-batch loss: 2.271\n",
      "[epoch: 7, i: 17999] avg mini-batch loss: 2.303\n",
      "[epoch: 7, i: 18999] avg mini-batch loss: 2.330\n",
      "[epoch: 7, i: 19999] avg mini-batch loss: 2.305\n",
      "[epoch: 7, i: 20999] avg mini-batch loss: 2.278\n",
      "[epoch: 7, i: 21999] avg mini-batch loss: 2.288\n",
      "[epoch: 7, i: 22999] avg mini-batch loss: 2.304\n",
      "[epoch: 7, i: 23999] avg mini-batch loss: 2.374\n",
      "[epoch: 7, i: 24999] avg mini-batch loss: 2.328\n",
      "[epoch: 7, i: 25999] avg mini-batch loss: 2.295\n",
      "[epoch: 7, i: 26999] avg mini-batch loss: 2.286\n",
      "[epoch: 7, i: 27999] avg mini-batch loss: 2.358\n",
      "[epoch: 7, i: 28999] avg mini-batch loss: 2.268\n",
      "[epoch: 7, i: 29999] avg mini-batch loss: 2.358\n",
      "[epoch: 7, i: 30999] avg mini-batch loss: 2.384\n",
      "[epoch: 7, i: 31999] avg mini-batch loss: 2.254\n",
      "[epoch: 7, i: 32999] avg mini-batch loss: 2.377\n",
      "[epoch: 7, i: 33999] avg mini-batch loss: 2.321\n",
      "[epoch: 7, i: 34999] avg mini-batch loss: 2.375\n",
      "[epoch: 7, i: 35999] avg mini-batch loss: 2.477\n",
      "[epoch: 7, i: 36999] avg mini-batch loss: 2.258\n",
      "[epoch: 7, i: 37999] avg mini-batch loss: 2.439\n",
      "[epoch: 7, i: 38999] avg mini-batch loss: 2.356\n",
      "[epoch: 7, i: 39999] avg mini-batch loss: 2.356\n",
      "[epoch: 7, i: 40999] avg mini-batch loss: 2.466\n",
      "[epoch: 7, i: 41999] avg mini-batch loss: 2.265\n",
      "[epoch: 7, i: 42999] avg mini-batch loss: 2.347\n",
      "[epoch: 7, i: 43999] avg mini-batch loss: 2.467\n",
      "[epoch: 7, i: 44999] avg mini-batch loss: 2.364\n",
      "[epoch: 7, i: 45999] avg mini-batch loss: 2.473\n",
      "[epoch: 7, i: 46999] avg mini-batch loss: 2.460\n",
      "[epoch: 7, i: 47999] avg mini-batch loss: 2.560\n",
      "[epoch: 7, i: 48999] avg mini-batch loss: 2.569\n",
      "[epoch: 7, i: 49999] avg mini-batch loss: 2.410\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 2.081\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 2.103\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 2.111\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 2.160\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 2.146\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 2.072\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 2.140\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 2.221\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 2.154\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 2.227\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 2.359\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 2.198\n",
      "[epoch: 8, i: 12999] avg mini-batch loss: 2.381\n",
      "[epoch: 8, i: 13999] avg mini-batch loss: 2.125\n",
      "[epoch: 8, i: 14999] avg mini-batch loss: 2.367\n",
      "[epoch: 8, i: 15999] avg mini-batch loss: 2.204\n",
      "[epoch: 8, i: 16999] avg mini-batch loss: 2.249\n",
      "[epoch: 8, i: 17999] avg mini-batch loss: 2.359\n",
      "[epoch: 8, i: 18999] avg mini-batch loss: 2.356\n",
      "[epoch: 8, i: 19999] avg mini-batch loss: 2.415\n",
      "[epoch: 8, i: 20999] avg mini-batch loss: 2.354\n",
      "[epoch: 8, i: 21999] avg mini-batch loss: 2.406\n",
      "[epoch: 8, i: 22999] avg mini-batch loss: 2.330\n",
      "[epoch: 8, i: 23999] avg mini-batch loss: 2.514\n",
      "[epoch: 8, i: 24999] avg mini-batch loss: 2.295\n",
      "[epoch: 8, i: 25999] avg mini-batch loss: 2.305\n",
      "[epoch: 8, i: 26999] avg mini-batch loss: 2.396\n",
      "[epoch: 8, i: 27999] avg mini-batch loss: 2.350\n",
      "[epoch: 8, i: 28999] avg mini-batch loss: 2.476\n",
      "[epoch: 8, i: 29999] avg mini-batch loss: 2.390\n",
      "[epoch: 8, i: 30999] avg mini-batch loss: 2.417\n",
      "[epoch: 8, i: 31999] avg mini-batch loss: 2.432\n",
      "[epoch: 8, i: 32999] avg mini-batch loss: 2.403\n",
      "[epoch: 8, i: 33999] avg mini-batch loss: 2.341\n",
      "[epoch: 8, i: 34999] avg mini-batch loss: 2.512\n",
      "[epoch: 8, i: 35999] avg mini-batch loss: 2.487\n",
      "[epoch: 8, i: 36999] avg mini-batch loss: 2.481\n",
      "[epoch: 8, i: 37999] avg mini-batch loss: 2.468\n",
      "[epoch: 8, i: 38999] avg mini-batch loss: 2.412\n",
      "[epoch: 8, i: 39999] avg mini-batch loss: 2.467\n",
      "[epoch: 8, i: 40999] avg mini-batch loss: 2.650\n",
      "[epoch: 8, i: 41999] avg mini-batch loss: 2.497\n",
      "[epoch: 8, i: 42999] avg mini-batch loss: 2.409\n",
      "[epoch: 8, i: 43999] avg mini-batch loss: 2.535\n",
      "[epoch: 8, i: 44999] avg mini-batch loss: 2.543\n",
      "[epoch: 8, i: 45999] avg mini-batch loss: 2.471\n",
      "[epoch: 8, i: 46999] avg mini-batch loss: 2.451\n",
      "[epoch: 8, i: 47999] avg mini-batch loss: 2.507\n",
      "[epoch: 8, i: 48999] avg mini-batch loss: 2.486\n",
      "[epoch: 8, i: 49999] avg mini-batch loss: 2.550\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 2.126\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 2.068\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 2.198\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 2.280\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 2.409\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 2.346\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 2.273\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 2.535\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 2.344\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 2.439\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 2.290\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 2.304\n",
      "[epoch: 9, i: 12999] avg mini-batch loss: 2.432\n",
      "[epoch: 9, i: 13999] avg mini-batch loss: 2.465\n",
      "[epoch: 9, i: 14999] avg mini-batch loss: 2.453\n",
      "[epoch: 9, i: 15999] avg mini-batch loss: 2.495\n",
      "[epoch: 9, i: 16999] avg mini-batch loss: 2.368\n",
      "[epoch: 9, i: 17999] avg mini-batch loss: 2.474\n",
      "[epoch: 9, i: 18999] avg mini-batch loss: 2.558\n",
      "[epoch: 9, i: 19999] avg mini-batch loss: 2.440\n",
      "[epoch: 9, i: 20999] avg mini-batch loss: 2.451\n",
      "[epoch: 9, i: 21999] avg mini-batch loss: 2.607\n",
      "[epoch: 9, i: 22999] avg mini-batch loss: 2.729\n",
      "[epoch: 9, i: 23999] avg mini-batch loss: 2.493\n",
      "[epoch: 9, i: 24999] avg mini-batch loss: 2.548\n",
      "[epoch: 9, i: 25999] avg mini-batch loss: 2.648\n",
      "[epoch: 9, i: 26999] avg mini-batch loss: 2.718\n",
      "[epoch: 9, i: 27999] avg mini-batch loss: 2.746\n",
      "[epoch: 9, i: 28999] avg mini-batch loss: 2.583\n",
      "[epoch: 9, i: 29999] avg mini-batch loss: 2.682\n",
      "[epoch: 9, i: 30999] avg mini-batch loss: 2.637\n",
      "[epoch: 9, i: 31999] avg mini-batch loss: 2.646\n",
      "[epoch: 9, i: 32999] avg mini-batch loss: 2.683\n",
      "[epoch: 9, i: 33999] avg mini-batch loss: 2.647\n",
      "[epoch: 9, i: 34999] avg mini-batch loss: 2.727\n",
      "[epoch: 9, i: 35999] avg mini-batch loss: 2.560\n",
      "[epoch: 9, i: 36999] avg mini-batch loss: 2.586\n",
      "[epoch: 9, i: 37999] avg mini-batch loss: 2.779\n",
      "[epoch: 9, i: 38999] avg mini-batch loss: 2.708\n",
      "[epoch: 9, i: 39999] avg mini-batch loss: 2.784\n",
      "[epoch: 9, i: 40999] avg mini-batch loss: 2.751\n",
      "[epoch: 9, i: 41999] avg mini-batch loss: 2.744\n",
      "[epoch: 9, i: 42999] avg mini-batch loss: 2.849\n",
      "[epoch: 9, i: 43999] avg mini-batch loss: 2.713\n",
      "[epoch: 9, i: 44999] avg mini-batch loss: 2.794\n",
      "[epoch: 9, i: 45999] avg mini-batch loss: 2.714\n",
      "[epoch: 9, i: 46999] avg mini-batch loss: 2.661\n",
      "[epoch: 9, i: 47999] avg mini-batch loss: 2.879\n",
      "[epoch: 9, i: 48999] avg mini-batch loss: 2.757\n",
      "[epoch: 9, i: 49999] avg mini-batch loss: 2.953\n",
      "[epoch: 10, i:   999] avg mini-batch loss: 2.537\n",
      "[epoch: 10, i:  1999] avg mini-batch loss: 2.567\n",
      "[epoch: 10, i:  2999] avg mini-batch loss: 2.585\n",
      "[epoch: 10, i:  3999] avg mini-batch loss: 2.435\n",
      "[epoch: 10, i:  4999] avg mini-batch loss: 2.594\n",
      "[epoch: 10, i:  5999] avg mini-batch loss: 2.691\n",
      "[epoch: 10, i:  6999] avg mini-batch loss: 2.521\n",
      "[epoch: 10, i:  7999] avg mini-batch loss: 2.714\n",
      "[epoch: 10, i:  8999] avg mini-batch loss: 2.639\n",
      "[epoch: 10, i:  9999] avg mini-batch loss: 2.710\n",
      "[epoch: 10, i: 10999] avg mini-batch loss: 2.783\n",
      "[epoch: 10, i: 11999] avg mini-batch loss: 2.855\n",
      "[epoch: 10, i: 12999] avg mini-batch loss: 2.840\n",
      "[epoch: 10, i: 13999] avg mini-batch loss: 2.718\n",
      "[epoch: 10, i: 14999] avg mini-batch loss: 2.861\n",
      "[epoch: 10, i: 15999] avg mini-batch loss: 2.702\n",
      "[epoch: 10, i: 16999] avg mini-batch loss: 2.878\n",
      "[epoch: 10, i: 17999] avg mini-batch loss: 2.798\n",
      "[epoch: 10, i: 18999] avg mini-batch loss: 2.881\n",
      "[epoch: 10, i: 19999] avg mini-batch loss: 2.793\n",
      "[epoch: 10, i: 20999] avg mini-batch loss: 2.849\n",
      "[epoch: 10, i: 21999] avg mini-batch loss: 2.921\n",
      "[epoch: 10, i: 22999] avg mini-batch loss: 2.935\n",
      "[epoch: 10, i: 23999] avg mini-batch loss: 2.907\n",
      "[epoch: 10, i: 24999] avg mini-batch loss: 2.932\n",
      "[epoch: 10, i: 25999] avg mini-batch loss: 2.940\n",
      "[epoch: 10, i: 26999] avg mini-batch loss: 2.876\n",
      "[epoch: 10, i: 27999] avg mini-batch loss: 3.015\n",
      "[epoch: 10, i: 28999] avg mini-batch loss: 3.129\n",
      "[epoch: 10, i: 29999] avg mini-batch loss: 3.186\n",
      "[epoch: 10, i: 30999] avg mini-batch loss: 3.098\n",
      "[epoch: 10, i: 31999] avg mini-batch loss: 2.958\n",
      "[epoch: 10, i: 32999] avg mini-batch loss: 2.985\n",
      "[epoch: 10, i: 33999] avg mini-batch loss: 2.883\n",
      "[epoch: 10, i: 34999] avg mini-batch loss: 2.954\n",
      "[epoch: 10, i: 35999] avg mini-batch loss: 3.169\n",
      "[epoch: 10, i: 36999] avg mini-batch loss: 3.213\n",
      "[epoch: 10, i: 37999] avg mini-batch loss: 3.017\n",
      "[epoch: 10, i: 38999] avg mini-batch loss: 3.075\n",
      "[epoch: 10, i: 39999] avg mini-batch loss: 3.310\n",
      "[epoch: 10, i: 40999] avg mini-batch loss: 3.149\n",
      "[epoch: 10, i: 41999] avg mini-batch loss: 3.263\n",
      "[epoch: 10, i: 42999] avg mini-batch loss: 3.331\n",
      "[epoch: 10, i: 43999] avg mini-batch loss: 3.040\n",
      "[epoch: 10, i: 44999] avg mini-batch loss: 3.153\n",
      "[epoch: 10, i: 45999] avg mini-batch loss: 3.225\n",
      "[epoch: 10, i: 46999] avg mini-batch loss: 3.114\n",
      "[epoch: 10, i: 47999] avg mini-batch loss: 3.132\n",
      "[epoch: 10, i: 48999] avg mini-batch loss: 3.137\n",
      "[epoch: 10, i: 49999] avg mini-batch loss: 3.156\n",
      "[epoch: 11, i:   999] avg mini-batch loss: 2.957\n",
      "[epoch: 11, i:  1999] avg mini-batch loss: 2.818\n",
      "[epoch: 11, i:  2999] avg mini-batch loss: 2.972\n",
      "[epoch: 11, i:  3999] avg mini-batch loss: 3.031\n",
      "[epoch: 11, i:  4999] avg mini-batch loss: 2.842\n",
      "[epoch: 11, i:  5999] avg mini-batch loss: 2.854\n",
      "[epoch: 11, i:  6999] avg mini-batch loss: 3.110\n",
      "[epoch: 11, i:  7999] avg mini-batch loss: 3.065\n",
      "[epoch: 11, i:  8999] avg mini-batch loss: 3.022\n",
      "[epoch: 11, i:  9999] avg mini-batch loss: 3.399\n",
      "[epoch: 11, i: 10999] avg mini-batch loss: 3.164\n",
      "[epoch: 11, i: 11999] avg mini-batch loss: 3.216\n",
      "[epoch: 11, i: 12999] avg mini-batch loss: 3.263\n",
      "[epoch: 11, i: 13999] avg mini-batch loss: 3.192\n",
      "[epoch: 11, i: 14999] avg mini-batch loss: 3.260\n",
      "[epoch: 11, i: 15999] avg mini-batch loss: 3.373\n",
      "[epoch: 11, i: 16999] avg mini-batch loss: 3.486\n",
      "[epoch: 11, i: 17999] avg mini-batch loss: 3.392\n",
      "[epoch: 11, i: 18999] avg mini-batch loss: 3.278\n",
      "[epoch: 11, i: 19999] avg mini-batch loss: 3.179\n",
      "[epoch: 11, i: 20999] avg mini-batch loss: 3.431\n",
      "[epoch: 11, i: 21999] avg mini-batch loss: 3.447\n",
      "[epoch: 11, i: 22999] avg mini-batch loss: 3.469\n",
      "[epoch: 11, i: 23999] avg mini-batch loss: 3.496\n",
      "[epoch: 11, i: 24999] avg mini-batch loss: 3.291\n",
      "[epoch: 11, i: 25999] avg mini-batch loss: 3.414\n",
      "[epoch: 11, i: 26999] avg mini-batch loss: 3.545\n",
      "[epoch: 11, i: 27999] avg mini-batch loss: 3.459\n",
      "[epoch: 11, i: 28999] avg mini-batch loss: 3.472\n",
      "[epoch: 11, i: 29999] avg mini-batch loss: 3.316\n",
      "[epoch: 11, i: 30999] avg mini-batch loss: 3.669\n",
      "[epoch: 11, i: 31999] avg mini-batch loss: 3.644\n",
      "[epoch: 11, i: 32999] avg mini-batch loss: 3.456\n",
      "[epoch: 11, i: 33999] avg mini-batch loss: 3.648\n",
      "[epoch: 11, i: 34999] avg mini-batch loss: 3.569\n",
      "[epoch: 11, i: 35999] avg mini-batch loss: 3.570\n",
      "[epoch: 11, i: 36999] avg mini-batch loss: 3.416\n",
      "[epoch: 11, i: 37999] avg mini-batch loss: 3.585\n",
      "[epoch: 11, i: 38999] avg mini-batch loss: 3.692\n",
      "[epoch: 11, i: 39999] avg mini-batch loss: 3.426\n",
      "[epoch: 11, i: 40999] avg mini-batch loss: 4.599\n",
      "[epoch: 11, i: 41999] avg mini-batch loss: 3.779\n",
      "[epoch: 11, i: 42999] avg mini-batch loss: 4.045\n",
      "[epoch: 11, i: 43999] avg mini-batch loss: 3.559\n",
      "[epoch: 11, i: 44999] avg mini-batch loss: 3.921\n",
      "[epoch: 11, i: 45999] avg mini-batch loss: 3.690\n",
      "[epoch: 11, i: 46999] avg mini-batch loss: 3.582\n",
      "[epoch: 11, i: 47999] avg mini-batch loss: 3.711\n",
      "[epoch: 11, i: 48999] avg mini-batch loss: 3.882\n",
      "[epoch: 11, i: 49999] avg mini-batch loss: 3.632\n",
      "[epoch: 12, i:   999] avg mini-batch loss: 3.507\n",
      "[epoch: 12, i:  1999] avg mini-batch loss: 3.579\n",
      "[epoch: 12, i:  2999] avg mini-batch loss: 3.309\n",
      "[epoch: 12, i:  3999] avg mini-batch loss: 3.777\n",
      "[epoch: 12, i:  4999] avg mini-batch loss: 3.504\n",
      "[epoch: 12, i:  5999] avg mini-batch loss: 3.727\n",
      "[epoch: 12, i:  6999] avg mini-batch loss: 3.629\n",
      "[epoch: 12, i:  7999] avg mini-batch loss: 3.571\n",
      "[epoch: 12, i:  8999] avg mini-batch loss: 3.565\n",
      "[epoch: 12, i:  9999] avg mini-batch loss: 3.774\n",
      "[epoch: 12, i: 10999] avg mini-batch loss: 3.653\n",
      "[epoch: 12, i: 11999] avg mini-batch loss: 3.675\n",
      "[epoch: 12, i: 12999] avg mini-batch loss: 3.866\n",
      "[epoch: 12, i: 13999] avg mini-batch loss: 3.620\n",
      "[epoch: 12, i: 14999] avg mini-batch loss: 3.699\n",
      "[epoch: 12, i: 15999] avg mini-batch loss: 3.806\n",
      "[epoch: 12, i: 16999] avg mini-batch loss: 3.910\n",
      "[epoch: 12, i: 17999] avg mini-batch loss: 3.868\n",
      "[epoch: 12, i: 18999] avg mini-batch loss: 3.967\n",
      "[epoch: 12, i: 19999] avg mini-batch loss: 4.001\n",
      "[epoch: 12, i: 20999] avg mini-batch loss: 3.699\n",
      "[epoch: 12, i: 21999] avg mini-batch loss: 3.788\n",
      "[epoch: 12, i: 22999] avg mini-batch loss: 3.828\n",
      "[epoch: 12, i: 23999] avg mini-batch loss: 3.881\n",
      "[epoch: 12, i: 24999] avg mini-batch loss: 3.863\n",
      "[epoch: 12, i: 25999] avg mini-batch loss: 4.026\n",
      "[epoch: 12, i: 26999] avg mini-batch loss: 3.913\n",
      "[epoch: 12, i: 27999] avg mini-batch loss: 3.863\n",
      "[epoch: 12, i: 28999] avg mini-batch loss: 4.024\n",
      "[epoch: 12, i: 29999] avg mini-batch loss: 3.998\n",
      "[epoch: 12, i: 30999] avg mini-batch loss: 3.831\n",
      "[epoch: 12, i: 31999] avg mini-batch loss: 3.644\n",
      "[epoch: 12, i: 32999] avg mini-batch loss: 3.724\n",
      "[epoch: 12, i: 33999] avg mini-batch loss: 4.101\n",
      "[epoch: 12, i: 34999] avg mini-batch loss: 3.871\n",
      "[epoch: 12, i: 35999] avg mini-batch loss: 4.021\n",
      "[epoch: 12, i: 36999] avg mini-batch loss: 3.930\n",
      "[epoch: 12, i: 37999] avg mini-batch loss: 4.066\n",
      "[epoch: 12, i: 38999] avg mini-batch loss: 4.556\n",
      "[epoch: 12, i: 39999] avg mini-batch loss: 4.027\n",
      "[epoch: 12, i: 40999] avg mini-batch loss: 4.563\n",
      "[epoch: 12, i: 41999] avg mini-batch loss: 4.021\n",
      "[epoch: 12, i: 42999] avg mini-batch loss: 4.125\n",
      "[epoch: 12, i: 43999] avg mini-batch loss: 3.907\n",
      "[epoch: 12, i: 44999] avg mini-batch loss: 4.107\n",
      "[epoch: 12, i: 45999] avg mini-batch loss: 4.165\n",
      "[epoch: 12, i: 46999] avg mini-batch loss: 4.069\n",
      "[epoch: 12, i: 47999] avg mini-batch loss: 4.048\n",
      "[epoch: 12, i: 48999] avg mini-batch loss: 4.002\n",
      "[epoch: 12, i: 49999] avg mini-batch loss: 3.866\n",
      "[epoch: 13, i:   999] avg mini-batch loss: 3.554\n",
      "[epoch: 13, i:  1999] avg mini-batch loss: 3.904\n",
      "[epoch: 13, i:  2999] avg mini-batch loss: 3.847\n",
      "[epoch: 13, i:  3999] avg mini-batch loss: 4.047\n",
      "[epoch: 13, i:  4999] avg mini-batch loss: 4.254\n",
      "[epoch: 13, i:  5999] avg mini-batch loss: 3.935\n",
      "[epoch: 13, i:  6999] avg mini-batch loss: 3.776\n",
      "[epoch: 13, i:  7999] avg mini-batch loss: 3.934\n",
      "[epoch: 13, i:  8999] avg mini-batch loss: 3.930\n",
      "[epoch: 13, i:  9999] avg mini-batch loss: 4.034\n",
      "[epoch: 13, i: 10999] avg mini-batch loss: 3.790\n",
      "[epoch: 13, i: 11999] avg mini-batch loss: 3.748\n",
      "[epoch: 13, i: 12999] avg mini-batch loss: 4.082\n",
      "[epoch: 13, i: 13999] avg mini-batch loss: 3.822\n",
      "[epoch: 13, i: 14999] avg mini-batch loss: 4.046\n",
      "[epoch: 13, i: 15999] avg mini-batch loss: 3.913\n",
      "[epoch: 13, i: 16999] avg mini-batch loss: 3.846\n",
      "[epoch: 13, i: 17999] avg mini-batch loss: 3.940\n",
      "[epoch: 13, i: 18999] avg mini-batch loss: 5.623\n",
      "[epoch: 13, i: 19999] avg mini-batch loss: 5.115\n",
      "[epoch: 13, i: 20999] avg mini-batch loss: 4.656\n",
      "[epoch: 13, i: 21999] avg mini-batch loss: 4.235\n",
      "[epoch: 13, i: 22999] avg mini-batch loss: 4.131\n",
      "[epoch: 13, i: 23999] avg mini-batch loss: 4.021\n",
      "[epoch: 13, i: 24999] avg mini-batch loss: 4.135\n",
      "[epoch: 13, i: 25999] avg mini-batch loss: 3.960\n",
      "[epoch: 13, i: 26999] avg mini-batch loss: 4.015\n",
      "[epoch: 13, i: 27999] avg mini-batch loss: 4.286\n",
      "[epoch: 13, i: 28999] avg mini-batch loss: 4.128\n",
      "[epoch: 13, i: 29999] avg mini-batch loss: 4.128\n",
      "[epoch: 13, i: 30999] avg mini-batch loss: 4.204\n",
      "[epoch: 13, i: 31999] avg mini-batch loss: 4.398\n",
      "[epoch: 13, i: 32999] avg mini-batch loss: 4.113\n",
      "[epoch: 13, i: 33999] avg mini-batch loss: 4.115\n",
      "[epoch: 13, i: 34999] avg mini-batch loss: 4.092\n",
      "[epoch: 13, i: 35999] avg mini-batch loss: 4.156\n",
      "[epoch: 13, i: 36999] avg mini-batch loss: 4.030\n",
      "[epoch: 13, i: 37999] avg mini-batch loss: 4.158\n",
      "[epoch: 13, i: 38999] avg mini-batch loss: 4.143\n",
      "[epoch: 13, i: 39999] avg mini-batch loss: 4.359\n",
      "[epoch: 13, i: 40999] avg mini-batch loss: 4.290\n",
      "[epoch: 13, i: 41999] avg mini-batch loss: 4.009\n",
      "[epoch: 13, i: 42999] avg mini-batch loss: 4.113\n",
      "[epoch: 13, i: 43999] avg mini-batch loss: 4.265\n",
      "[epoch: 13, i: 44999] avg mini-batch loss: 4.212\n",
      "[epoch: 13, i: 45999] avg mini-batch loss: 4.045\n",
      "[epoch: 13, i: 46999] avg mini-batch loss: 4.410\n",
      "[epoch: 13, i: 47999] avg mini-batch loss: 4.256\n",
      "[epoch: 13, i: 48999] avg mini-batch loss: 4.134\n",
      "[epoch: 13, i: 49999] avg mini-batch loss: 4.184\n",
      "[epoch: 14, i:   999] avg mini-batch loss: 4.186\n",
      "[epoch: 14, i:  1999] avg mini-batch loss: 3.923\n",
      "[epoch: 14, i:  2999] avg mini-batch loss: 3.945\n",
      "[epoch: 14, i:  3999] avg mini-batch loss: 4.059\n",
      "[epoch: 14, i:  4999] avg mini-batch loss: 4.009\n",
      "[epoch: 14, i:  5999] avg mini-batch loss: 4.115\n",
      "[epoch: 14, i:  6999] avg mini-batch loss: 4.037\n",
      "[epoch: 14, i:  7999] avg mini-batch loss: 4.278\n",
      "[epoch: 14, i:  8999] avg mini-batch loss: 4.324\n",
      "[epoch: 14, i:  9999] avg mini-batch loss: 4.233\n",
      "[epoch: 14, i: 10999] avg mini-batch loss: 4.203\n",
      "[epoch: 14, i: 11999] avg mini-batch loss: 4.125\n",
      "[epoch: 14, i: 12999] avg mini-batch loss: 3.944\n",
      "[epoch: 14, i: 13999] avg mini-batch loss: 4.070\n",
      "[epoch: 14, i: 14999] avg mini-batch loss: 4.184\n",
      "[epoch: 14, i: 15999] avg mini-batch loss: 4.052\n",
      "[epoch: 14, i: 16999] avg mini-batch loss: 4.049\n",
      "[epoch: 14, i: 17999] avg mini-batch loss: 4.238\n",
      "[epoch: 14, i: 18999] avg mini-batch loss: 4.149\n",
      "[epoch: 14, i: 19999] avg mini-batch loss: 4.146\n",
      "[epoch: 14, i: 20999] avg mini-batch loss: 4.187\n",
      "[epoch: 14, i: 21999] avg mini-batch loss: 4.193\n",
      "[epoch: 14, i: 22999] avg mini-batch loss: 4.700\n",
      "[epoch: 14, i: 23999] avg mini-batch loss: 4.472\n",
      "[epoch: 14, i: 24999] avg mini-batch loss: 4.425\n",
      "[epoch: 14, i: 25999] avg mini-batch loss: 4.212\n",
      "[epoch: 14, i: 26999] avg mini-batch loss: 4.287\n",
      "[epoch: 14, i: 27999] avg mini-batch loss: 4.173\n",
      "[epoch: 14, i: 28999] avg mini-batch loss: 4.385\n",
      "[epoch: 14, i: 29999] avg mini-batch loss: 4.112\n",
      "[epoch: 14, i: 30999] avg mini-batch loss: 4.195\n",
      "[epoch: 14, i: 31999] avg mini-batch loss: 4.120\n",
      "[epoch: 14, i: 32999] avg mini-batch loss: 4.657\n",
      "[epoch: 14, i: 33999] avg mini-batch loss: 4.332\n",
      "[epoch: 14, i: 34999] avg mini-batch loss: 4.472\n",
      "[epoch: 14, i: 35999] avg mini-batch loss: 4.272\n",
      "[epoch: 14, i: 36999] avg mini-batch loss: 4.328\n",
      "[epoch: 14, i: 37999] avg mini-batch loss: 4.204\n",
      "[epoch: 14, i: 38999] avg mini-batch loss: 4.245\n",
      "[epoch: 14, i: 39999] avg mini-batch loss: 4.204\n",
      "[epoch: 14, i: 40999] avg mini-batch loss: 4.299\n",
      "[epoch: 14, i: 41999] avg mini-batch loss: 4.334\n",
      "[epoch: 14, i: 42999] avg mini-batch loss: 4.345\n",
      "[epoch: 14, i: 43999] avg mini-batch loss: 4.287\n",
      "[epoch: 14, i: 44999] avg mini-batch loss: 4.451\n",
      "[epoch: 14, i: 45999] avg mini-batch loss: 4.297\n",
      "[epoch: 14, i: 46999] avg mini-batch loss: 4.629\n",
      "[epoch: 14, i: 47999] avg mini-batch loss: 4.423\n",
      "[epoch: 14, i: 48999] avg mini-batch loss: 4.448\n",
      "[epoch: 14, i: 49999] avg mini-batch loss: 4.400\n",
      "[epoch: 15, i:   999] avg mini-batch loss: 4.174\n",
      "[epoch: 15, i:  1999] avg mini-batch loss: 4.163\n",
      "[epoch: 15, i:  2999] avg mini-batch loss: 4.101\n",
      "[epoch: 15, i:  3999] avg mini-batch loss: 4.077\n",
      "[epoch: 15, i:  4999] avg mini-batch loss: 4.611\n",
      "[epoch: 15, i:  5999] avg mini-batch loss: 4.217\n",
      "[epoch: 15, i:  6999] avg mini-batch loss: 4.267\n",
      "[epoch: 15, i:  7999] avg mini-batch loss: 4.585\n",
      "[epoch: 15, i:  8999] avg mini-batch loss: 4.611\n",
      "[epoch: 15, i:  9999] avg mini-batch loss: 4.918\n",
      "[epoch: 15, i: 10999] avg mini-batch loss: 4.473\n",
      "[epoch: 15, i: 11999] avg mini-batch loss: 4.360\n",
      "[epoch: 15, i: 12999] avg mini-batch loss: 4.255\n",
      "[epoch: 15, i: 13999] avg mini-batch loss: 4.349\n",
      "[epoch: 15, i: 14999] avg mini-batch loss: 4.190\n",
      "[epoch: 15, i: 15999] avg mini-batch loss: 4.316\n",
      "[epoch: 15, i: 16999] avg mini-batch loss: 4.216\n",
      "[epoch: 15, i: 17999] avg mini-batch loss: 4.187\n",
      "[epoch: 15, i: 18999] avg mini-batch loss: 4.061\n",
      "[epoch: 15, i: 19999] avg mini-batch loss: 4.395\n",
      "[epoch: 15, i: 20999] avg mini-batch loss: 4.391\n",
      "[epoch: 15, i: 21999] avg mini-batch loss: 4.206\n",
      "[epoch: 15, i: 22999] avg mini-batch loss: 4.110\n",
      "[epoch: 15, i: 23999] avg mini-batch loss: 4.081\n",
      "[epoch: 15, i: 24999] avg mini-batch loss: 4.116\n",
      "[epoch: 15, i: 25999] avg mini-batch loss: 4.314\n",
      "[epoch: 15, i: 26999] avg mini-batch loss: 4.302\n",
      "[epoch: 15, i: 27999] avg mini-batch loss: 4.264\n",
      "[epoch: 15, i: 28999] avg mini-batch loss: 4.503\n",
      "[epoch: 15, i: 29999] avg mini-batch loss: 4.560\n",
      "[epoch: 15, i: 30999] avg mini-batch loss: 4.466\n",
      "[epoch: 15, i: 31999] avg mini-batch loss: 4.595\n",
      "[epoch: 15, i: 32999] avg mini-batch loss: 4.417\n",
      "[epoch: 15, i: 33999] avg mini-batch loss: 4.271\n",
      "[epoch: 15, i: 34999] avg mini-batch loss: 4.217\n",
      "[epoch: 15, i: 35999] avg mini-batch loss: 4.534\n",
      "[epoch: 15, i: 36999] avg mini-batch loss: 4.293\n",
      "[epoch: 15, i: 37999] avg mini-batch loss: 4.930\n",
      "[epoch: 15, i: 38999] avg mini-batch loss: 4.432\n",
      "[epoch: 15, i: 39999] avg mini-batch loss: 4.605\n",
      "[epoch: 15, i: 40999] avg mini-batch loss: 4.439\n",
      "[epoch: 15, i: 41999] avg mini-batch loss: 5.250\n",
      "[epoch: 15, i: 42999] avg mini-batch loss: 4.769\n",
      "[epoch: 15, i: 43999] avg mini-batch loss: 4.438\n",
      "[epoch: 15, i: 44999] avg mini-batch loss: 4.303\n",
      "[epoch: 15, i: 45999] avg mini-batch loss: 4.375\n",
      "[epoch: 15, i: 46999] avg mini-batch loss: 4.340\n",
      "[epoch: 15, i: 47999] avg mini-batch loss: 4.497\n",
      "[epoch: 15, i: 48999] avg mini-batch loss: 4.220\n",
      "[epoch: 15, i: 49999] avg mini-batch loss: 4.712\n",
      "[epoch: 16, i:   999] avg mini-batch loss: 4.521\n",
      "[epoch: 16, i:  1999] avg mini-batch loss: 4.411\n",
      "[epoch: 16, i:  2999] avg mini-batch loss: 4.430\n",
      "[epoch: 16, i:  3999] avg mini-batch loss: 4.637\n",
      "[epoch: 16, i:  4999] avg mini-batch loss: 4.269\n",
      "[epoch: 16, i:  5999] avg mini-batch loss: 4.364\n",
      "[epoch: 16, i:  6999] avg mini-batch loss: 4.322\n",
      "[epoch: 16, i:  7999] avg mini-batch loss: 4.609\n",
      "[epoch: 16, i:  8999] avg mini-batch loss: 4.442\n",
      "[epoch: 16, i:  9999] avg mini-batch loss: 4.413\n",
      "[epoch: 16, i: 10999] avg mini-batch loss: 4.323\n",
      "[epoch: 16, i: 11999] avg mini-batch loss: 4.407\n",
      "[epoch: 16, i: 12999] avg mini-batch loss: 4.295\n",
      "[epoch: 16, i: 13999] avg mini-batch loss: 4.203\n",
      "[epoch: 16, i: 14999] avg mini-batch loss: 4.390\n",
      "[epoch: 16, i: 15999] avg mini-batch loss: 4.606\n",
      "[epoch: 16, i: 16999] avg mini-batch loss: 4.504\n",
      "[epoch: 16, i: 17999] avg mini-batch loss: 4.218\n",
      "[epoch: 16, i: 18999] avg mini-batch loss: 4.308\n",
      "[epoch: 16, i: 19999] avg mini-batch loss: 4.369\n",
      "[epoch: 16, i: 20999] avg mini-batch loss: 4.132\n",
      "[epoch: 16, i: 21999] avg mini-batch loss: 4.274\n",
      "[epoch: 16, i: 22999] avg mini-batch loss: 4.582\n",
      "[epoch: 16, i: 23999] avg mini-batch loss: 5.211\n",
      "[epoch: 16, i: 24999] avg mini-batch loss: 5.121\n",
      "[epoch: 16, i: 25999] avg mini-batch loss: 5.051\n",
      "[epoch: 16, i: 26999] avg mini-batch loss: 4.668\n",
      "[epoch: 16, i: 27999] avg mini-batch loss: 4.651\n",
      "[epoch: 16, i: 28999] avg mini-batch loss: 4.472\n",
      "[epoch: 16, i: 29999] avg mini-batch loss: 4.290\n",
      "[epoch: 16, i: 30999] avg mini-batch loss: 4.502\n",
      "[epoch: 16, i: 31999] avg mini-batch loss: 4.356\n",
      "[epoch: 16, i: 32999] avg mini-batch loss: 4.454\n",
      "[epoch: 16, i: 33999] avg mini-batch loss: 4.470\n",
      "[epoch: 16, i: 34999] avg mini-batch loss: 4.565\n",
      "[epoch: 16, i: 35999] avg mini-batch loss: 4.330\n",
      "[epoch: 16, i: 36999] avg mini-batch loss: 4.343\n",
      "[epoch: 16, i: 37999] avg mini-batch loss: 4.147\n",
      "[epoch: 16, i: 38999] avg mini-batch loss: 4.346\n",
      "[epoch: 16, i: 39999] avg mini-batch loss: 4.458\n",
      "[epoch: 16, i: 40999] avg mini-batch loss: 4.346\n",
      "[epoch: 16, i: 41999] avg mini-batch loss: 4.368\n",
      "[epoch: 16, i: 42999] avg mini-batch loss: 4.261\n",
      "[epoch: 16, i: 43999] avg mini-batch loss: 4.441\n",
      "[epoch: 16, i: 44999] avg mini-batch loss: 4.169\n",
      "[epoch: 16, i: 45999] avg mini-batch loss: 4.192\n",
      "[epoch: 16, i: 46999] avg mini-batch loss: 4.344\n",
      "[epoch: 16, i: 47999] avg mini-batch loss: 4.436\n",
      "[epoch: 16, i: 48999] avg mini-batch loss: 4.318\n",
      "[epoch: 16, i: 49999] avg mini-batch loss: 4.386\n",
      "[epoch: 17, i:   999] avg mini-batch loss: 4.227\n",
      "[epoch: 17, i:  1999] avg mini-batch loss: 4.230\n",
      "[epoch: 17, i:  2999] avg mini-batch loss: 4.341\n",
      "[epoch: 17, i:  3999] avg mini-batch loss: 4.502\n",
      "[epoch: 17, i:  4999] avg mini-batch loss: 4.294\n",
      "[epoch: 17, i:  5999] avg mini-batch loss: 4.817\n",
      "[epoch: 17, i:  6999] avg mini-batch loss: 4.379\n",
      "[epoch: 17, i:  7999] avg mini-batch loss: 4.722\n",
      "[epoch: 17, i:  8999] avg mini-batch loss: 4.609\n",
      "[epoch: 17, i:  9999] avg mini-batch loss: 4.505\n",
      "[epoch: 17, i: 10999] avg mini-batch loss: 4.939\n",
      "[epoch: 17, i: 11999] avg mini-batch loss: 5.205\n",
      "[epoch: 17, i: 12999] avg mini-batch loss: 5.296\n",
      "[epoch: 17, i: 13999] avg mini-batch loss: 5.223\n",
      "[epoch: 17, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 17, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 18, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 18, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 19, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 19, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 20, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 20, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 21, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 21, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 22, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 22, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 23, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 23, i: 49999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:   999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  1999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  2999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  3999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  4999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  5999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  6999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  7999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  8999] avg mini-batch loss: nan\n",
      "[epoch: 24, i:  9999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 10999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 11999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 12999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 13999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 14999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 15999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 16999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 17999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 18999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 19999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 20999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 21999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 22999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 23999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 24999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 25999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 26999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 27999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 28999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 29999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 30999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 31999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 32999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 33999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 34999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 35999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 36999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 37999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 38999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 39999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 40999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 41999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 42999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 43999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 44999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 45999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 46999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 47999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 48999] avg mini-batch loss: nan\n",
      "[epoch: 24, i: 49999] avg mini-batch loss: nan\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 25       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf477eed",
   "metadata": {},
   "source": [
    "## Plotting Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce96227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1a2bb",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad224c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 1 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
