{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d7a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da4c56",
   "metadata": {},
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6117c7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', \n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', \n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', \n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', \n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', \n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b170b",
   "metadata": {},
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b574a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8336a6dc",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc14492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_layer_one): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_two): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_three): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_four): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_five): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_six): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batchNorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3 , stride=1, padding=1)\n",
    "        self.conv_layer_two = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_three = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_four = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_five = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_six = nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "        self.batchNorm = nn.BatchNorm2d(3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 100)\n",
    "  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.conv_layer_one(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.max_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_two(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_three(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_four(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_five(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.avg_pool2d(x,(2,2))\n",
    "        x = self.conv_layer_six(x)\n",
    "        x = F.elu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904d075",
   "metadata": {},
   "source": [
    "## Select Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247b7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857ce00",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "211ff432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 4.608\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 4.607\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 4.608\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 4.607\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 4.606\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 4.607\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 4.606\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 4.603\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 4.599\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 4.574\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 4.466\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 4.403\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 4.333\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 4.328\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 4.333\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 4.268\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 4.248\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 4.218\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 4.187\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 4.118\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 4.090\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 4.032\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 4.015\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 4.019\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 3.951\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 3.920\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 3.901\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 3.870\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 3.842\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 3.844\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 3.777\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 3.694\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 3.698\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 3.690\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 3.609\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 3.571\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 3.578\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 3.529\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 3.518\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 3.446\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 3.410\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 3.364\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 3.352\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 3.258\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 3.231\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 3.227\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 3.227\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 3.180\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 3.182\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 3.118\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 3.094\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 3.078\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 3.011\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 2.990\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 2.978\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 2.918\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 2.889\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 2.879\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 2.855\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 2.848\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 2.808\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 2.752\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 2.743\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 2.753\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 2.712\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 2.681\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 2.668\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 2.574\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 2.619\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 2.573\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 2.594\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 2.563\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 2.511\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 2.556\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 2.518\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 2.500\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 2.500\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 2.471\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 2.419\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 2.344\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 2.336\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 2.346\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 2.330\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 2.366\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 2.329\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 2.364\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 2.267\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 2.311\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 2.325\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 2.283\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 2.282\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 2.113\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 2.147\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 2.134\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 2.165\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 2.132\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 2.118\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 2.081\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 2.104\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 2.160\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 2.140\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 2.109\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 2.097\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 1.882\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 2.003\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 1.958\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 1.976\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 1.988\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 1.967\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 1.943\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 2.025\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 1.945\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 1.947\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 1.967\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 1.958\n",
      "[epoch: 10, i:   999] avg mini-batch loss: 1.734\n",
      "[epoch: 10, i:  1999] avg mini-batch loss: 1.790\n",
      "[epoch: 10, i:  2999] avg mini-batch loss: 1.771\n",
      "[epoch: 10, i:  3999] avg mini-batch loss: 1.792\n",
      "[epoch: 10, i:  4999] avg mini-batch loss: 1.828\n",
      "[epoch: 10, i:  5999] avg mini-batch loss: 1.770\n",
      "[epoch: 10, i:  6999] avg mini-batch loss: 1.814\n",
      "[epoch: 10, i:  7999] avg mini-batch loss: 1.811\n",
      "[epoch: 10, i:  8999] avg mini-batch loss: 1.841\n",
      "[epoch: 10, i:  9999] avg mini-batch loss: 1.851\n",
      "[epoch: 10, i: 10999] avg mini-batch loss: 1.831\n",
      "[epoch: 10, i: 11999] avg mini-batch loss: 1.798\n",
      "[epoch: 11, i:   999] avg mini-batch loss: 1.607\n",
      "[epoch: 11, i:  1999] avg mini-batch loss: 1.576\n",
      "[epoch: 11, i:  2999] avg mini-batch loss: 1.617\n",
      "[epoch: 11, i:  3999] avg mini-batch loss: 1.654\n",
      "[epoch: 11, i:  4999] avg mini-batch loss: 1.676\n",
      "[epoch: 11, i:  5999] avg mini-batch loss: 1.652\n",
      "[epoch: 11, i:  6999] avg mini-batch loss: 1.690\n",
      "[epoch: 11, i:  7999] avg mini-batch loss: 1.650\n",
      "[epoch: 11, i:  8999] avg mini-batch loss: 1.634\n",
      "[epoch: 11, i:  9999] avg mini-batch loss: 1.699\n",
      "[epoch: 11, i: 10999] avg mini-batch loss: 1.660\n",
      "[epoch: 11, i: 11999] avg mini-batch loss: 1.681\n",
      "[epoch: 12, i:   999] avg mini-batch loss: 1.404\n",
      "[epoch: 12, i:  1999] avg mini-batch loss: 1.440\n",
      "[epoch: 12, i:  2999] avg mini-batch loss: 1.468\n",
      "[epoch: 12, i:  3999] avg mini-batch loss: 1.477\n",
      "[epoch: 12, i:  4999] avg mini-batch loss: 1.472\n",
      "[epoch: 12, i:  5999] avg mini-batch loss: 1.491\n",
      "[epoch: 12, i:  6999] avg mini-batch loss: 1.532\n",
      "[epoch: 12, i:  7999] avg mini-batch loss: 1.535\n",
      "[epoch: 12, i:  8999] avg mini-batch loss: 1.529\n",
      "[epoch: 12, i:  9999] avg mini-batch loss: 1.542\n",
      "[epoch: 12, i: 10999] avg mini-batch loss: 1.539\n",
      "[epoch: 12, i: 11999] avg mini-batch loss: 1.533\n",
      "[epoch: 13, i:   999] avg mini-batch loss: 1.265\n",
      "[epoch: 13, i:  1999] avg mini-batch loss: 1.278\n",
      "[epoch: 13, i:  2999] avg mini-batch loss: 1.391\n",
      "[epoch: 13, i:  3999] avg mini-batch loss: 1.338\n",
      "[epoch: 13, i:  4999] avg mini-batch loss: 1.342\n",
      "[epoch: 13, i:  5999] avg mini-batch loss: 1.311\n",
      "[epoch: 13, i:  6999] avg mini-batch loss: 1.399\n",
      "[epoch: 13, i:  7999] avg mini-batch loss: 1.404\n",
      "[epoch: 13, i:  8999] avg mini-batch loss: 1.376\n",
      "[epoch: 13, i:  9999] avg mini-batch loss: 1.405\n",
      "[epoch: 13, i: 10999] avg mini-batch loss: 1.443\n",
      "[epoch: 13, i: 11999] avg mini-batch loss: 1.410\n",
      "[epoch: 14, i:   999] avg mini-batch loss: 1.096\n",
      "[epoch: 14, i:  1999] avg mini-batch loss: 1.153\n",
      "[epoch: 14, i:  2999] avg mini-batch loss: 1.188\n",
      "[epoch: 14, i:  3999] avg mini-batch loss: 1.192\n",
      "[epoch: 14, i:  4999] avg mini-batch loss: 1.224\n",
      "[epoch: 14, i:  5999] avg mini-batch loss: 1.222\n",
      "[epoch: 14, i:  6999] avg mini-batch loss: 1.227\n",
      "[epoch: 14, i:  7999] avg mini-batch loss: 1.190\n",
      "[epoch: 14, i:  8999] avg mini-batch loss: 1.222\n",
      "[epoch: 14, i:  9999] avg mini-batch loss: 1.292\n",
      "[epoch: 14, i: 10999] avg mini-batch loss: 1.310\n",
      "[epoch: 14, i: 11999] avg mini-batch loss: 1.275\n",
      "[epoch: 15, i:   999] avg mini-batch loss: 0.939\n",
      "[epoch: 15, i:  1999] avg mini-batch loss: 0.949\n",
      "[epoch: 15, i:  2999] avg mini-batch loss: 0.993\n",
      "[epoch: 15, i:  3999] avg mini-batch loss: 1.007\n",
      "[epoch: 15, i:  4999] avg mini-batch loss: 1.083\n",
      "[epoch: 15, i:  5999] avg mini-batch loss: 1.097\n",
      "[epoch: 15, i:  6999] avg mini-batch loss: 1.122\n",
      "[epoch: 15, i:  7999] avg mini-batch loss: 1.121\n",
      "[epoch: 15, i:  8999] avg mini-batch loss: 1.132\n",
      "[epoch: 15, i:  9999] avg mini-batch loss: 1.153\n",
      "[epoch: 15, i: 10999] avg mini-batch loss: 1.134\n",
      "[epoch: 15, i: 11999] avg mini-batch loss: 1.202\n",
      "[epoch: 16, i:   999] avg mini-batch loss: 0.777\n",
      "[epoch: 16, i:  1999] avg mini-batch loss: 0.842\n",
      "[epoch: 16, i:  2999] avg mini-batch loss: 0.886\n",
      "[epoch: 16, i:  3999] avg mini-batch loss: 0.920\n",
      "[epoch: 16, i:  4999] avg mini-batch loss: 0.936\n",
      "[epoch: 16, i:  5999] avg mini-batch loss: 0.930\n",
      "[epoch: 16, i:  6999] avg mini-batch loss: 1.038\n",
      "[epoch: 16, i:  7999] avg mini-batch loss: 0.975\n",
      "[epoch: 16, i:  8999] avg mini-batch loss: 1.007\n",
      "[epoch: 16, i:  9999] avg mini-batch loss: 1.028\n",
      "[epoch: 16, i: 10999] avg mini-batch loss: 1.026\n",
      "[epoch: 16, i: 11999] avg mini-batch loss: 1.037\n",
      "[epoch: 17, i:   999] avg mini-batch loss: 0.654\n",
      "[epoch: 17, i:  1999] avg mini-batch loss: 0.719\n",
      "[epoch: 17, i:  2999] avg mini-batch loss: 0.751\n",
      "[epoch: 17, i:  3999] avg mini-batch loss: 0.788\n",
      "[epoch: 17, i:  4999] avg mini-batch loss: 0.813\n",
      "[epoch: 17, i:  5999] avg mini-batch loss: 0.872\n",
      "[epoch: 17, i:  6999] avg mini-batch loss: 0.869\n",
      "[epoch: 17, i:  7999] avg mini-batch loss: 0.897\n",
      "[epoch: 17, i:  8999] avg mini-batch loss: 0.917\n",
      "[epoch: 17, i:  9999] avg mini-batch loss: 0.885\n",
      "[epoch: 17, i: 10999] avg mini-batch loss: 0.948\n",
      "[epoch: 17, i: 11999] avg mini-batch loss: 0.916\n",
      "[epoch: 18, i:   999] avg mini-batch loss: 0.560\n",
      "[epoch: 18, i:  1999] avg mini-batch loss: 0.643\n",
      "[epoch: 18, i:  2999] avg mini-batch loss: 0.646\n",
      "[epoch: 18, i:  3999] avg mini-batch loss: 0.687\n",
      "[epoch: 18, i:  4999] avg mini-batch loss: 0.702\n",
      "[epoch: 18, i:  5999] avg mini-batch loss: 0.721\n",
      "[epoch: 18, i:  6999] avg mini-batch loss: 0.745\n",
      "[epoch: 18, i:  7999] avg mini-batch loss: 0.793\n",
      "[epoch: 18, i:  8999] avg mini-batch loss: 0.795\n",
      "[epoch: 18, i:  9999] avg mini-batch loss: 0.818\n",
      "[epoch: 18, i: 10999] avg mini-batch loss: 0.819\n",
      "[epoch: 18, i: 11999] avg mini-batch loss: 0.804\n",
      "[epoch: 19, i:   999] avg mini-batch loss: 0.499\n",
      "[epoch: 19, i:  1999] avg mini-batch loss: 0.490\n",
      "[epoch: 19, i:  2999] avg mini-batch loss: 0.586\n",
      "[epoch: 19, i:  3999] avg mini-batch loss: 0.633\n",
      "[epoch: 19, i:  4999] avg mini-batch loss: 0.611\n",
      "[epoch: 19, i:  5999] avg mini-batch loss: 0.662\n",
      "[epoch: 19, i:  6999] avg mini-batch loss: 0.661\n",
      "[epoch: 19, i:  7999] avg mini-batch loss: 0.738\n",
      "[epoch: 19, i:  8999] avg mini-batch loss: 0.692\n",
      "[epoch: 19, i:  9999] avg mini-batch loss: 0.724\n",
      "[epoch: 19, i: 10999] avg mini-batch loss: 0.718\n",
      "[epoch: 19, i: 11999] avg mini-batch loss: 0.769\n",
      "[epoch: 20, i:   999] avg mini-batch loss: 0.472\n",
      "[epoch: 20, i:  1999] avg mini-batch loss: 0.484\n",
      "[epoch: 20, i:  2999] avg mini-batch loss: 0.482\n",
      "[epoch: 20, i:  3999] avg mini-batch loss: 0.536\n",
      "[epoch: 20, i:  4999] avg mini-batch loss: 0.560\n",
      "[epoch: 20, i:  5999] avg mini-batch loss: 0.570\n",
      "[epoch: 20, i:  6999] avg mini-batch loss: 0.566\n",
      "[epoch: 20, i:  7999] avg mini-batch loss: 0.627\n",
      "[epoch: 20, i:  8999] avg mini-batch loss: 0.665\n",
      "[epoch: 20, i:  9999] avg mini-batch loss: 0.625\n",
      "[epoch: 20, i: 10999] avg mini-batch loss: 0.655\n",
      "[epoch: 20, i: 11999] avg mini-batch loss: 0.671\n",
      "[epoch: 21, i:   999] avg mini-batch loss: 0.420\n",
      "[epoch: 21, i:  1999] avg mini-batch loss: 0.384\n",
      "[epoch: 21, i:  2999] avg mini-batch loss: 0.444\n",
      "[epoch: 21, i:  3999] avg mini-batch loss: 0.490\n",
      "[epoch: 21, i:  4999] avg mini-batch loss: 0.461\n",
      "[epoch: 21, i:  5999] avg mini-batch loss: 0.509\n",
      "[epoch: 21, i:  6999] avg mini-batch loss: 0.519\n",
      "[epoch: 21, i:  7999] avg mini-batch loss: 0.592\n",
      "[epoch: 21, i:  8999] avg mini-batch loss: 0.547\n",
      "[epoch: 21, i:  9999] avg mini-batch loss: 0.533\n",
      "[epoch: 21, i: 10999] avg mini-batch loss: 0.577\n",
      "[epoch: 21, i: 11999] avg mini-batch loss: 0.612\n",
      "[epoch: 22, i:   999] avg mini-batch loss: 0.326\n",
      "[epoch: 22, i:  1999] avg mini-batch loss: 0.343\n",
      "[epoch: 22, i:  2999] avg mini-batch loss: 0.387\n",
      "[epoch: 22, i:  3999] avg mini-batch loss: 0.408\n",
      "[epoch: 22, i:  4999] avg mini-batch loss: 0.431\n",
      "[epoch: 22, i:  5999] avg mini-batch loss: 0.397\n",
      "[epoch: 22, i:  6999] avg mini-batch loss: 0.466\n",
      "[epoch: 22, i:  7999] avg mini-batch loss: 0.497\n",
      "[epoch: 22, i:  8999] avg mini-batch loss: 0.483\n",
      "[epoch: 22, i:  9999] avg mini-batch loss: 0.549\n",
      "[epoch: 22, i: 10999] avg mini-batch loss: 0.527\n",
      "[epoch: 22, i: 11999] avg mini-batch loss: 0.545\n",
      "[epoch: 23, i:   999] avg mini-batch loss: 0.317\n",
      "[epoch: 23, i:  1999] avg mini-batch loss: 0.351\n",
      "[epoch: 23, i:  2999] avg mini-batch loss: 0.377\n",
      "[epoch: 23, i:  3999] avg mini-batch loss: 0.346\n",
      "[epoch: 23, i:  4999] avg mini-batch loss: 0.391\n",
      "[epoch: 23, i:  5999] avg mini-batch loss: 0.409\n",
      "[epoch: 23, i:  6999] avg mini-batch loss: 0.404\n",
      "[epoch: 23, i:  7999] avg mini-batch loss: 0.437\n",
      "[epoch: 23, i:  8999] avg mini-batch loss: 0.459\n",
      "[epoch: 23, i:  9999] avg mini-batch loss: 0.424\n",
      "[epoch: 23, i: 10999] avg mini-batch loss: 0.504\n",
      "[epoch: 23, i: 11999] avg mini-batch loss: 0.521\n",
      "[epoch: 24, i:   999] avg mini-batch loss: 0.294\n",
      "[epoch: 24, i:  1999] avg mini-batch loss: 0.314\n",
      "[epoch: 24, i:  2999] avg mini-batch loss: 0.343\n",
      "[epoch: 24, i:  3999] avg mini-batch loss: 0.306\n",
      "[epoch: 24, i:  4999] avg mini-batch loss: 0.328\n",
      "[epoch: 24, i:  5999] avg mini-batch loss: 0.364\n",
      "[epoch: 24, i:  6999] avg mini-batch loss: 0.388\n",
      "[epoch: 24, i:  7999] avg mini-batch loss: 0.366\n",
      "[epoch: 24, i:  8999] avg mini-batch loss: 0.419\n",
      "[epoch: 24, i:  9999] avg mini-batch loss: 0.410\n",
      "[epoch: 24, i: 10999] avg mini-batch loss: 0.432\n",
      "[epoch: 24, i: 11999] avg mini-batch loss: 0.441\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 25       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf477eed",
   "metadata": {},
   "source": [
    "## Plotting Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce96227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1a2bb",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad224c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 47 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ce54b",
   "metadata": {},
   "source": [
    "## Evaluate Test Data Across Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e14f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of apple : 74 %\n",
      "Accuracy of aquarium_fish : 57 %\n",
      "Accuracy of  baby : 39 %\n",
      "Accuracy of  bear : 28 %\n",
      "Accuracy of beaver : 52 %\n",
      "Accuracy of   bed : 36 %\n",
      "Accuracy of   bee : 54 %\n",
      "Accuracy of beetle : 46 %\n",
      "Accuracy of bicycle : 58 %\n",
      "Accuracy of bottle : 60 %\n",
      "Accuracy of  bowl : 43 %\n",
      "Accuracy of   boy : 21 %\n",
      "Accuracy of bridge : 55 %\n",
      "Accuracy of   bus : 32 %\n",
      "Accuracy of butterfly : 50 %\n",
      "Accuracy of camel : 36 %\n",
      "Accuracy of   can : 49 %\n",
      "Accuracy of castle : 67 %\n",
      "Accuracy of caterpillar : 23 %\n",
      "Accuracy of cattle : 40 %\n",
      "Accuracy of chair : 75 %\n",
      "Accuracy of chimpanzee : 59 %\n",
      "Accuracy of clock : 52 %\n",
      "Accuracy of cloud : 71 %\n",
      "Accuracy of cockroach : 71 %\n",
      "Accuracy of couch : 38 %\n",
      "Accuracy of  crab : 40 %\n",
      "Accuracy of crocodile : 31 %\n",
      "Accuracy of   cup : 64 %\n",
      "Accuracy of dinosaur : 42 %\n",
      "Accuracy of dolphin : 39 %\n",
      "Accuracy of elephant : 38 %\n",
      "Accuracy of flatfish : 29 %\n",
      "Accuracy of forest : 47 %\n",
      "Accuracy of   fox : 41 %\n",
      "Accuracy of  girl : 33 %\n",
      "Accuracy of hamster : 44 %\n",
      "Accuracy of house : 36 %\n",
      "Accuracy of kangaroo : 49 %\n",
      "Accuracy of keyboard : 70 %\n",
      "Accuracy of  lamp : 33 %\n",
      "Accuracy of lawn_mower : 68 %\n",
      "Accuracy of leopard : 45 %\n",
      "Accuracy of  lion : 51 %\n",
      "Accuracy of lizard : 14 %\n",
      "Accuracy of lobster : 32 %\n",
      "Accuracy of   man : 16 %\n",
      "Accuracy of maple_tree : 51 %\n",
      "Accuracy of motorcycle : 80 %\n",
      "Accuracy of mountain : 62 %\n",
      "Accuracy of mouse : 37 %\n",
      "Accuracy of mushroom : 53 %\n",
      "Accuracy of oak_tree : 70 %\n",
      "Accuracy of orange : 87 %\n",
      "Accuracy of orchid : 54 %\n",
      "Accuracy of otter : 13 %\n",
      "Accuracy of palm_tree : 71 %\n",
      "Accuracy of  pear : 56 %\n",
      "Accuracy of pickup_truck : 63 %\n",
      "Accuracy of pine_tree : 46 %\n",
      "Accuracy of plain : 79 %\n",
      "Accuracy of plate : 56 %\n",
      "Accuracy of poppy : 55 %\n",
      "Accuracy of porcupine : 41 %\n",
      "Accuracy of possum : 22 %\n",
      "Accuracy of rabbit : 23 %\n",
      "Accuracy of raccoon : 47 %\n",
      "Accuracy of   ray : 37 %\n",
      "Accuracy of  road : 72 %\n",
      "Accuracy of rocket : 78 %\n",
      "Accuracy of  rose : 44 %\n",
      "Accuracy of   sea : 68 %\n",
      "Accuracy of  seal : 16 %\n",
      "Accuracy of shark : 16 %\n",
      "Accuracy of shrew : 28 %\n",
      "Accuracy of skunk : 71 %\n",
      "Accuracy of skyscraper : 65 %\n",
      "Accuracy of snail : 24 %\n",
      "Accuracy of snake : 39 %\n",
      "Accuracy of spider : 38 %\n",
      "Accuracy of squirrel : 18 %\n",
      "Accuracy of streetcar : 43 %\n",
      "Accuracy of sunflower : 75 %\n",
      "Accuracy of sweet_pepper : 34 %\n",
      "Accuracy of table : 36 %\n",
      "Accuracy of  tank : 50 %\n",
      "Accuracy of telephone : 60 %\n",
      "Accuracy of television : 62 %\n",
      "Accuracy of tiger : 54 %\n",
      "Accuracy of tractor : 47 %\n",
      "Accuracy of train : 42 %\n",
      "Accuracy of trout : 56 %\n",
      "Accuracy of tulip : 45 %\n",
      "Accuracy of turtle : 19 %\n",
      "Accuracy of wardrobe : 75 %\n",
      "Accuracy of whale : 55 %\n",
      "Accuracy of willow_tree : 36 %\n",
      "Accuracy of  wolf : 35 %\n",
      "Accuracy of woman : 24 %\n",
      "Accuracy of  worm : 47 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(100))\n",
    "class_total = list(0. for i in range(100))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(100):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
