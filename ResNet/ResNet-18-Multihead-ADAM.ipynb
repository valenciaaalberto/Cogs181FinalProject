{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58a5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ff0dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', \n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', \n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', \n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', \n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', \n",
    "    'worm'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f8273b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maple_tree shrew  road kangaroo\n"
     ]
    }
   ],
   "source": [
    "# The function to show an image.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # Unnormalize.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images.\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "# Show images.\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels.\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67397347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832189d",
   "metadata": {},
   "source": [
    "# Resnet-18 with MultiHead with ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c2fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, in_dim, heads):\n",
    "        super(MultiHeadAttentionWrapper, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=in_dim, num_heads=heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store original shape\n",
    "        original_shape = x.shape  # New line to store original shape\n",
    "\n",
    "        # Reshape x for attention\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.flatten(2).permute(0, 2, 1)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Restore attn_output to original shape\n",
    "        attn_output = attn_output.permute(0, 2, 1).contiguous()\n",
    "        attn_output = attn_output.view(batch_size, channels, height, width)\n",
    "\n",
    "        # Restore x to its original shape\n",
    "        x = x.permute(0, 2, 1).contiguous().view(original_shape)  # New line to restore x's shape\n",
    "\n",
    "        return attn_output + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "317fa4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Load pretrained ResNet-18\n",
    "        self.resnet = models.resnet18(pretrained=False)\n",
    "\n",
    "        # Modify the first convolutional layer\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        # Modify to output 100 classes\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 100)\n",
    "\n",
    "        # Modify layers to include multi-head attention\n",
    "        self.layer1 = self._add_attention_to_layer(self.resnet.layer1, 64, 2)\n",
    "        self.layer2 = self._add_attention_to_layer(self.resnet.layer2, 128, 4)\n",
    "        self.layer3 = self._add_attention_to_layer(self.resnet.layer3, 256, 8)\n",
    "        self.layer4 = self._add_attention_to_layer(self.resnet.layer4, 512, 8)\n",
    "\n",
    "    def _add_attention_to_layer(self, layer, in_dim, heads):\n",
    "        new_layer = []\n",
    "        for block in layer:\n",
    "            new_layer.append(block)\n",
    "            new_layer.append(MultiHeadAttentionWrapper(in_dim, heads))\n",
    "        return nn.Sequential(*new_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Assuming 'device' is defined (e.g., 'cuda' or 'cpu')\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26dd6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Your existing loss function remains the same\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the Adam optimizer\n",
    "opt = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0f7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 4.630\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.610\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 4.629\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 4.618\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 4.616\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 4.615\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 4.616\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 4.615\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 4.618\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 4.619\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 4.620\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 4.619\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 4.618\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 4.619\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 4.620\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 4.617\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 4.621\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 4.619\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 4.620\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 4.621\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 4.621\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 4.620\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 4.621\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 4.620\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 4.617\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 4.618\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 4.617\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 4.619\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 4.619\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 4.621\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 4.621\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 4.623\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 4.619\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 4.621\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 4.621\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 4.621\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 4.618\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 4.620\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 4.620\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 4.621\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 4.621\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 4.620\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 4.622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Forward step.\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Backward step.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m---> 39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 100       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa87c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(avg_losses)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmini-batch index / \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(print_freq))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg. mini-batch loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11162f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m testloader:\n\u001b[0;32m      6\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the X test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
