{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58a5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ff0dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', \n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', \n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', \n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', \n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', \n",
    "    'worm'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f8273b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lamp cockroach house   sea\n"
     ]
    }
   ],
   "source": [
    "# The function to show an image.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # Unnormalize.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images.\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "# Show images.\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Print labels.\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67397347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832189d",
   "metadata": {},
   "source": [
    "# Resnet-18 with MultiHead with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c2fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, in_dim, heads):\n",
    "        super(MultiHeadAttentionWrapper, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=in_dim, num_heads=heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store original shape\n",
    "        original_shape = x.shape  # New line to store original shape\n",
    "\n",
    "        # Reshape x for attention\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.flatten(2).permute(0, 2, 1)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Restore attn_output to original shape\n",
    "        attn_output = attn_output.permute(0, 2, 1).contiguous()\n",
    "        attn_output = attn_output.view(batch_size, channels, height, width)\n",
    "\n",
    "        # Restore x to its original shape\n",
    "        x = x.permute(0, 2, 1).contiguous().view(original_shape)  # New line to restore x's shape\n",
    "\n",
    "        return attn_output + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317fa4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Melvyn Tan\\miniconda3\\envs\\GPU\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MultiHeadAttentionWrapper(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Load pretrained ResNet-18\n",
    "        self.resnet = models.resnet18(pretrained=False)\n",
    "\n",
    "        # Modify the first convolutional layer\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        # Modify to output 100 classes\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 100)\n",
    "\n",
    "        # Modify layers to include multi-head attention\n",
    "        self.layer1 = self._add_attention_to_layer(self.resnet.layer1, 64, 2)\n",
    "        self.layer2 = self._add_attention_to_layer(self.resnet.layer2, 128, 4)\n",
    "        self.layer3 = self._add_attention_to_layer(self.resnet.layer3, 256, 8)\n",
    "        self.layer4 = self._add_attention_to_layer(self.resnet.layer4, 512, 8)\n",
    "\n",
    "    def _add_attention_to_layer(self, layer, in_dim, heads):\n",
    "        new_layer = []\n",
    "        for block in layer:\n",
    "            new_layer.append(block)\n",
    "            new_layer.append(MultiHeadAttentionWrapper(in_dim, heads))\n",
    "        return nn.Sequential(*new_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.resnet.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Assuming 'device' is defined (e.g., 'cuda' or 'cpu')\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26dd6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "# We use stochastic gradient descent (SGD) as optimizer.\n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0f7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 4.476\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.116\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 3.944\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 3.828\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 3.672\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 3.603\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 3.546\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 3.439\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 3.367\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 3.293\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 3.219\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 3.165\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 2.974\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 2.939\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 2.882\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 2.884\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 2.860\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 2.835\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 2.759\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 2.737\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 2.738\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 2.717\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 2.639\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 2.621\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 2.377\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 2.406\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 2.396\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 2.376\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 2.345\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 2.286\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 2.310\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 2.334\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 2.362\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 2.305\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 2.291\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 2.298\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 1.982\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 1.957\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 1.984\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 2.023\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 2.012\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 2.009\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 2.009\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 2.040\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 2.012\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 2.034\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 2.008\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 2.014\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 1.659\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 1.692\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 1.689\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 1.712\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 1.771\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 1.714\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 1.752\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 1.755\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 1.743\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 1.714\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 1.803\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 1.756\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 1.333\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 1.404\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 1.447\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 1.472\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 1.460\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 1.503\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 1.542\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 1.558\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 1.518\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 1.525\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 1.565\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 1.537\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 1.090\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 1.155\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 1.202\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 1.266\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 1.263\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 1.300\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 1.254\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 1.330\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 1.329\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 1.331\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 1.367\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 1.367\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 0.916\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 0.931\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 0.951\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 1.056\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 1.070\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 1.067\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 1.132\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 1.132\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 1.168\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 1.154\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 1.131\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 1.196\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 0.718\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 0.765\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 0.817\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 0.837\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 0.885\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 0.904\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 0.963\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 0.950\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 0.956\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 0.999\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 1.012\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 1.025\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 0.613\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 0.651\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 0.667\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 0.678\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 0.762\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 0.727\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 0.776\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 0.811\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 0.835\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 0.853\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 0.864\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 0.904\n",
      "[epoch: 10, i:   999] avg mini-batch loss: 0.495\n",
      "[epoch: 10, i:  1999] avg mini-batch loss: 0.521\n",
      "[epoch: 10, i:  2999] avg mini-batch loss: 0.549\n",
      "[epoch: 10, i:  3999] avg mini-batch loss: 0.564\n",
      "[epoch: 10, i:  4999] avg mini-batch loss: 0.624\n",
      "[epoch: 10, i:  5999] avg mini-batch loss: 0.648\n",
      "[epoch: 10, i:  6999] avg mini-batch loss: 0.648\n",
      "[epoch: 10, i:  7999] avg mini-batch loss: 0.679\n",
      "[epoch: 10, i:  8999] avg mini-batch loss: 0.713\n",
      "[epoch: 10, i:  9999] avg mini-batch loss: 0.746\n",
      "[epoch: 10, i: 10999] avg mini-batch loss: 0.749\n",
      "[epoch: 10, i: 11999] avg mini-batch loss: 0.731\n",
      "[epoch: 11, i:   999] avg mini-batch loss: 0.413\n",
      "[epoch: 11, i:  1999] avg mini-batch loss: 0.412\n",
      "[epoch: 11, i:  2999] avg mini-batch loss: 0.447\n",
      "[epoch: 11, i:  3999] avg mini-batch loss: 0.463\n",
      "[epoch: 11, i:  4999] avg mini-batch loss: 0.503\n",
      "[epoch: 11, i:  5999] avg mini-batch loss: 0.498\n",
      "[epoch: 11, i:  6999] avg mini-batch loss: 0.574\n",
      "[epoch: 11, i:  7999] avg mini-batch loss: 0.603\n",
      "[epoch: 11, i:  8999] avg mini-batch loss: 0.565\n",
      "[epoch: 11, i:  9999] avg mini-batch loss: 0.621\n",
      "[epoch: 11, i: 10999] avg mini-batch loss: 0.616\n",
      "[epoch: 11, i: 11999] avg mini-batch loss: 0.650\n",
      "[epoch: 12, i:   999] avg mini-batch loss: 0.356\n",
      "[epoch: 12, i:  1999] avg mini-batch loss: 0.371\n",
      "[epoch: 12, i:  2999] avg mini-batch loss: 0.365\n",
      "[epoch: 12, i:  3999] avg mini-batch loss: 0.388\n",
      "[epoch: 12, i:  4999] avg mini-batch loss: 0.432\n",
      "[epoch: 12, i:  5999] avg mini-batch loss: 0.486\n",
      "[epoch: 12, i:  6999] avg mini-batch loss: 0.466\n",
      "[epoch: 12, i:  7999] avg mini-batch loss: 0.505\n",
      "[epoch: 12, i:  8999] avg mini-batch loss: 0.554\n",
      "[epoch: 12, i:  9999] avg mini-batch loss: 0.559\n",
      "[epoch: 12, i: 10999] avg mini-batch loss: 0.548\n",
      "[epoch: 12, i: 11999] avg mini-batch loss: 0.541\n",
      "[epoch: 13, i:   999] avg mini-batch loss: 0.320\n",
      "[epoch: 13, i:  1999] avg mini-batch loss: 0.304\n",
      "[epoch: 13, i:  2999] avg mini-batch loss: 0.359\n",
      "[epoch: 13, i:  3999] avg mini-batch loss: 0.321\n",
      "[epoch: 13, i:  4999] avg mini-batch loss: 0.387\n",
      "[epoch: 13, i:  5999] avg mini-batch loss: 0.421\n",
      "[epoch: 13, i:  6999] avg mini-batch loss: 0.363\n",
      "[epoch: 13, i:  7999] avg mini-batch loss: 0.453\n",
      "[epoch: 13, i:  8999] avg mini-batch loss: 0.474\n",
      "[epoch: 13, i:  9999] avg mini-batch loss: 0.473\n",
      "[epoch: 13, i: 10999] avg mini-batch loss: 0.449\n",
      "[epoch: 13, i: 11999] avg mini-batch loss: 0.509\n",
      "[epoch: 14, i:   999] avg mini-batch loss: 0.268\n",
      "[epoch: 14, i:  1999] avg mini-batch loss: 0.279\n",
      "[epoch: 14, i:  2999] avg mini-batch loss: 0.277\n",
      "[epoch: 14, i:  3999] avg mini-batch loss: 0.308\n",
      "[epoch: 14, i:  4999] avg mini-batch loss: 0.326\n",
      "[epoch: 14, i:  5999] avg mini-batch loss: 0.328\n",
      "[epoch: 14, i:  6999] avg mini-batch loss: 0.360\n",
      "[epoch: 14, i:  7999] avg mini-batch loss: 0.365\n",
      "[epoch: 14, i:  8999] avg mini-batch loss: 0.377\n",
      "[epoch: 14, i:  9999] avg mini-batch loss: 0.376\n",
      "[epoch: 14, i: 10999] avg mini-batch loss: 0.413\n",
      "[epoch: 14, i: 11999] avg mini-batch loss: 0.413\n",
      "[epoch: 15, i:   999] avg mini-batch loss: 0.245\n",
      "[epoch: 15, i:  1999] avg mini-batch loss: 0.205\n",
      "[epoch: 15, i:  2999] avg mini-batch loss: 0.243\n",
      "[epoch: 15, i:  3999] avg mini-batch loss: 0.258\n",
      "[epoch: 15, i:  4999] avg mini-batch loss: 0.251\n",
      "[epoch: 15, i:  5999] avg mini-batch loss: 0.299\n",
      "[epoch: 15, i:  6999] avg mini-batch loss: 0.328\n",
      "[epoch: 15, i:  7999] avg mini-batch loss: 0.337\n",
      "[epoch: 15, i:  8999] avg mini-batch loss: 0.331\n",
      "[epoch: 15, i:  9999] avg mini-batch loss: 0.345\n",
      "[epoch: 15, i: 10999] avg mini-batch loss: 0.347\n",
      "[epoch: 15, i: 11999] avg mini-batch loss: 0.384\n",
      "[epoch: 16, i:   999] avg mini-batch loss: 0.232\n",
      "[epoch: 16, i:  1999] avg mini-batch loss: 0.200\n",
      "[epoch: 16, i:  2999] avg mini-batch loss: 0.249\n",
      "[epoch: 16, i:  3999] avg mini-batch loss: 0.260\n",
      "[epoch: 16, i:  4999] avg mini-batch loss: 0.240\n",
      "[epoch: 16, i:  5999] avg mini-batch loss: 0.254\n",
      "[epoch: 16, i:  6999] avg mini-batch loss: 0.277\n",
      "[epoch: 16, i:  7999] avg mini-batch loss: 0.312\n",
      "[epoch: 16, i:  8999] avg mini-batch loss: 0.298\n",
      "[epoch: 16, i:  9999] avg mini-batch loss: 0.305\n",
      "[epoch: 16, i: 10999] avg mini-batch loss: 0.292\n",
      "[epoch: 16, i: 11999] avg mini-batch loss: 0.335\n",
      "[epoch: 17, i:   999] avg mini-batch loss: 0.186\n",
      "[epoch: 17, i:  1999] avg mini-batch loss: 0.179\n",
      "[epoch: 17, i:  2999] avg mini-batch loss: 0.211\n",
      "[epoch: 17, i:  3999] avg mini-batch loss: 0.201\n",
      "[epoch: 17, i:  4999] avg mini-batch loss: 0.233\n",
      "[epoch: 17, i:  5999] avg mini-batch loss: 0.232\n",
      "[epoch: 17, i:  6999] avg mini-batch loss: 0.214\n",
      "[epoch: 17, i:  7999] avg mini-batch loss: 0.247\n",
      "[epoch: 17, i:  8999] avg mini-batch loss: 0.242\n",
      "[epoch: 17, i:  9999] avg mini-batch loss: 0.289\n",
      "[epoch: 17, i: 10999] avg mini-batch loss: 0.258\n",
      "[epoch: 17, i: 11999] avg mini-batch loss: 0.279\n",
      "[epoch: 18, i:   999] avg mini-batch loss: 0.172\n",
      "[epoch: 18, i:  1999] avg mini-batch loss: 0.159\n",
      "[epoch: 18, i:  2999] avg mini-batch loss: 0.178\n",
      "[epoch: 18, i:  3999] avg mini-batch loss: 0.170\n",
      "[epoch: 18, i:  4999] avg mini-batch loss: 0.199\n",
      "[epoch: 18, i:  5999] avg mini-batch loss: 0.212\n",
      "[epoch: 18, i:  6999] avg mini-batch loss: 0.202\n",
      "[epoch: 18, i:  7999] avg mini-batch loss: 0.230\n",
      "[epoch: 18, i:  8999] avg mini-batch loss: 0.228\n",
      "[epoch: 18, i:  9999] avg mini-batch loss: 0.240\n",
      "[epoch: 18, i: 10999] avg mini-batch loss: 0.231\n",
      "[epoch: 18, i: 11999] avg mini-batch loss: 0.265\n",
      "[epoch: 19, i:   999] avg mini-batch loss: 0.141\n",
      "[epoch: 19, i:  1999] avg mini-batch loss: 0.152\n",
      "[epoch: 19, i:  2999] avg mini-batch loss: 0.145\n",
      "[epoch: 19, i:  3999] avg mini-batch loss: 0.166\n",
      "[epoch: 19, i:  4999] avg mini-batch loss: 0.175\n",
      "[epoch: 19, i:  5999] avg mini-batch loss: 0.204\n",
      "[epoch: 19, i:  6999] avg mini-batch loss: 0.200\n",
      "[epoch: 19, i:  7999] avg mini-batch loss: 0.204\n",
      "[epoch: 19, i:  8999] avg mini-batch loss: 0.192\n",
      "[epoch: 19, i:  9999] avg mini-batch loss: 0.213\n",
      "[epoch: 19, i: 10999] avg mini-batch loss: 0.222\n",
      "[epoch: 19, i: 11999] avg mini-batch loss: 0.214\n",
      "[epoch: 20, i:   999] avg mini-batch loss: 0.156\n",
      "[epoch: 20, i:  1999] avg mini-batch loss: 0.156\n",
      "[epoch: 20, i:  2999] avg mini-batch loss: 0.155\n",
      "[epoch: 20, i:  3999] avg mini-batch loss: 0.150\n",
      "[epoch: 20, i:  4999] avg mini-batch loss: 0.132\n",
      "[epoch: 20, i:  5999] avg mini-batch loss: 0.176\n",
      "[epoch: 20, i:  6999] avg mini-batch loss: 0.193\n",
      "[epoch: 20, i:  7999] avg mini-batch loss: 0.201\n",
      "[epoch: 20, i:  8999] avg mini-batch loss: 0.219\n",
      "[epoch: 20, i:  9999] avg mini-batch loss: 0.227\n",
      "[epoch: 20, i: 10999] avg mini-batch loss: 0.187\n",
      "[epoch: 20, i: 11999] avg mini-batch loss: 0.219\n",
      "[epoch: 21, i:   999] avg mini-batch loss: 0.123\n",
      "[epoch: 21, i:  1999] avg mini-batch loss: 0.123\n",
      "[epoch: 21, i:  2999] avg mini-batch loss: 0.142\n",
      "[epoch: 21, i:  3999] avg mini-batch loss: 0.135\n",
      "[epoch: 21, i:  4999] avg mini-batch loss: 0.156\n",
      "[epoch: 21, i:  5999] avg mini-batch loss: 0.152\n",
      "[epoch: 21, i:  6999] avg mini-batch loss: 0.150\n",
      "[epoch: 21, i:  7999] avg mini-batch loss: 0.171\n",
      "[epoch: 21, i:  8999] avg mini-batch loss: 0.175\n",
      "[epoch: 21, i:  9999] avg mini-batch loss: 0.191\n",
      "[epoch: 21, i: 10999] avg mini-batch loss: 0.194\n",
      "[epoch: 21, i: 11999] avg mini-batch loss: 0.193\n",
      "[epoch: 22, i:   999] avg mini-batch loss: 0.110\n",
      "[epoch: 22, i:  1999] avg mini-batch loss: 0.127\n",
      "[epoch: 22, i:  2999] avg mini-batch loss: 0.116\n",
      "[epoch: 22, i:  3999] avg mini-batch loss: 0.126\n",
      "[epoch: 22, i:  4999] avg mini-batch loss: 0.149\n",
      "[epoch: 22, i:  5999] avg mini-batch loss: 0.126\n",
      "[epoch: 22, i:  6999] avg mini-batch loss: 0.148\n",
      "[epoch: 22, i:  7999] avg mini-batch loss: 0.144\n",
      "[epoch: 22, i:  8999] avg mini-batch loss: 0.170\n",
      "[epoch: 22, i:  9999] avg mini-batch loss: 0.141\n",
      "[epoch: 22, i: 10999] avg mini-batch loss: 0.154\n",
      "[epoch: 22, i: 11999] avg mini-batch loss: 0.169\n",
      "[epoch: 23, i:   999] avg mini-batch loss: 0.102\n",
      "[epoch: 23, i:  1999] avg mini-batch loss: 0.096\n",
      "[epoch: 23, i:  2999] avg mini-batch loss: 0.108\n",
      "[epoch: 23, i:  3999] avg mini-batch loss: 0.113\n",
      "[epoch: 23, i:  4999] avg mini-batch loss: 0.113\n",
      "[epoch: 23, i:  5999] avg mini-batch loss: 0.145\n",
      "[epoch: 23, i:  6999] avg mini-batch loss: 0.131\n",
      "[epoch: 23, i:  7999] avg mini-batch loss: 0.165\n",
      "[epoch: 23, i:  8999] avg mini-batch loss: 0.148\n",
      "[epoch: 23, i:  9999] avg mini-batch loss: 0.147\n",
      "[epoch: 23, i: 10999] avg mini-batch loss: 0.158\n",
      "[epoch: 23, i: 11999] avg mini-batch loss: 0.177\n",
      "[epoch: 24, i:   999] avg mini-batch loss: 0.093\n",
      "[epoch: 24, i:  1999] avg mini-batch loss: 0.099\n",
      "[epoch: 24, i:  2999] avg mini-batch loss: 0.098\n",
      "[epoch: 24, i:  3999] avg mini-batch loss: 0.122\n",
      "[epoch: 24, i:  4999] avg mini-batch loss: 0.134\n",
      "[epoch: 24, i:  5999] avg mini-batch loss: 0.113\n",
      "[epoch: 24, i:  6999] avg mini-batch loss: 0.138\n",
      "[epoch: 24, i:  7999] avg mini-batch loss: 0.146\n",
      "[epoch: 24, i:  8999] avg mini-batch loss: 0.143\n",
      "[epoch: 24, i:  9999] avg mini-batch loss: 0.169\n",
      "[epoch: 24, i: 10999] avg mini-batch loss: 0.156\n",
      "[epoch: 24, i: 11999] avg mini-batch loss: 0.130\n",
      "[epoch: 25, i:   999] avg mini-batch loss: 0.099\n",
      "[epoch: 25, i:  1999] avg mini-batch loss: 0.102\n",
      "[epoch: 25, i:  2999] avg mini-batch loss: 0.117\n",
      "[epoch: 25, i:  3999] avg mini-batch loss: 0.095\n",
      "[epoch: 25, i:  4999] avg mini-batch loss: 0.114\n",
      "[epoch: 25, i:  5999] avg mini-batch loss: 0.118\n",
      "[epoch: 25, i:  6999] avg mini-batch loss: 0.134\n",
      "[epoch: 25, i:  7999] avg mini-batch loss: 0.101\n",
      "[epoch: 25, i:  8999] avg mini-batch loss: 0.124\n",
      "[epoch: 25, i:  9999] avg mini-batch loss: 0.125\n",
      "[epoch: 25, i: 10999] avg mini-batch loss: 0.143\n",
      "[epoch: 25, i: 11999] avg mini-batch loss: 0.130\n",
      "[epoch: 26, i:   999] avg mini-batch loss: 0.091\n",
      "[epoch: 26, i:  1999] avg mini-batch loss: 0.104\n",
      "[epoch: 26, i:  2999] avg mini-batch loss: 0.086\n",
      "[epoch: 26, i:  3999] avg mini-batch loss: 0.099\n",
      "[epoch: 26, i:  4999] avg mini-batch loss: 0.093\n",
      "[epoch: 26, i:  5999] avg mini-batch loss: 0.107\n",
      "[epoch: 26, i:  6999] avg mini-batch loss: 0.118\n",
      "[epoch: 26, i:  7999] avg mini-batch loss: 0.122\n",
      "[epoch: 26, i:  8999] avg mini-batch loss: 0.125\n",
      "[epoch: 26, i:  9999] avg mini-batch loss: 0.150\n",
      "[epoch: 26, i: 10999] avg mini-batch loss: 0.119\n",
      "[epoch: 26, i: 11999] avg mini-batch loss: 0.125\n",
      "[epoch: 27, i:   999] avg mini-batch loss: 0.087\n",
      "[epoch: 27, i:  1999] avg mini-batch loss: 0.067\n",
      "[epoch: 27, i:  2999] avg mini-batch loss: 0.078\n",
      "[epoch: 27, i:  3999] avg mini-batch loss: 0.093\n",
      "[epoch: 27, i:  4999] avg mini-batch loss: 0.094\n",
      "[epoch: 27, i:  5999] avg mini-batch loss: 0.089\n",
      "[epoch: 27, i:  6999] avg mini-batch loss: 0.088\n",
      "[epoch: 27, i:  7999] avg mini-batch loss: 0.122\n",
      "[epoch: 27, i:  8999] avg mini-batch loss: 0.126\n",
      "[epoch: 27, i:  9999] avg mini-batch loss: 0.109\n",
      "[epoch: 27, i: 10999] avg mini-batch loss: 0.137\n",
      "[epoch: 27, i: 11999] avg mini-batch loss: 0.122\n",
      "[epoch: 28, i:   999] avg mini-batch loss: 0.090\n",
      "[epoch: 28, i:  1999] avg mini-batch loss: 0.086\n",
      "[epoch: 28, i:  2999] avg mini-batch loss: 0.086\n",
      "[epoch: 28, i:  3999] avg mini-batch loss: 0.092\n",
      "[epoch: 28, i:  4999] avg mini-batch loss: 0.097\n",
      "[epoch: 28, i:  5999] avg mini-batch loss: 0.110\n",
      "[epoch: 28, i:  6999] avg mini-batch loss: 0.129\n",
      "[epoch: 28, i:  7999] avg mini-batch loss: 0.101\n",
      "[epoch: 28, i:  8999] avg mini-batch loss: 0.109\n",
      "[epoch: 28, i:  9999] avg mini-batch loss: 0.103\n",
      "[epoch: 28, i: 10999] avg mini-batch loss: 0.105\n",
      "[epoch: 28, i: 11999] avg mini-batch loss: 0.107\n",
      "[epoch: 29, i:   999] avg mini-batch loss: 0.064\n",
      "[epoch: 29, i:  1999] avg mini-batch loss: 0.077\n",
      "[epoch: 29, i:  2999] avg mini-batch loss: 0.062\n",
      "[epoch: 29, i:  3999] avg mini-batch loss: 0.069\n",
      "[epoch: 29, i:  4999] avg mini-batch loss: 0.094\n",
      "[epoch: 29, i:  5999] avg mini-batch loss: 0.089\n",
      "[epoch: 29, i:  6999] avg mini-batch loss: 0.087\n",
      "[epoch: 29, i:  7999] avg mini-batch loss: 0.113\n",
      "[epoch: 29, i:  8999] avg mini-batch loss: 0.102\n",
      "[epoch: 29, i:  9999] avg mini-batch loss: 0.110\n",
      "[epoch: 29, i: 10999] avg mini-batch loss: 0.100\n",
      "[epoch: 29, i: 11999] avg mini-batch loss: 0.111\n",
      "[epoch: 30, i:   999] avg mini-batch loss: 0.069\n",
      "[epoch: 30, i:  1999] avg mini-batch loss: 0.076\n",
      "[epoch: 30, i:  2999] avg mini-batch loss: 0.091\n",
      "[epoch: 30, i:  3999] avg mini-batch loss: 0.091\n",
      "[epoch: 30, i:  4999] avg mini-batch loss: 0.082\n",
      "[epoch: 30, i:  5999] avg mini-batch loss: 0.084\n",
      "[epoch: 30, i:  6999] avg mini-batch loss: 0.071\n",
      "[epoch: 30, i:  7999] avg mini-batch loss: 0.090\n",
      "[epoch: 30, i:  8999] avg mini-batch loss: 0.106\n",
      "[epoch: 30, i:  9999] avg mini-batch loss: 0.091\n",
      "[epoch: 30, i: 10999] avg mini-batch loss: 0.101\n",
      "[epoch: 30, i: 11999] avg mini-batch loss: 0.092\n",
      "[epoch: 31, i:   999] avg mini-batch loss: 0.079\n",
      "[epoch: 31, i:  1999] avg mini-batch loss: 0.058\n",
      "[epoch: 31, i:  2999] avg mini-batch loss: 0.070\n",
      "[epoch: 31, i:  3999] avg mini-batch loss: 0.061\n",
      "[epoch: 31, i:  4999] avg mini-batch loss: 0.089\n",
      "[epoch: 31, i:  5999] avg mini-batch loss: 0.084\n",
      "[epoch: 31, i:  6999] avg mini-batch loss: 0.076\n",
      "[epoch: 31, i:  7999] avg mini-batch loss: 0.077\n",
      "[epoch: 31, i:  8999] avg mini-batch loss: 0.088\n",
      "[epoch: 31, i:  9999] avg mini-batch loss: 0.081\n",
      "[epoch: 31, i: 10999] avg mini-batch loss: 0.078\n",
      "[epoch: 31, i: 11999] avg mini-batch loss: 0.084\n",
      "[epoch: 32, i:   999] avg mini-batch loss: 0.049\n",
      "[epoch: 32, i:  1999] avg mini-batch loss: 0.057\n",
      "[epoch: 32, i:  2999] avg mini-batch loss: 0.048\n",
      "[epoch: 32, i:  3999] avg mini-batch loss: 0.064\n",
      "[epoch: 32, i:  4999] avg mini-batch loss: 0.081\n",
      "[epoch: 32, i:  5999] avg mini-batch loss: 0.069\n",
      "[epoch: 32, i:  6999] avg mini-batch loss: 0.072\n",
      "[epoch: 32, i:  7999] avg mini-batch loss: 0.088\n",
      "[epoch: 32, i:  8999] avg mini-batch loss: 0.073\n",
      "[epoch: 32, i:  9999] avg mini-batch loss: 0.081\n",
      "[epoch: 32, i: 10999] avg mini-batch loss: 0.099\n",
      "[epoch: 32, i: 11999] avg mini-batch loss: 0.097\n",
      "[epoch: 33, i:   999] avg mini-batch loss: 0.050\n",
      "[epoch: 33, i:  1999] avg mini-batch loss: 0.050\n",
      "[epoch: 33, i:  2999] avg mini-batch loss: 0.085\n",
      "[epoch: 33, i:  3999] avg mini-batch loss: 0.090\n",
      "[epoch: 33, i:  4999] avg mini-batch loss: 0.072\n",
      "[epoch: 33, i:  5999] avg mini-batch loss: 0.089\n",
      "[epoch: 33, i:  6999] avg mini-batch loss: 0.090\n",
      "[epoch: 33, i:  7999] avg mini-batch loss: 0.079\n",
      "[epoch: 33, i:  8999] avg mini-batch loss: 0.086\n",
      "[epoch: 33, i:  9999] avg mini-batch loss: 0.095\n",
      "[epoch: 33, i: 10999] avg mini-batch loss: 0.078\n",
      "[epoch: 33, i: 11999] avg mini-batch loss: 0.086\n",
      "[epoch: 34, i:   999] avg mini-batch loss: 0.078\n",
      "[epoch: 34, i:  1999] avg mini-batch loss: 0.063\n",
      "[epoch: 34, i:  2999] avg mini-batch loss: 0.064\n",
      "[epoch: 34, i:  3999] avg mini-batch loss: 0.064\n",
      "[epoch: 34, i:  4999] avg mini-batch loss: 0.068\n",
      "[epoch: 34, i:  5999] avg mini-batch loss: 0.054\n",
      "[epoch: 34, i:  6999] avg mini-batch loss: 0.078\n",
      "[epoch: 34, i:  7999] avg mini-batch loss: 0.081\n",
      "[epoch: 34, i:  8999] avg mini-batch loss: 0.076\n",
      "[epoch: 34, i:  9999] avg mini-batch loss: 0.084\n",
      "[epoch: 34, i: 10999] avg mini-batch loss: 0.079\n",
      "[epoch: 34, i: 11999] avg mini-batch loss: 0.083\n",
      "[epoch: 35, i:   999] avg mini-batch loss: 0.060\n",
      "[epoch: 35, i:  1999] avg mini-batch loss: 0.059\n",
      "[epoch: 35, i:  2999] avg mini-batch loss: 0.048\n",
      "[epoch: 35, i:  3999] avg mini-batch loss: 0.057\n",
      "[epoch: 35, i:  4999] avg mini-batch loss: 0.061\n",
      "[epoch: 35, i:  5999] avg mini-batch loss: 0.070\n",
      "[epoch: 35, i:  6999] avg mini-batch loss: 0.074\n",
      "[epoch: 35, i:  7999] avg mini-batch loss: 0.061\n",
      "[epoch: 35, i:  8999] avg mini-batch loss: 0.067\n",
      "[epoch: 35, i:  9999] avg mini-batch loss: 0.081\n",
      "[epoch: 35, i: 10999] avg mini-batch loss: 0.076\n",
      "[epoch: 35, i: 11999] avg mini-batch loss: 0.076\n",
      "[epoch: 36, i:   999] avg mini-batch loss: 0.061\n",
      "[epoch: 36, i:  1999] avg mini-batch loss: 0.058\n",
      "[epoch: 36, i:  2999] avg mini-batch loss: 0.051\n",
      "[epoch: 36, i:  3999] avg mini-batch loss: 0.066\n",
      "[epoch: 36, i:  4999] avg mini-batch loss: 0.056\n",
      "[epoch: 36, i:  5999] avg mini-batch loss: 0.053\n",
      "[epoch: 36, i:  6999] avg mini-batch loss: 0.060\n",
      "[epoch: 36, i:  7999] avg mini-batch loss: 0.053\n",
      "[epoch: 36, i:  8999] avg mini-batch loss: 0.057\n",
      "[epoch: 36, i:  9999] avg mini-batch loss: 0.059\n",
      "[epoch: 36, i: 10999] avg mini-batch loss: 0.083\n",
      "[epoch: 36, i: 11999] avg mini-batch loss: 0.066\n",
      "[epoch: 37, i:   999] avg mini-batch loss: 0.036\n",
      "[epoch: 37, i:  1999] avg mini-batch loss: 0.052\n",
      "[epoch: 37, i:  2999] avg mini-batch loss: 0.054\n",
      "[epoch: 37, i:  3999] avg mini-batch loss: 0.049\n",
      "[epoch: 37, i:  4999] avg mini-batch loss: 0.070\n",
      "[epoch: 37, i:  5999] avg mini-batch loss: 0.066\n",
      "[epoch: 37, i:  6999] avg mini-batch loss: 0.080\n",
      "[epoch: 37, i:  7999] avg mini-batch loss: 0.084\n",
      "[epoch: 37, i:  8999] avg mini-batch loss: 0.084\n",
      "[epoch: 37, i:  9999] avg mini-batch loss: 0.069\n",
      "[epoch: 37, i: 10999] avg mini-batch loss: 0.069\n",
      "[epoch: 37, i: 11999] avg mini-batch loss: 0.067\n",
      "[epoch: 38, i:   999] avg mini-batch loss: 0.044\n",
      "[epoch: 38, i:  1999] avg mini-batch loss: 0.047\n",
      "[epoch: 38, i:  2999] avg mini-batch loss: 0.053\n",
      "[epoch: 38, i:  3999] avg mini-batch loss: 0.040\n",
      "[epoch: 38, i:  4999] avg mini-batch loss: 0.064\n",
      "[epoch: 38, i:  5999] avg mini-batch loss: 0.066\n",
      "[epoch: 38, i:  6999] avg mini-batch loss: 0.058\n",
      "[epoch: 38, i:  7999] avg mini-batch loss: 0.066\n",
      "[epoch: 38, i:  8999] avg mini-batch loss: 0.059\n",
      "[epoch: 38, i:  9999] avg mini-batch loss: 0.074\n",
      "[epoch: 38, i: 10999] avg mini-batch loss: 0.060\n",
      "[epoch: 38, i: 11999] avg mini-batch loss: 0.072\n",
      "[epoch: 39, i:   999] avg mini-batch loss: 0.053\n",
      "[epoch: 39, i:  1999] avg mini-batch loss: 0.040\n",
      "[epoch: 39, i:  2999] avg mini-batch loss: 0.040\n",
      "[epoch: 39, i:  3999] avg mini-batch loss: 0.049\n",
      "[epoch: 39, i:  4999] avg mini-batch loss: 0.055\n",
      "[epoch: 39, i:  5999] avg mini-batch loss: 0.062\n",
      "[epoch: 39, i:  6999] avg mini-batch loss: 0.073\n",
      "[epoch: 39, i:  7999] avg mini-batch loss: 0.057\n",
      "[epoch: 39, i:  8999] avg mini-batch loss: 0.061\n",
      "[epoch: 39, i:  9999] avg mini-batch loss: 0.061\n",
      "[epoch: 39, i: 10999] avg mini-batch loss: 0.056\n",
      "[epoch: 39, i: 11999] avg mini-batch loss: 0.059\n",
      "[epoch: 40, i:   999] avg mini-batch loss: 0.048\n",
      "[epoch: 40, i:  1999] avg mini-batch loss: 0.042\n",
      "[epoch: 40, i:  2999] avg mini-batch loss: 0.042\n",
      "[epoch: 40, i:  3999] avg mini-batch loss: 0.039\n",
      "[epoch: 40, i:  4999] avg mini-batch loss: 0.044\n",
      "[epoch: 40, i:  5999] avg mini-batch loss: 0.055\n",
      "[epoch: 40, i:  6999] avg mini-batch loss: 0.047\n",
      "[epoch: 40, i:  7999] avg mini-batch loss: 0.052\n",
      "[epoch: 40, i:  8999] avg mini-batch loss: 0.065\n",
      "[epoch: 40, i:  9999] avg mini-batch loss: 0.068\n",
      "[epoch: 40, i: 10999] avg mini-batch loss: 0.071\n",
      "[epoch: 40, i: 11999] avg mini-batch loss: 0.066\n",
      "[epoch: 41, i:   999] avg mini-batch loss: 0.054\n",
      "[epoch: 41, i:  1999] avg mini-batch loss: 0.043\n",
      "[epoch: 41, i:  2999] avg mini-batch loss: 0.041\n",
      "[epoch: 41, i:  3999] avg mini-batch loss: 0.042\n",
      "[epoch: 41, i:  4999] avg mini-batch loss: 0.047\n",
      "[epoch: 41, i:  5999] avg mini-batch loss: 0.049\n",
      "[epoch: 41, i:  6999] avg mini-batch loss: 0.051\n",
      "[epoch: 41, i:  7999] avg mini-batch loss: 0.044\n",
      "[epoch: 41, i:  8999] avg mini-batch loss: 0.051\n",
      "[epoch: 41, i:  9999] avg mini-batch loss: 0.061\n",
      "[epoch: 41, i: 10999] avg mini-batch loss: 0.054\n",
      "[epoch: 41, i: 11999] avg mini-batch loss: 0.058\n",
      "[epoch: 42, i:   999] avg mini-batch loss: 0.038\n",
      "[epoch: 42, i:  1999] avg mini-batch loss: 0.045\n",
      "[epoch: 42, i:  2999] avg mini-batch loss: 0.039\n",
      "[epoch: 42, i:  3999] avg mini-batch loss: 0.041\n",
      "[epoch: 42, i:  4999] avg mini-batch loss: 0.050\n",
      "[epoch: 42, i:  5999] avg mini-batch loss: 0.049\n",
      "[epoch: 42, i:  6999] avg mini-batch loss: 0.048\n",
      "[epoch: 42, i:  7999] avg mini-batch loss: 0.065\n",
      "[epoch: 42, i:  8999] avg mini-batch loss: 0.066\n",
      "[epoch: 42, i:  9999] avg mini-batch loss: 0.056\n",
      "[epoch: 42, i: 10999] avg mini-batch loss: 0.043\n",
      "[epoch: 42, i: 11999] avg mini-batch loss: 0.054\n",
      "[epoch: 43, i:   999] avg mini-batch loss: 0.036\n",
      "[epoch: 43, i:  1999] avg mini-batch loss: 0.035\n",
      "[epoch: 43, i:  2999] avg mini-batch loss: 0.042\n",
      "[epoch: 43, i:  3999] avg mini-batch loss: 0.044\n",
      "[epoch: 43, i:  4999] avg mini-batch loss: 0.043\n",
      "[epoch: 43, i:  5999] avg mini-batch loss: 0.040\n",
      "[epoch: 43, i:  6999] avg mini-batch loss: 0.043\n",
      "[epoch: 43, i:  7999] avg mini-batch loss: 0.038\n",
      "[epoch: 43, i:  8999] avg mini-batch loss: 0.037\n",
      "[epoch: 43, i:  9999] avg mini-batch loss: 0.052\n",
      "[epoch: 43, i: 10999] avg mini-batch loss: 0.038\n",
      "[epoch: 43, i: 11999] avg mini-batch loss: 0.045\n",
      "[epoch: 44, i:   999] avg mini-batch loss: 0.031\n",
      "[epoch: 44, i:  1999] avg mini-batch loss: 0.035\n",
      "[epoch: 44, i:  2999] avg mini-batch loss: 0.034\n",
      "[epoch: 44, i:  3999] avg mini-batch loss: 0.035\n",
      "[epoch: 44, i:  4999] avg mini-batch loss: 0.040\n",
      "[epoch: 44, i:  5999] avg mini-batch loss: 0.050\n",
      "[epoch: 44, i:  6999] avg mini-batch loss: 0.045\n",
      "[epoch: 44, i:  7999] avg mini-batch loss: 0.045\n",
      "[epoch: 44, i:  8999] avg mini-batch loss: 0.041\n",
      "[epoch: 44, i:  9999] avg mini-batch loss: 0.055\n",
      "[epoch: 44, i: 10999] avg mini-batch loss: 0.050\n",
      "[epoch: 44, i: 11999] avg mini-batch loss: 0.066\n",
      "[epoch: 45, i:   999] avg mini-batch loss: 0.049\n",
      "[epoch: 45, i:  1999] avg mini-batch loss: 0.029\n",
      "[epoch: 45, i:  2999] avg mini-batch loss: 0.039\n",
      "[epoch: 45, i:  3999] avg mini-batch loss: 0.050\n",
      "[epoch: 45, i:  4999] avg mini-batch loss: 0.046\n",
      "[epoch: 45, i:  5999] avg mini-batch loss: 0.047\n",
      "[epoch: 45, i:  6999] avg mini-batch loss: 0.048\n",
      "[epoch: 45, i:  7999] avg mini-batch loss: 0.058\n",
      "[epoch: 45, i:  8999] avg mini-batch loss: 0.048\n",
      "[epoch: 45, i:  9999] avg mini-batch loss: 0.059\n",
      "[epoch: 45, i: 10999] avg mini-batch loss: 0.060\n",
      "[epoch: 45, i: 11999] avg mini-batch loss: 0.053\n",
      "[epoch: 46, i:   999] avg mini-batch loss: 0.045\n",
      "[epoch: 46, i:  1999] avg mini-batch loss: 0.040\n",
      "[epoch: 46, i:  2999] avg mini-batch loss: 0.046\n",
      "[epoch: 46, i:  3999] avg mini-batch loss: 0.035\n",
      "[epoch: 46, i:  4999] avg mini-batch loss: 0.048\n",
      "[epoch: 46, i:  5999] avg mini-batch loss: 0.048\n",
      "[epoch: 46, i:  6999] avg mini-batch loss: 0.060\n",
      "[epoch: 46, i:  7999] avg mini-batch loss: 0.056\n",
      "[epoch: 46, i:  8999] avg mini-batch loss: 0.050\n",
      "[epoch: 46, i:  9999] avg mini-batch loss: 0.050\n",
      "[epoch: 46, i: 10999] avg mini-batch loss: 0.072\n",
      "[epoch: 46, i: 11999] avg mini-batch loss: 0.062\n",
      "[epoch: 47, i:   999] avg mini-batch loss: 0.038\n",
      "[epoch: 47, i:  1999] avg mini-batch loss: 0.050\n",
      "[epoch: 47, i:  2999] avg mini-batch loss: 0.037\n",
      "[epoch: 47, i:  3999] avg mini-batch loss: 0.030\n",
      "[epoch: 47, i:  4999] avg mini-batch loss: 0.045\n",
      "[epoch: 47, i:  5999] avg mini-batch loss: 0.049\n",
      "[epoch: 47, i:  6999] avg mini-batch loss: 0.066\n",
      "[epoch: 47, i:  7999] avg mini-batch loss: 0.063\n",
      "[epoch: 47, i:  8999] avg mini-batch loss: 0.056\n",
      "[epoch: 47, i:  9999] avg mini-batch loss: 0.060\n",
      "[epoch: 47, i: 10999] avg mini-batch loss: 0.059\n",
      "[epoch: 47, i: 11999] avg mini-batch loss: 0.051\n",
      "[epoch: 48, i:   999] avg mini-batch loss: 0.048\n",
      "[epoch: 48, i:  1999] avg mini-batch loss: 0.047\n",
      "[epoch: 48, i:  2999] avg mini-batch loss: 0.039\n",
      "[epoch: 48, i:  3999] avg mini-batch loss: 0.030\n",
      "[epoch: 48, i:  4999] avg mini-batch loss: 0.036\n",
      "[epoch: 48, i:  5999] avg mini-batch loss: 0.050\n",
      "[epoch: 48, i:  6999] avg mini-batch loss: 0.049\n",
      "[epoch: 48, i:  7999] avg mini-batch loss: 0.058\n",
      "[epoch: 48, i:  8999] avg mini-batch loss: 0.046\n",
      "[epoch: 48, i:  9999] avg mini-batch loss: 0.036\n",
      "[epoch: 48, i: 10999] avg mini-batch loss: 0.040\n",
      "[epoch: 48, i: 11999] avg mini-batch loss: 0.056\n",
      "[epoch: 49, i:   999] avg mini-batch loss: 0.029\n",
      "[epoch: 49, i:  1999] avg mini-batch loss: 0.035\n",
      "[epoch: 49, i:  2999] avg mini-batch loss: 0.025\n",
      "[epoch: 49, i:  3999] avg mini-batch loss: 0.025\n",
      "[epoch: 49, i:  4999] avg mini-batch loss: 0.022\n",
      "[epoch: 49, i:  5999] avg mini-batch loss: 0.029\n",
      "[epoch: 49, i:  6999] avg mini-batch loss: 0.043\n",
      "[epoch: 49, i:  7999] avg mini-batch loss: 0.041\n",
      "[epoch: 49, i:  8999] avg mini-batch loss: 0.044\n",
      "[epoch: 49, i:  9999] avg mini-batch loss: 0.035\n",
      "[epoch: 49, i: 10999] avg mini-batch loss: 0.047\n",
      "[epoch: 49, i: 11999] avg mini-batch loss: 0.058\n",
      "[epoch: 50, i:   999] avg mini-batch loss: 0.033\n",
      "[epoch: 50, i:  1999] avg mini-batch loss: 0.043\n",
      "[epoch: 50, i:  2999] avg mini-batch loss: 0.026\n",
      "[epoch: 50, i:  3999] avg mini-batch loss: 0.033\n",
      "[epoch: 50, i:  4999] avg mini-batch loss: 0.047\n",
      "[epoch: 50, i:  5999] avg mini-batch loss: 0.036\n",
      "[epoch: 50, i:  6999] avg mini-batch loss: 0.030\n",
      "[epoch: 50, i:  7999] avg mini-batch loss: 0.042\n",
      "[epoch: 50, i:  8999] avg mini-batch loss: 0.045\n",
      "[epoch: 50, i:  9999] avg mini-batch loss: 0.044\n",
      "[epoch: 50, i: 10999] avg mini-batch loss: 0.041\n",
      "[epoch: 50, i: 11999] avg mini-batch loss: 0.064\n",
      "[epoch: 51, i:   999] avg mini-batch loss: 0.041\n",
      "[epoch: 51, i:  1999] avg mini-batch loss: 0.047\n",
      "[epoch: 51, i:  2999] avg mini-batch loss: 0.041\n",
      "[epoch: 51, i:  3999] avg mini-batch loss: 0.036\n",
      "[epoch: 51, i:  4999] avg mini-batch loss: 0.033\n",
      "[epoch: 51, i:  5999] avg mini-batch loss: 0.040\n",
      "[epoch: 51, i:  6999] avg mini-batch loss: 0.038\n",
      "[epoch: 51, i:  7999] avg mini-batch loss: 0.053\n",
      "[epoch: 51, i:  8999] avg mini-batch loss: 0.054\n",
      "[epoch: 51, i:  9999] avg mini-batch loss: 0.066\n",
      "[epoch: 51, i: 10999] avg mini-batch loss: 0.045\n",
      "[epoch: 51, i: 11999] avg mini-batch loss: 0.051\n",
      "[epoch: 52, i:   999] avg mini-batch loss: 0.039\n",
      "[epoch: 52, i:  1999] avg mini-batch loss: 0.028\n",
      "[epoch: 52, i:  2999] avg mini-batch loss: 0.035\n",
      "[epoch: 52, i:  3999] avg mini-batch loss: 0.042\n",
      "[epoch: 52, i:  4999] avg mini-batch loss: 0.031\n",
      "[epoch: 52, i:  5999] avg mini-batch loss: 0.034\n",
      "[epoch: 52, i:  6999] avg mini-batch loss: 0.038\n",
      "[epoch: 52, i:  7999] avg mini-batch loss: 0.047\n",
      "[epoch: 52, i:  8999] avg mini-batch loss: 0.032\n",
      "[epoch: 52, i:  9999] avg mini-batch loss: 0.037\n",
      "[epoch: 52, i: 10999] avg mini-batch loss: 0.048\n",
      "[epoch: 52, i: 11999] avg mini-batch loss: 0.046\n",
      "[epoch: 53, i:   999] avg mini-batch loss: 0.035\n",
      "[epoch: 53, i:  1999] avg mini-batch loss: 0.029\n",
      "[epoch: 53, i:  2999] avg mini-batch loss: 0.031\n",
      "[epoch: 53, i:  3999] avg mini-batch loss: 0.033\n",
      "[epoch: 53, i:  4999] avg mini-batch loss: 0.034\n",
      "[epoch: 53, i:  5999] avg mini-batch loss: 0.033\n",
      "[epoch: 53, i:  6999] avg mini-batch loss: 0.029\n",
      "[epoch: 53, i:  7999] avg mini-batch loss: 0.039\n",
      "[epoch: 53, i:  8999] avg mini-batch loss: 0.042\n",
      "[epoch: 53, i:  9999] avg mini-batch loss: 0.037\n",
      "[epoch: 53, i: 10999] avg mini-batch loss: 0.050\n",
      "[epoch: 53, i: 11999] avg mini-batch loss: 0.037\n",
      "[epoch: 54, i:   999] avg mini-batch loss: 0.025\n",
      "[epoch: 54, i:  1999] avg mini-batch loss: 0.031\n",
      "[epoch: 54, i:  2999] avg mini-batch loss: 0.038\n",
      "[epoch: 54, i:  3999] avg mini-batch loss: 0.030\n",
      "[epoch: 54, i:  4999] avg mini-batch loss: 0.038\n",
      "[epoch: 54, i:  5999] avg mini-batch loss: 0.031\n",
      "[epoch: 54, i:  6999] avg mini-batch loss: 0.033\n",
      "[epoch: 54, i:  7999] avg mini-batch loss: 0.045\n",
      "[epoch: 54, i:  8999] avg mini-batch loss: 0.042\n",
      "[epoch: 54, i:  9999] avg mini-batch loss: 0.039\n",
      "[epoch: 54, i: 10999] avg mini-batch loss: 0.033\n",
      "[epoch: 54, i: 11999] avg mini-batch loss: 0.040\n",
      "[epoch: 55, i:   999] avg mini-batch loss: 0.031\n",
      "[epoch: 55, i:  1999] avg mini-batch loss: 0.043\n",
      "[epoch: 55, i:  2999] avg mini-batch loss: 0.036\n",
      "[epoch: 55, i:  3999] avg mini-batch loss: 0.030\n",
      "[epoch: 55, i:  4999] avg mini-batch loss: 0.031\n",
      "[epoch: 55, i:  5999] avg mini-batch loss: 0.032\n",
      "[epoch: 55, i:  6999] avg mini-batch loss: 0.044\n",
      "[epoch: 55, i:  7999] avg mini-batch loss: 0.041\n",
      "[epoch: 55, i:  8999] avg mini-batch loss: 0.030\n",
      "[epoch: 55, i:  9999] avg mini-batch loss: 0.039\n",
      "[epoch: 55, i: 10999] avg mini-batch loss: 0.045\n",
      "[epoch: 55, i: 11999] avg mini-batch loss: 0.040\n",
      "[epoch: 56, i:   999] avg mini-batch loss: 0.031\n",
      "[epoch: 56, i:  1999] avg mini-batch loss: 0.028\n",
      "[epoch: 56, i:  2999] avg mini-batch loss: 0.042\n",
      "[epoch: 56, i:  3999] avg mini-batch loss: 0.041\n",
      "[epoch: 56, i:  4999] avg mini-batch loss: 0.034\n",
      "[epoch: 56, i:  5999] avg mini-batch loss: 0.036\n",
      "[epoch: 56, i:  6999] avg mini-batch loss: 0.034\n",
      "[epoch: 56, i:  7999] avg mini-batch loss: 0.033\n",
      "[epoch: 56, i:  8999] avg mini-batch loss: 0.039\n",
      "[epoch: 56, i:  9999] avg mini-batch loss: 0.036\n",
      "[epoch: 56, i: 10999] avg mini-batch loss: 0.045\n",
      "[epoch: 56, i: 11999] avg mini-batch loss: 0.044\n",
      "[epoch: 57, i:   999] avg mini-batch loss: 0.041\n",
      "[epoch: 57, i:  1999] avg mini-batch loss: 0.026\n",
      "[epoch: 57, i:  2999] avg mini-batch loss: 0.022\n",
      "[epoch: 57, i:  3999] avg mini-batch loss: 0.029\n",
      "[epoch: 57, i:  4999] avg mini-batch loss: 0.037\n",
      "[epoch: 57, i:  5999] avg mini-batch loss: 0.031\n",
      "[epoch: 57, i:  6999] avg mini-batch loss: 0.034\n",
      "[epoch: 57, i:  7999] avg mini-batch loss: 0.032\n",
      "[epoch: 57, i:  8999] avg mini-batch loss: 0.040\n",
      "[epoch: 57, i:  9999] avg mini-batch loss: 0.045\n",
      "[epoch: 57, i: 10999] avg mini-batch loss: 0.048\n",
      "[epoch: 57, i: 11999] avg mini-batch loss: 0.044\n",
      "[epoch: 58, i:   999] avg mini-batch loss: 0.025\n",
      "[epoch: 58, i:  1999] avg mini-batch loss: 0.024\n",
      "[epoch: 58, i:  2999] avg mini-batch loss: 0.033\n",
      "[epoch: 58, i:  3999] avg mini-batch loss: 0.025\n",
      "[epoch: 58, i:  4999] avg mini-batch loss: 0.031\n",
      "[epoch: 58, i:  5999] avg mini-batch loss: 0.023\n",
      "[epoch: 58, i:  6999] avg mini-batch loss: 0.028\n",
      "[epoch: 58, i:  7999] avg mini-batch loss: 0.038\n",
      "[epoch: 58, i:  8999] avg mini-batch loss: 0.030\n",
      "[epoch: 58, i:  9999] avg mini-batch loss: 0.030\n",
      "[epoch: 58, i: 10999] avg mini-batch loss: 0.039\n",
      "[epoch: 58, i: 11999] avg mini-batch loss: 0.034\n",
      "[epoch: 59, i:   999] avg mini-batch loss: 0.028\n",
      "[epoch: 59, i:  1999] avg mini-batch loss: 0.015\n",
      "[epoch: 59, i:  2999] avg mini-batch loss: 0.015\n",
      "[epoch: 59, i:  3999] avg mini-batch loss: 0.016\n",
      "[epoch: 59, i:  4999] avg mini-batch loss: 0.016\n",
      "[epoch: 59, i:  5999] avg mini-batch loss: 0.044\n",
      "[epoch: 59, i:  6999] avg mini-batch loss: 0.028\n",
      "[epoch: 59, i:  7999] avg mini-batch loss: 0.020\n",
      "[epoch: 59, i:  8999] avg mini-batch loss: 0.022\n",
      "[epoch: 59, i:  9999] avg mini-batch loss: 0.033\n",
      "[epoch: 59, i: 10999] avg mini-batch loss: 0.049\n",
      "[epoch: 59, i: 11999] avg mini-batch loss: 0.029\n",
      "[epoch: 60, i:   999] avg mini-batch loss: 0.032\n",
      "[epoch: 60, i:  1999] avg mini-batch loss: 0.025\n",
      "[epoch: 60, i:  2999] avg mini-batch loss: 0.039\n",
      "[epoch: 60, i:  3999] avg mini-batch loss: 0.036\n",
      "[epoch: 60, i:  4999] avg mini-batch loss: 0.034\n",
      "[epoch: 60, i:  5999] avg mini-batch loss: 0.028\n",
      "[epoch: 60, i:  6999] avg mini-batch loss: 0.027\n",
      "[epoch: 60, i:  7999] avg mini-batch loss: 0.031\n",
      "[epoch: 60, i:  8999] avg mini-batch loss: 0.034\n",
      "[epoch: 60, i:  9999] avg mini-batch loss: 0.027\n",
      "[epoch: 60, i: 10999] avg mini-batch loss: 0.031\n",
      "[epoch: 60, i: 11999] avg mini-batch loss: 0.029\n",
      "[epoch: 61, i:   999] avg mini-batch loss: 0.025\n",
      "[epoch: 61, i:  1999] avg mini-batch loss: 0.027\n",
      "[epoch: 61, i:  2999] avg mini-batch loss: 0.020\n",
      "[epoch: 61, i:  3999] avg mini-batch loss: 0.022\n",
      "[epoch: 61, i:  4999] avg mini-batch loss: 0.026\n",
      "[epoch: 61, i:  5999] avg mini-batch loss: 0.028\n",
      "[epoch: 61, i:  6999] avg mini-batch loss: 0.024\n",
      "[epoch: 61, i:  7999] avg mini-batch loss: 0.019\n",
      "[epoch: 61, i:  8999] avg mini-batch loss: 0.016\n",
      "[epoch: 61, i:  9999] avg mini-batch loss: 0.019\n",
      "[epoch: 61, i: 10999] avg mini-batch loss: 0.028\n",
      "[epoch: 61, i: 11999] avg mini-batch loss: 0.035\n",
      "[epoch: 62, i:   999] avg mini-batch loss: 0.015\n",
      "[epoch: 62, i:  1999] avg mini-batch loss: 0.019\n",
      "[epoch: 62, i:  2999] avg mini-batch loss: 0.023\n",
      "[epoch: 62, i:  3999] avg mini-batch loss: 0.025\n",
      "[epoch: 62, i:  4999] avg mini-batch loss: 0.018\n",
      "[epoch: 62, i:  5999] avg mini-batch loss: 0.017\n",
      "[epoch: 62, i:  6999] avg mini-batch loss: 0.021\n",
      "[epoch: 62, i:  7999] avg mini-batch loss: 0.013\n",
      "[epoch: 62, i:  8999] avg mini-batch loss: 0.016\n",
      "[epoch: 62, i:  9999] avg mini-batch loss: 0.021\n",
      "[epoch: 62, i: 10999] avg mini-batch loss: 0.027\n",
      "[epoch: 62, i: 11999] avg mini-batch loss: 0.021\n",
      "[epoch: 63, i:   999] avg mini-batch loss: 0.018\n",
      "[epoch: 63, i:  1999] avg mini-batch loss: 0.016\n",
      "[epoch: 63, i:  2999] avg mini-batch loss: 0.020\n",
      "[epoch: 63, i:  3999] avg mini-batch loss: 0.013\n",
      "[epoch: 63, i:  4999] avg mini-batch loss: 0.021\n",
      "[epoch: 63, i:  5999] avg mini-batch loss: 0.026\n",
      "[epoch: 63, i:  6999] avg mini-batch loss: 0.017\n",
      "[epoch: 63, i:  7999] avg mini-batch loss: 0.023\n",
      "[epoch: 63, i:  8999] avg mini-batch loss: 0.025\n",
      "[epoch: 63, i:  9999] avg mini-batch loss: 0.024\n",
      "[epoch: 63, i: 10999] avg mini-batch loss: 0.034\n",
      "[epoch: 63, i: 11999] avg mini-batch loss: 0.035\n",
      "[epoch: 64, i:   999] avg mini-batch loss: 0.014\n",
      "[epoch: 64, i:  1999] avg mini-batch loss: 0.019\n",
      "[epoch: 64, i:  2999] avg mini-batch loss: 0.025\n",
      "[epoch: 64, i:  3999] avg mini-batch loss: 0.021\n",
      "[epoch: 64, i:  4999] avg mini-batch loss: 0.026\n",
      "[epoch: 64, i:  5999] avg mini-batch loss: 0.025\n",
      "[epoch: 64, i:  6999] avg mini-batch loss: 0.028\n",
      "[epoch: 64, i:  7999] avg mini-batch loss: 0.030\n",
      "[epoch: 64, i:  8999] avg mini-batch loss: 0.023\n",
      "[epoch: 64, i:  9999] avg mini-batch loss: 0.022\n",
      "[epoch: 64, i: 10999] avg mini-batch loss: 0.025\n",
      "[epoch: 64, i: 11999] avg mini-batch loss: 0.025\n",
      "[epoch: 65, i:   999] avg mini-batch loss: 0.025\n",
      "[epoch: 65, i:  1999] avg mini-batch loss: 0.022\n",
      "[epoch: 65, i:  2999] avg mini-batch loss: 0.025\n",
      "[epoch: 65, i:  3999] avg mini-batch loss: 0.024\n",
      "[epoch: 65, i:  4999] avg mini-batch loss: 0.025\n",
      "[epoch: 65, i:  5999] avg mini-batch loss: 0.023\n",
      "[epoch: 65, i:  6999] avg mini-batch loss: 0.027\n",
      "[epoch: 65, i:  7999] avg mini-batch loss: 0.029\n",
      "[epoch: 65, i:  8999] avg mini-batch loss: 0.021\n",
      "[epoch: 65, i:  9999] avg mini-batch loss: 0.036\n",
      "[epoch: 65, i: 10999] avg mini-batch loss: 0.026\n",
      "[epoch: 65, i: 11999] avg mini-batch loss: 0.024\n",
      "[epoch: 66, i:   999] avg mini-batch loss: 0.022\n",
      "[epoch: 66, i:  1999] avg mini-batch loss: 0.027\n",
      "[epoch: 66, i:  2999] avg mini-batch loss: 0.027\n",
      "[epoch: 66, i:  3999] avg mini-batch loss: 0.032\n",
      "[epoch: 66, i:  4999] avg mini-batch loss: 0.023\n",
      "[epoch: 66, i:  5999] avg mini-batch loss: 0.032\n",
      "[epoch: 66, i:  6999] avg mini-batch loss: 0.027\n",
      "[epoch: 66, i:  7999] avg mini-batch loss: 0.025\n",
      "[epoch: 66, i:  8999] avg mini-batch loss: 0.038\n",
      "[epoch: 66, i:  9999] avg mini-batch loss: 0.033\n",
      "[epoch: 66, i: 10999] avg mini-batch loss: 0.031\n",
      "[epoch: 66, i: 11999] avg mini-batch loss: 0.028\n",
      "[epoch: 67, i:   999] avg mini-batch loss: 0.022\n",
      "[epoch: 67, i:  1999] avg mini-batch loss: 0.017\n",
      "[epoch: 67, i:  2999] avg mini-batch loss: 0.023\n",
      "[epoch: 67, i:  3999] avg mini-batch loss: 0.025\n",
      "[epoch: 67, i:  4999] avg mini-batch loss: 0.022\n",
      "[epoch: 67, i:  5999] avg mini-batch loss: 0.017\n",
      "[epoch: 67, i:  6999] avg mini-batch loss: 0.017\n",
      "[epoch: 67, i:  7999] avg mini-batch loss: 0.013\n",
      "[epoch: 67, i:  8999] avg mini-batch loss: 0.024\n",
      "[epoch: 67, i:  9999] avg mini-batch loss: 0.022\n",
      "[epoch: 67, i: 10999] avg mini-batch loss: 0.022\n",
      "[epoch: 67, i: 11999] avg mini-batch loss: 0.037\n",
      "[epoch: 68, i:   999] avg mini-batch loss: 0.014\n",
      "[epoch: 68, i:  1999] avg mini-batch loss: 0.024\n",
      "[epoch: 68, i:  2999] avg mini-batch loss: 0.029\n",
      "[epoch: 68, i:  3999] avg mini-batch loss: 0.025\n",
      "[epoch: 68, i:  4999] avg mini-batch loss: 0.020\n",
      "[epoch: 68, i:  5999] avg mini-batch loss: 0.025\n",
      "[epoch: 68, i:  6999] avg mini-batch loss: 0.028\n",
      "[epoch: 68, i:  7999] avg mini-batch loss: 0.028\n",
      "[epoch: 68, i:  8999] avg mini-batch loss: 0.020\n",
      "[epoch: 68, i:  9999] avg mini-batch loss: 0.026\n",
      "[epoch: 68, i: 10999] avg mini-batch loss: 0.032\n",
      "[epoch: 68, i: 11999] avg mini-batch loss: 0.036\n",
      "[epoch: 69, i:   999] avg mini-batch loss: 0.021\n",
      "[epoch: 69, i:  1999] avg mini-batch loss: 0.032\n",
      "[epoch: 69, i:  2999] avg mini-batch loss: 0.028\n",
      "[epoch: 69, i:  3999] avg mini-batch loss: 0.025\n",
      "[epoch: 69, i:  4999] avg mini-batch loss: 0.024\n",
      "[epoch: 69, i:  5999] avg mini-batch loss: 0.023\n",
      "[epoch: 69, i:  6999] avg mini-batch loss: 0.027\n",
      "[epoch: 69, i:  7999] avg mini-batch loss: 0.028\n",
      "[epoch: 69, i:  8999] avg mini-batch loss: 0.032\n",
      "[epoch: 69, i:  9999] avg mini-batch loss: 0.028\n",
      "[epoch: 69, i: 10999] avg mini-batch loss: 0.029\n",
      "[epoch: 69, i: 11999] avg mini-batch loss: 0.028\n",
      "[epoch: 70, i:   999] avg mini-batch loss: 0.021\n",
      "[epoch: 70, i:  1999] avg mini-batch loss: 0.038\n",
      "[epoch: 70, i:  2999] avg mini-batch loss: 0.021\n",
      "[epoch: 70, i:  3999] avg mini-batch loss: 0.024\n",
      "[epoch: 70, i:  4999] avg mini-batch loss: 0.029\n",
      "[epoch: 70, i:  5999] avg mini-batch loss: 0.023\n",
      "[epoch: 70, i:  6999] avg mini-batch loss: 0.025\n",
      "[epoch: 70, i:  7999] avg mini-batch loss: 0.028\n",
      "[epoch: 70, i:  8999] avg mini-batch loss: 0.035\n",
      "[epoch: 70, i:  9999] avg mini-batch loss: 0.032\n",
      "[epoch: 70, i: 10999] avg mini-batch loss: 0.034\n",
      "[epoch: 70, i: 11999] avg mini-batch loss: 0.033\n",
      "[epoch: 71, i:   999] avg mini-batch loss: 0.031\n",
      "[epoch: 71, i:  1999] avg mini-batch loss: 0.018\n",
      "[epoch: 71, i:  2999] avg mini-batch loss: 0.021\n",
      "[epoch: 71, i:  3999] avg mini-batch loss: 0.027\n",
      "[epoch: 71, i:  4999] avg mini-batch loss: 0.033\n",
      "[epoch: 71, i:  5999] avg mini-batch loss: 0.031\n",
      "[epoch: 71, i:  6999] avg mini-batch loss: 0.038\n",
      "[epoch: 71, i:  7999] avg mini-batch loss: 0.036\n",
      "[epoch: 71, i:  8999] avg mini-batch loss: 0.031\n",
      "[epoch: 71, i:  9999] avg mini-batch loss: 0.037\n",
      "[epoch: 71, i: 10999] avg mini-batch loss: 0.034\n",
      "[epoch: 71, i: 11999] avg mini-batch loss: 0.032\n",
      "[epoch: 72, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 72, i:  1999] avg mini-batch loss: 0.025\n",
      "[epoch: 72, i:  2999] avg mini-batch loss: 0.018\n",
      "[epoch: 72, i:  3999] avg mini-batch loss: 0.027\n",
      "[epoch: 72, i:  4999] avg mini-batch loss: 0.026\n",
      "[epoch: 72, i:  5999] avg mini-batch loss: 0.021\n",
      "[epoch: 72, i:  6999] avg mini-batch loss: 0.014\n",
      "[epoch: 72, i:  7999] avg mini-batch loss: 0.019\n",
      "[epoch: 72, i:  8999] avg mini-batch loss: 0.012\n",
      "[epoch: 72, i:  9999] avg mini-batch loss: 0.023\n",
      "[epoch: 72, i: 10999] avg mini-batch loss: 0.015\n",
      "[epoch: 72, i: 11999] avg mini-batch loss: 0.019\n",
      "[epoch: 73, i:   999] avg mini-batch loss: 0.024\n",
      "[epoch: 73, i:  1999] avg mini-batch loss: 0.021\n",
      "[epoch: 73, i:  2999] avg mini-batch loss: 0.016\n",
      "[epoch: 73, i:  3999] avg mini-batch loss: 0.024\n",
      "[epoch: 73, i:  4999] avg mini-batch loss: 0.020\n",
      "[epoch: 73, i:  5999] avg mini-batch loss: 0.018\n",
      "[epoch: 73, i:  6999] avg mini-batch loss: 0.027\n",
      "[epoch: 73, i:  7999] avg mini-batch loss: 0.025\n",
      "[epoch: 73, i:  8999] avg mini-batch loss: 0.022\n",
      "[epoch: 73, i:  9999] avg mini-batch loss: 0.032\n",
      "[epoch: 73, i: 10999] avg mini-batch loss: 0.033\n",
      "[epoch: 73, i: 11999] avg mini-batch loss: 0.034\n",
      "[epoch: 74, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 74, i:  1999] avg mini-batch loss: 0.020\n",
      "[epoch: 74, i:  2999] avg mini-batch loss: 0.029\n",
      "[epoch: 74, i:  3999] avg mini-batch loss: 0.014\n",
      "[epoch: 74, i:  4999] avg mini-batch loss: 0.027\n",
      "[epoch: 74, i:  5999] avg mini-batch loss: 0.020\n",
      "[epoch: 74, i:  6999] avg mini-batch loss: 0.023\n",
      "[epoch: 74, i:  7999] avg mini-batch loss: 0.018\n",
      "[epoch: 74, i:  8999] avg mini-batch loss: 0.020\n",
      "[epoch: 74, i:  9999] avg mini-batch loss: 0.029\n",
      "[epoch: 74, i: 10999] avg mini-batch loss: 0.029\n",
      "[epoch: 74, i: 11999] avg mini-batch loss: 0.041\n",
      "[epoch: 75, i:   999] avg mini-batch loss: 0.019\n",
      "[epoch: 75, i:  1999] avg mini-batch loss: 0.017\n",
      "[epoch: 75, i:  2999] avg mini-batch loss: 0.034\n",
      "[epoch: 75, i:  3999] avg mini-batch loss: 0.017\n",
      "[epoch: 75, i:  4999] avg mini-batch loss: 0.020\n",
      "[epoch: 75, i:  5999] avg mini-batch loss: 0.023\n",
      "[epoch: 75, i:  6999] avg mini-batch loss: 0.028\n",
      "[epoch: 75, i:  7999] avg mini-batch loss: 0.034\n",
      "[epoch: 75, i:  8999] avg mini-batch loss: 0.018\n",
      "[epoch: 75, i:  9999] avg mini-batch loss: 0.024\n",
      "[epoch: 75, i: 10999] avg mini-batch loss: 0.022\n",
      "[epoch: 75, i: 11999] avg mini-batch loss: 0.024\n",
      "[epoch: 76, i:   999] avg mini-batch loss: 0.022\n",
      "[epoch: 76, i:  1999] avg mini-batch loss: 0.034\n",
      "[epoch: 76, i:  2999] avg mini-batch loss: 0.033\n",
      "[epoch: 76, i:  3999] avg mini-batch loss: 0.019\n",
      "[epoch: 76, i:  4999] avg mini-batch loss: 0.025\n",
      "[epoch: 76, i:  5999] avg mini-batch loss: 0.022\n",
      "[epoch: 76, i:  6999] avg mini-batch loss: 0.029\n",
      "[epoch: 76, i:  7999] avg mini-batch loss: 0.027\n",
      "[epoch: 76, i:  8999] avg mini-batch loss: 0.017\n",
      "[epoch: 76, i:  9999] avg mini-batch loss: 0.032\n",
      "[epoch: 76, i: 10999] avg mini-batch loss: 0.029\n",
      "[epoch: 76, i: 11999] avg mini-batch loss: 0.025\n",
      "[epoch: 77, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 77, i:  1999] avg mini-batch loss: 0.019\n",
      "[epoch: 77, i:  2999] avg mini-batch loss: 0.023\n",
      "[epoch: 77, i:  3999] avg mini-batch loss: 0.021\n",
      "[epoch: 77, i:  4999] avg mini-batch loss: 0.017\n",
      "[epoch: 77, i:  5999] avg mini-batch loss: 0.021\n",
      "[epoch: 77, i:  6999] avg mini-batch loss: 0.020\n",
      "[epoch: 77, i:  7999] avg mini-batch loss: 0.027\n",
      "[epoch: 77, i:  8999] avg mini-batch loss: 0.021\n",
      "[epoch: 77, i:  9999] avg mini-batch loss: 0.023\n",
      "[epoch: 77, i: 10999] avg mini-batch loss: 0.028\n",
      "[epoch: 77, i: 11999] avg mini-batch loss: 0.023\n",
      "[epoch: 78, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 78, i:  1999] avg mini-batch loss: 0.020\n",
      "[epoch: 78, i:  2999] avg mini-batch loss: 0.019\n",
      "[epoch: 78, i:  3999] avg mini-batch loss: 0.023\n",
      "[epoch: 78, i:  4999] avg mini-batch loss: 0.024\n",
      "[epoch: 78, i:  5999] avg mini-batch loss: 0.019\n",
      "[epoch: 78, i:  6999] avg mini-batch loss: 0.019\n",
      "[epoch: 78, i:  7999] avg mini-batch loss: 0.026\n",
      "[epoch: 78, i:  8999] avg mini-batch loss: 0.024\n",
      "[epoch: 78, i:  9999] avg mini-batch loss: 0.018\n",
      "[epoch: 78, i: 10999] avg mini-batch loss: 0.025\n",
      "[epoch: 78, i: 11999] avg mini-batch loss: 0.027\n",
      "[epoch: 79, i:   999] avg mini-batch loss: 0.021\n",
      "[epoch: 79, i:  1999] avg mini-batch loss: 0.025\n",
      "[epoch: 79, i:  2999] avg mini-batch loss: 0.019\n",
      "[epoch: 79, i:  3999] avg mini-batch loss: 0.024\n",
      "[epoch: 79, i:  4999] avg mini-batch loss: 0.014\n",
      "[epoch: 79, i:  5999] avg mini-batch loss: 0.022\n",
      "[epoch: 79, i:  6999] avg mini-batch loss: 0.022\n",
      "[epoch: 79, i:  7999] avg mini-batch loss: 0.021\n",
      "[epoch: 79, i:  8999] avg mini-batch loss: 0.028\n",
      "[epoch: 79, i:  9999] avg mini-batch loss: 0.027\n",
      "[epoch: 79, i: 10999] avg mini-batch loss: 0.024\n",
      "[epoch: 79, i: 11999] avg mini-batch loss: 0.018\n",
      "[epoch: 80, i:   999] avg mini-batch loss: 0.021\n",
      "[epoch: 80, i:  1999] avg mini-batch loss: 0.022\n",
      "[epoch: 80, i:  2999] avg mini-batch loss: 0.029\n",
      "[epoch: 80, i:  3999] avg mini-batch loss: 0.028\n",
      "[epoch: 80, i:  4999] avg mini-batch loss: 0.028\n",
      "[epoch: 80, i:  5999] avg mini-batch loss: 0.026\n",
      "[epoch: 80, i:  6999] avg mini-batch loss: 0.022\n",
      "[epoch: 80, i:  7999] avg mini-batch loss: 0.035\n",
      "[epoch: 80, i:  8999] avg mini-batch loss: 0.028\n",
      "[epoch: 80, i:  9999] avg mini-batch loss: 0.030\n",
      "[epoch: 80, i: 10999] avg mini-batch loss: 0.025\n",
      "[epoch: 80, i: 11999] avg mini-batch loss: 0.025\n",
      "[epoch: 81, i:   999] avg mini-batch loss: 0.015\n",
      "[epoch: 81, i:  1999] avg mini-batch loss: 0.015\n",
      "[epoch: 81, i:  2999] avg mini-batch loss: 0.015\n",
      "[epoch: 81, i:  3999] avg mini-batch loss: 0.021\n",
      "[epoch: 81, i:  4999] avg mini-batch loss: 0.027\n",
      "[epoch: 81, i:  5999] avg mini-batch loss: 0.022\n",
      "[epoch: 81, i:  6999] avg mini-batch loss: 0.027\n",
      "[epoch: 81, i:  7999] avg mini-batch loss: 0.032\n",
      "[epoch: 81, i:  8999] avg mini-batch loss: 0.029\n",
      "[epoch: 81, i:  9999] avg mini-batch loss: 0.026\n",
      "[epoch: 81, i: 10999] avg mini-batch loss: 0.018\n",
      "[epoch: 81, i: 11999] avg mini-batch loss: 0.025\n",
      "[epoch: 82, i:   999] avg mini-batch loss: 0.022\n",
      "[epoch: 82, i:  1999] avg mini-batch loss: 0.027\n",
      "[epoch: 82, i:  2999] avg mini-batch loss: 0.029\n",
      "[epoch: 82, i:  3999] avg mini-batch loss: 0.026\n",
      "[epoch: 82, i:  4999] avg mini-batch loss: 0.025\n",
      "[epoch: 82, i:  5999] avg mini-batch loss: 0.036\n",
      "[epoch: 82, i:  6999] avg mini-batch loss: 0.024\n",
      "[epoch: 82, i:  7999] avg mini-batch loss: 0.023\n",
      "[epoch: 82, i:  8999] avg mini-batch loss: 0.020\n",
      "[epoch: 82, i:  9999] avg mini-batch loss: 0.022\n",
      "[epoch: 82, i: 10999] avg mini-batch loss: 0.027\n",
      "[epoch: 82, i: 11999] avg mini-batch loss: 0.024\n",
      "[epoch: 83, i:   999] avg mini-batch loss: 0.018\n",
      "[epoch: 83, i:  1999] avg mini-batch loss: 0.022\n",
      "[epoch: 83, i:  2999] avg mini-batch loss: 0.019\n",
      "[epoch: 83, i:  3999] avg mini-batch loss: 0.021\n",
      "[epoch: 83, i:  4999] avg mini-batch loss: 0.019\n",
      "[epoch: 83, i:  5999] avg mini-batch loss: 0.023\n",
      "[epoch: 83, i:  6999] avg mini-batch loss: 0.021\n",
      "[epoch: 83, i:  7999] avg mini-batch loss: 0.021\n",
      "[epoch: 83, i:  8999] avg mini-batch loss: 0.018\n",
      "[epoch: 83, i:  9999] avg mini-batch loss: 0.017\n",
      "[epoch: 83, i: 10999] avg mini-batch loss: 0.019\n",
      "[epoch: 83, i: 11999] avg mini-batch loss: 0.018\n",
      "[epoch: 84, i:   999] avg mini-batch loss: 0.016\n",
      "[epoch: 84, i:  1999] avg mini-batch loss: 0.017\n",
      "[epoch: 84, i:  2999] avg mini-batch loss: 0.007\n",
      "[epoch: 84, i:  3999] avg mini-batch loss: 0.017\n",
      "[epoch: 84, i:  4999] avg mini-batch loss: 0.018\n",
      "[epoch: 84, i:  5999] avg mini-batch loss: 0.013\n",
      "[epoch: 84, i:  6999] avg mini-batch loss: 0.014\n",
      "[epoch: 84, i:  7999] avg mini-batch loss: 0.009\n",
      "[epoch: 84, i:  8999] avg mini-batch loss: 0.021\n",
      "[epoch: 84, i:  9999] avg mini-batch loss: 0.019\n",
      "[epoch: 84, i: 10999] avg mini-batch loss: 0.015\n",
      "[epoch: 84, i: 11999] avg mini-batch loss: 0.018\n",
      "[epoch: 85, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 85, i:  1999] avg mini-batch loss: 0.020\n",
      "[epoch: 85, i:  2999] avg mini-batch loss: 0.017\n",
      "[epoch: 85, i:  3999] avg mini-batch loss: 0.012\n",
      "[epoch: 85, i:  4999] avg mini-batch loss: 0.015\n",
      "[epoch: 85, i:  5999] avg mini-batch loss: 0.017\n",
      "[epoch: 85, i:  6999] avg mini-batch loss: 0.014\n",
      "[epoch: 85, i:  7999] avg mini-batch loss: 0.021\n",
      "[epoch: 85, i:  8999] avg mini-batch loss: 0.019\n",
      "[epoch: 85, i:  9999] avg mini-batch loss: 0.008\n",
      "[epoch: 85, i: 10999] avg mini-batch loss: 0.016\n",
      "[epoch: 85, i: 11999] avg mini-batch loss: 0.016\n",
      "[epoch: 86, i:   999] avg mini-batch loss: 0.011\n",
      "[epoch: 86, i:  1999] avg mini-batch loss: 0.010\n",
      "[epoch: 86, i:  2999] avg mini-batch loss: 0.016\n",
      "[epoch: 86, i:  3999] avg mini-batch loss: 0.014\n",
      "[epoch: 86, i:  4999] avg mini-batch loss: 0.016\n",
      "[epoch: 86, i:  5999] avg mini-batch loss: 0.015\n",
      "[epoch: 86, i:  6999] avg mini-batch loss: 0.016\n",
      "[epoch: 86, i:  7999] avg mini-batch loss: 0.010\n",
      "[epoch: 86, i:  8999] avg mini-batch loss: 0.019\n",
      "[epoch: 86, i:  9999] avg mini-batch loss: 0.018\n",
      "[epoch: 86, i: 10999] avg mini-batch loss: 0.016\n",
      "[epoch: 86, i: 11999] avg mini-batch loss: 0.024\n",
      "[epoch: 87, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 87, i:  1999] avg mini-batch loss: 0.009\n",
      "[epoch: 87, i:  2999] avg mini-batch loss: 0.017\n",
      "[epoch: 87, i:  3999] avg mini-batch loss: 0.017\n",
      "[epoch: 87, i:  4999] avg mini-batch loss: 0.015\n",
      "[epoch: 87, i:  5999] avg mini-batch loss: 0.015\n",
      "[epoch: 87, i:  6999] avg mini-batch loss: 0.016\n",
      "[epoch: 87, i:  7999] avg mini-batch loss: 0.019\n",
      "[epoch: 87, i:  8999] avg mini-batch loss: 0.021\n",
      "[epoch: 87, i:  9999] avg mini-batch loss: 0.023\n",
      "[epoch: 87, i: 10999] avg mini-batch loss: 0.021\n",
      "[epoch: 87, i: 11999] avg mini-batch loss: 0.032\n",
      "[epoch: 88, i:   999] avg mini-batch loss: 0.018\n",
      "[epoch: 88, i:  1999] avg mini-batch loss: 0.013\n",
      "[epoch: 88, i:  2999] avg mini-batch loss: 0.013\n",
      "[epoch: 88, i:  3999] avg mini-batch loss: 0.011\n",
      "[epoch: 88, i:  4999] avg mini-batch loss: 0.010\n",
      "[epoch: 88, i:  5999] avg mini-batch loss: 0.018\n",
      "[epoch: 88, i:  6999] avg mini-batch loss: 0.017\n",
      "[epoch: 88, i:  7999] avg mini-batch loss: 0.019\n",
      "[epoch: 88, i:  8999] avg mini-batch loss: 0.023\n",
      "[epoch: 88, i:  9999] avg mini-batch loss: 0.023\n",
      "[epoch: 88, i: 10999] avg mini-batch loss: 0.016\n",
      "[epoch: 88, i: 11999] avg mini-batch loss: 0.021\n",
      "[epoch: 89, i:   999] avg mini-batch loss: 0.012\n",
      "[epoch: 89, i:  1999] avg mini-batch loss: 0.012\n",
      "[epoch: 89, i:  2999] avg mini-batch loss: 0.015\n",
      "[epoch: 89, i:  3999] avg mini-batch loss: 0.013\n",
      "[epoch: 89, i:  4999] avg mini-batch loss: 0.015\n",
      "[epoch: 89, i:  5999] avg mini-batch loss: 0.020\n",
      "[epoch: 89, i:  6999] avg mini-batch loss: 0.019\n",
      "[epoch: 89, i:  7999] avg mini-batch loss: 0.024\n",
      "[epoch: 89, i:  8999] avg mini-batch loss: 0.025\n",
      "[epoch: 89, i:  9999] avg mini-batch loss: 0.019\n",
      "[epoch: 89, i: 10999] avg mini-batch loss: 0.026\n",
      "[epoch: 89, i: 11999] avg mini-batch loss: 0.026\n",
      "[epoch: 90, i:   999] avg mini-batch loss: 0.014\n",
      "[epoch: 90, i:  1999] avg mini-batch loss: 0.013\n",
      "[epoch: 90, i:  2999] avg mini-batch loss: 0.013\n",
      "[epoch: 90, i:  3999] avg mini-batch loss: 0.021\n",
      "[epoch: 90, i:  4999] avg mini-batch loss: 0.024\n",
      "[epoch: 90, i:  5999] avg mini-batch loss: 0.027\n",
      "[epoch: 90, i:  6999] avg mini-batch loss: 0.016\n",
      "[epoch: 90, i:  7999] avg mini-batch loss: 0.028\n",
      "[epoch: 90, i:  8999] avg mini-batch loss: 0.020\n",
      "[epoch: 90, i:  9999] avg mini-batch loss: 0.020\n",
      "[epoch: 90, i: 10999] avg mini-batch loss: 0.029\n",
      "[epoch: 90, i: 11999] avg mini-batch loss: 0.025\n",
      "[epoch: 91, i:   999] avg mini-batch loss: 0.015\n",
      "[epoch: 91, i:  1999] avg mini-batch loss: 0.016\n",
      "[epoch: 91, i:  2999] avg mini-batch loss: 0.019\n",
      "[epoch: 91, i:  3999] avg mini-batch loss: 0.018\n",
      "[epoch: 91, i:  4999] avg mini-batch loss: 0.019\n",
      "[epoch: 91, i:  5999] avg mini-batch loss: 0.019\n",
      "[epoch: 91, i:  6999] avg mini-batch loss: 0.013\n",
      "[epoch: 91, i:  7999] avg mini-batch loss: 0.010\n",
      "[epoch: 91, i:  8999] avg mini-batch loss: 0.016\n",
      "[epoch: 91, i:  9999] avg mini-batch loss: 0.018\n",
      "[epoch: 91, i: 10999] avg mini-batch loss: 0.027\n",
      "[epoch: 91, i: 11999] avg mini-batch loss: 0.024\n",
      "[epoch: 92, i:   999] avg mini-batch loss: 0.014\n",
      "[epoch: 92, i:  1999] avg mini-batch loss: 0.019\n",
      "[epoch: 92, i:  2999] avg mini-batch loss: 0.025\n",
      "[epoch: 92, i:  3999] avg mini-batch loss: 0.015\n",
      "[epoch: 92, i:  4999] avg mini-batch loss: 0.022\n",
      "[epoch: 92, i:  5999] avg mini-batch loss: 0.021\n",
      "[epoch: 92, i:  6999] avg mini-batch loss: 0.022\n",
      "[epoch: 92, i:  7999] avg mini-batch loss: 0.023\n",
      "[epoch: 92, i:  8999] avg mini-batch loss: 0.021\n",
      "[epoch: 92, i:  9999] avg mini-batch loss: 0.021\n",
      "[epoch: 92, i: 10999] avg mini-batch loss: 0.023\n",
      "[epoch: 92, i: 11999] avg mini-batch loss: 0.021\n",
      "[epoch: 93, i:   999] avg mini-batch loss: 0.013\n",
      "[epoch: 93, i:  1999] avg mini-batch loss: 0.019\n",
      "[epoch: 93, i:  2999] avg mini-batch loss: 0.013\n",
      "[epoch: 93, i:  3999] avg mini-batch loss: 0.014\n",
      "[epoch: 93, i:  4999] avg mini-batch loss: 0.019\n",
      "[epoch: 93, i:  5999] avg mini-batch loss: 0.015\n",
      "[epoch: 93, i:  6999] avg mini-batch loss: 0.017\n",
      "[epoch: 93, i:  7999] avg mini-batch loss: 0.008\n",
      "[epoch: 93, i:  8999] avg mini-batch loss: 0.018\n",
      "[epoch: 93, i:  9999] avg mini-batch loss: 0.013\n",
      "[epoch: 93, i: 10999] avg mini-batch loss: 0.015\n",
      "[epoch: 93, i: 11999] avg mini-batch loss: 0.014\n",
      "[epoch: 94, i:   999] avg mini-batch loss: 0.021\n",
      "[epoch: 94, i:  1999] avg mini-batch loss: 0.013\n",
      "[epoch: 94, i:  2999] avg mini-batch loss: 0.018\n",
      "[epoch: 94, i:  3999] avg mini-batch loss: 0.021\n",
      "[epoch: 94, i:  4999] avg mini-batch loss: 0.021\n",
      "[epoch: 94, i:  5999] avg mini-batch loss: 0.024\n",
      "[epoch: 94, i:  6999] avg mini-batch loss: 0.015\n",
      "[epoch: 94, i:  7999] avg mini-batch loss: 0.017\n",
      "[epoch: 94, i:  8999] avg mini-batch loss: 0.015\n",
      "[epoch: 94, i:  9999] avg mini-batch loss: 0.016\n",
      "[epoch: 94, i: 10999] avg mini-batch loss: 0.015\n",
      "[epoch: 94, i: 11999] avg mini-batch loss: 0.013\n",
      "[epoch: 95, i:   999] avg mini-batch loss: 0.020\n",
      "[epoch: 95, i:  1999] avg mini-batch loss: 0.014\n",
      "[epoch: 95, i:  2999] avg mini-batch loss: 0.016\n",
      "[epoch: 95, i:  3999] avg mini-batch loss: 0.020\n",
      "[epoch: 95, i:  4999] avg mini-batch loss: 0.019\n",
      "[epoch: 95, i:  5999] avg mini-batch loss: 0.016\n",
      "[epoch: 95, i:  6999] avg mini-batch loss: 0.018\n",
      "[epoch: 95, i:  7999] avg mini-batch loss: 0.020\n",
      "[epoch: 95, i:  8999] avg mini-batch loss: 0.015\n",
      "[epoch: 95, i:  9999] avg mini-batch loss: 0.013\n",
      "[epoch: 95, i: 10999] avg mini-batch loss: 0.012\n",
      "[epoch: 95, i: 11999] avg mini-batch loss: 0.018\n",
      "[epoch: 96, i:   999] avg mini-batch loss: 0.017\n",
      "[epoch: 96, i:  1999] avg mini-batch loss: 0.008\n",
      "[epoch: 96, i:  2999] avg mini-batch loss: 0.021\n",
      "[epoch: 96, i:  3999] avg mini-batch loss: 0.015\n",
      "[epoch: 96, i:  4999] avg mini-batch loss: 0.020\n",
      "[epoch: 96, i:  5999] avg mini-batch loss: 0.017\n",
      "[epoch: 96, i:  6999] avg mini-batch loss: 0.018\n",
      "[epoch: 96, i:  7999] avg mini-batch loss: 0.017\n",
      "[epoch: 96, i:  8999] avg mini-batch loss: 0.018\n",
      "[epoch: 96, i:  9999] avg mini-batch loss: 0.016\n",
      "[epoch: 96, i: 10999] avg mini-batch loss: 0.017\n",
      "[epoch: 96, i: 11999] avg mini-batch loss: 0.020\n",
      "[epoch: 97, i:   999] avg mini-batch loss: 0.015\n",
      "[epoch: 97, i:  1999] avg mini-batch loss: 0.011\n",
      "[epoch: 97, i:  2999] avg mini-batch loss: 0.020\n",
      "[epoch: 97, i:  3999] avg mini-batch loss: 0.026\n",
      "[epoch: 97, i:  4999] avg mini-batch loss: 0.013\n",
      "[epoch: 97, i:  5999] avg mini-batch loss: 0.018\n",
      "[epoch: 97, i:  6999] avg mini-batch loss: 0.022\n",
      "[epoch: 97, i:  7999] avg mini-batch loss: 0.014\n",
      "[epoch: 97, i:  8999] avg mini-batch loss: 0.015\n",
      "[epoch: 97, i:  9999] avg mini-batch loss: 0.018\n",
      "[epoch: 97, i: 10999] avg mini-batch loss: 0.013\n",
      "[epoch: 97, i: 11999] avg mini-batch loss: 0.033\n",
      "[epoch: 98, i:   999] avg mini-batch loss: 0.019\n",
      "[epoch: 98, i:  1999] avg mini-batch loss: 0.018\n",
      "[epoch: 98, i:  2999] avg mini-batch loss: 0.020\n",
      "[epoch: 98, i:  3999] avg mini-batch loss: 0.020\n",
      "[epoch: 98, i:  4999] avg mini-batch loss: 0.017\n",
      "[epoch: 98, i:  5999] avg mini-batch loss: 0.015\n",
      "[epoch: 98, i:  6999] avg mini-batch loss: 0.019\n",
      "[epoch: 98, i:  7999] avg mini-batch loss: 0.029\n",
      "[epoch: 98, i:  8999] avg mini-batch loss: 0.034\n",
      "[epoch: 98, i:  9999] avg mini-batch loss: 0.015\n",
      "[epoch: 98, i: 10999] avg mini-batch loss: 0.018\n",
      "[epoch: 98, i: 11999] avg mini-batch loss: 0.026\n",
      "[epoch: 99, i:   999] avg mini-batch loss: 0.014\n",
      "[epoch: 99, i:  1999] avg mini-batch loss: 0.021\n",
      "[epoch: 99, i:  2999] avg mini-batch loss: 0.013\n",
      "[epoch: 99, i:  3999] avg mini-batch loss: 0.012\n",
      "[epoch: 99, i:  4999] avg mini-batch loss: 0.014\n",
      "[epoch: 99, i:  5999] avg mini-batch loss: 0.020\n",
      "[epoch: 99, i:  6999] avg mini-batch loss: 0.016\n",
      "[epoch: 99, i:  7999] avg mini-batch loss: 0.010\n",
      "[epoch: 99, i:  8999] avg mini-batch loss: 0.022\n",
      "[epoch: 99, i:  9999] avg mini-batch loss: 0.020\n",
      "[epoch: 99, i: 10999] avg mini-batch loss: 0.025\n",
      "[epoch: 99, i: 11999] avg mini-batch loss: 0.016\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 100       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13aa87c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11162f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the X test images: 45 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the X test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
