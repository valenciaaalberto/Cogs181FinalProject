{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f8043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c48cef",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a702576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.RandomResizedCrop(224,antialias=True),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0e50d",
   "metadata": {},
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e6776c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7ed3f",
   "metadata": {},
   "source": [
    "## Modified AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2102b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_layer_one): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
       "  (conv_layer_two): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv_layer_three): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_four): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_five): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  (batchNorm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11 , stride=4, padding=1)\n",
    "        self.conv_layer_two = nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5, stride=1, padding=2)\n",
    "        self.conv_layer_three = nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_four = nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_five = nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(6400, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 1000)\n",
    "        \n",
    "        self.batchNorm1 = nn.BatchNorm2d(3)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(384)\n",
    "  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm1(x)\n",
    "        x = self.conv_layer_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(3,3),stride=2)\n",
    "        \n",
    "        x = self.conv_layer_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(3,3),stride=2)\n",
    "        \n",
    "        x = self.conv_layer_three(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.batchNorm2(x)\n",
    "        x = self.conv_layer_four(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_layer_five(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(3,3),stride=2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)    \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12d8556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71d17361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 5.167\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.579\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 4.409\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 4.316\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 4.259\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 4.187\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 4.143\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 4.067\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 4.040\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 4.024\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 3.951\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 3.909\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 3.854\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 3.853\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 3.806\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 3.800\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 3.734\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 3.739\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 3.683\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 3.719\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 3.700\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 3.667\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 3.599\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 3.634\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 3.532\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 3.548\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 3.540\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 3.506\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 3.452\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 3.385\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 3.402\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 3.457\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 3.416\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 3.377\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 3.382\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 3.359\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 3.260\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 3.264\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 3.245\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 3.257\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 3.229\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 3.219\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 3.253\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 3.224\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 3.214\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 3.195\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 3.134\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 3.067\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 3.031\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 3.059\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 3.051\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 3.048\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 3.016\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 3.042\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 3.031\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 3.015\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 2.957\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 2.983\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 2.973\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 2.965\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 2.866\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 2.896\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 2.833\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 2.855\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 2.865\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 2.855\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 2.829\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 2.862\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 2.877\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 2.815\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 2.842\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 2.848\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 2.700\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 2.712\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 2.701\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 2.749\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 2.693\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 2.760\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 2.735\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 2.715\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 2.687\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 2.699\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 2.684\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 2.784\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 2.548\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 2.646\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 2.559\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 2.626\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 2.583\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 2.559\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 2.582\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 2.541\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 2.608\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 2.563\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 2.565\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 2.584\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 2.439\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 2.511\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 2.475\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 2.509\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 2.505\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 2.470\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 2.517\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 2.534\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 2.498\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 2.483\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 2.469\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 2.478\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 2.366\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 2.386\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 2.336\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 2.390\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 2.364\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 2.403\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 2.405\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 2.426\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 2.418\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 2.410\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 2.378\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 2.405\n",
      "[epoch: 10, i:   999] avg mini-batch loss: 2.224\n",
      "[epoch: 10, i:  1999] avg mini-batch loss: 2.313\n",
      "[epoch: 10, i:  2999] avg mini-batch loss: 2.289\n",
      "[epoch: 10, i:  3999] avg mini-batch loss: 2.289\n",
      "[epoch: 10, i:  4999] avg mini-batch loss: 2.276\n",
      "[epoch: 10, i:  5999] avg mini-batch loss: 2.251\n",
      "[epoch: 10, i:  6999] avg mini-batch loss: 2.307\n",
      "[epoch: 10, i:  7999] avg mini-batch loss: 2.321\n",
      "[epoch: 10, i:  8999] avg mini-batch loss: 2.303\n",
      "[epoch: 10, i:  9999] avg mini-batch loss: 2.293\n",
      "[epoch: 10, i: 10999] avg mini-batch loss: 2.322\n",
      "[epoch: 10, i: 11999] avg mini-batch loss: 2.307\n",
      "[epoch: 11, i:   999] avg mini-batch loss: 2.199\n",
      "[epoch: 11, i:  1999] avg mini-batch loss: 2.163\n",
      "[epoch: 11, i:  2999] avg mini-batch loss: 2.214\n",
      "[epoch: 11, i:  3999] avg mini-batch loss: 2.206\n",
      "[epoch: 11, i:  4999] avg mini-batch loss: 2.188\n",
      "[epoch: 11, i:  5999] avg mini-batch loss: 2.229\n",
      "[epoch: 11, i:  6999] avg mini-batch loss: 2.259\n",
      "[epoch: 11, i:  7999] avg mini-batch loss: 2.238\n",
      "[epoch: 11, i:  8999] avg mini-batch loss: 2.283\n",
      "[epoch: 11, i:  9999] avg mini-batch loss: 2.192\n",
      "[epoch: 11, i: 10999] avg mini-batch loss: 2.233\n",
      "[epoch: 11, i: 11999] avg mini-batch loss: 2.230\n",
      "[epoch: 12, i:   999] avg mini-batch loss: 2.068\n",
      "[epoch: 12, i:  1999] avg mini-batch loss: 2.133\n",
      "[epoch: 12, i:  2999] avg mini-batch loss: 2.091\n",
      "[epoch: 12, i:  3999] avg mini-batch loss: 2.169\n",
      "[epoch: 12, i:  4999] avg mini-batch loss: 2.112\n",
      "[epoch: 12, i:  5999] avg mini-batch loss: 2.146\n",
      "[epoch: 12, i:  6999] avg mini-batch loss: 2.097\n",
      "[epoch: 12, i:  7999] avg mini-batch loss: 2.161\n",
      "[epoch: 12, i:  8999] avg mini-batch loss: 2.167\n",
      "[epoch: 12, i:  9999] avg mini-batch loss: 2.170\n",
      "[epoch: 12, i: 10999] avg mini-batch loss: 2.161\n",
      "[epoch: 12, i: 11999] avg mini-batch loss: 2.130\n",
      "[epoch: 13, i:   999] avg mini-batch loss: 2.118\n",
      "[epoch: 13, i:  1999] avg mini-batch loss: 2.016\n",
      "[epoch: 13, i:  2999] avg mini-batch loss: 2.052\n",
      "[epoch: 13, i:  3999] avg mini-batch loss: 2.078\n",
      "[epoch: 13, i:  4999] avg mini-batch loss: 2.001\n",
      "[epoch: 13, i:  5999] avg mini-batch loss: 2.108\n",
      "[epoch: 13, i:  6999] avg mini-batch loss: 2.104\n",
      "[epoch: 13, i:  7999] avg mini-batch loss: 2.089\n",
      "[epoch: 13, i:  8999] avg mini-batch loss: 2.096\n",
      "[epoch: 13, i:  9999] avg mini-batch loss: 2.092\n",
      "[epoch: 13, i: 10999] avg mini-batch loss: 2.106\n",
      "[epoch: 13, i: 11999] avg mini-batch loss: 2.109\n",
      "[epoch: 14, i:   999] avg mini-batch loss: 1.984\n",
      "[epoch: 14, i:  1999] avg mini-batch loss: 1.956\n",
      "[epoch: 14, i:  2999] avg mini-batch loss: 2.026\n",
      "[epoch: 14, i:  3999] avg mini-batch loss: 1.975\n",
      "[epoch: 14, i:  4999] avg mini-batch loss: 2.024\n",
      "[epoch: 14, i:  5999] avg mini-batch loss: 2.024\n",
      "[epoch: 14, i:  6999] avg mini-batch loss: 2.015\n",
      "[epoch: 14, i:  7999] avg mini-batch loss: 2.007\n",
      "[epoch: 14, i:  8999] avg mini-batch loss: 2.071\n",
      "[epoch: 14, i:  9999] avg mini-batch loss: 2.040\n",
      "[epoch: 14, i: 10999] avg mini-batch loss: 2.055\n",
      "[epoch: 14, i: 11999] avg mini-batch loss: 2.046\n",
      "[epoch: 15, i:   999] avg mini-batch loss: 1.853\n",
      "[epoch: 15, i:  1999] avg mini-batch loss: 1.971\n",
      "[epoch: 15, i:  2999] avg mini-batch loss: 1.961\n",
      "[epoch: 15, i:  3999] avg mini-batch loss: 1.954\n",
      "[epoch: 15, i:  4999] avg mini-batch loss: 1.984\n",
      "[epoch: 15, i:  5999] avg mini-batch loss: 1.929\n",
      "[epoch: 15, i:  6999] avg mini-batch loss: 1.958\n",
      "[epoch: 15, i:  7999] avg mini-batch loss: 1.955\n",
      "[epoch: 15, i:  8999] avg mini-batch loss: 1.965\n",
      "[epoch: 15, i:  9999] avg mini-batch loss: 1.902\n",
      "[epoch: 15, i: 10999] avg mini-batch loss: 2.027\n",
      "[epoch: 15, i: 11999] avg mini-batch loss: 1.965\n",
      "[epoch: 16, i:   999] avg mini-batch loss: 1.873\n",
      "[epoch: 16, i:  1999] avg mini-batch loss: 1.902\n",
      "[epoch: 16, i:  2999] avg mini-batch loss: 1.906\n",
      "[epoch: 16, i:  3999] avg mini-batch loss: 1.857\n",
      "[epoch: 16, i:  4999] avg mini-batch loss: 1.928\n",
      "[epoch: 16, i:  5999] avg mini-batch loss: 1.872\n",
      "[epoch: 16, i:  6999] avg mini-batch loss: 1.898\n",
      "[epoch: 16, i:  7999] avg mini-batch loss: 1.857\n",
      "[epoch: 16, i:  8999] avg mini-batch loss: 1.915\n",
      "[epoch: 16, i:  9999] avg mini-batch loss: 1.933\n",
      "[epoch: 16, i: 10999] avg mini-batch loss: 1.911\n",
      "[epoch: 16, i: 11999] avg mini-batch loss: 1.934\n",
      "[epoch: 17, i:   999] avg mini-batch loss: 1.779\n",
      "[epoch: 17, i:  1999] avg mini-batch loss: 1.842\n",
      "[epoch: 17, i:  2999] avg mini-batch loss: 1.817\n",
      "[epoch: 17, i:  3999] avg mini-batch loss: 1.827\n",
      "[epoch: 17, i:  4999] avg mini-batch loss: 1.792\n",
      "[epoch: 17, i:  5999] avg mini-batch loss: 1.774\n",
      "[epoch: 17, i:  6999] avg mini-batch loss: 1.839\n",
      "[epoch: 17, i:  7999] avg mini-batch loss: 1.838\n",
      "[epoch: 17, i:  8999] avg mini-batch loss: 1.857\n",
      "[epoch: 17, i:  9999] avg mini-batch loss: 1.863\n",
      "[epoch: 17, i: 10999] avg mini-batch loss: 1.934\n",
      "[epoch: 17, i: 11999] avg mini-batch loss: 1.855\n",
      "[epoch: 18, i:   999] avg mini-batch loss: 1.740\n",
      "[epoch: 18, i:  1999] avg mini-batch loss: 1.739\n",
      "[epoch: 18, i:  2999] avg mini-batch loss: 1.714\n",
      "[epoch: 18, i:  3999] avg mini-batch loss: 1.767\n",
      "[epoch: 18, i:  4999] avg mini-batch loss: 1.751\n",
      "[epoch: 18, i:  5999] avg mini-batch loss: 1.770\n",
      "[epoch: 18, i:  6999] avg mini-batch loss: 1.765\n",
      "[epoch: 18, i:  7999] avg mini-batch loss: 1.799\n",
      "[epoch: 18, i:  8999] avg mini-batch loss: 1.822\n",
      "[epoch: 18, i:  9999] avg mini-batch loss: 1.782\n",
      "[epoch: 18, i: 10999] avg mini-batch loss: 1.816\n",
      "[epoch: 18, i: 11999] avg mini-batch loss: 1.858\n",
      "[epoch: 19, i:   999] avg mini-batch loss: 1.659\n",
      "[epoch: 19, i:  1999] avg mini-batch loss: 1.677\n",
      "[epoch: 19, i:  2999] avg mini-batch loss: 1.726\n",
      "[epoch: 19, i:  3999] avg mini-batch loss: 1.785\n",
      "[epoch: 19, i:  4999] avg mini-batch loss: 1.695\n",
      "[epoch: 19, i:  5999] avg mini-batch loss: 1.676\n",
      "[epoch: 19, i:  6999] avg mini-batch loss: 1.737\n",
      "[epoch: 19, i:  7999] avg mini-batch loss: 1.710\n",
      "[epoch: 19, i:  8999] avg mini-batch loss: 1.735\n",
      "[epoch: 19, i:  9999] avg mini-batch loss: 1.794\n",
      "[epoch: 19, i: 10999] avg mini-batch loss: 1.726\n",
      "[epoch: 19, i: 11999] avg mini-batch loss: 1.770\n",
      "[epoch: 20, i:   999] avg mini-batch loss: 1.670\n",
      "[epoch: 20, i:  1999] avg mini-batch loss: 1.624\n",
      "[epoch: 20, i:  2999] avg mini-batch loss: 1.629\n",
      "[epoch: 20, i:  3999] avg mini-batch loss: 1.656\n",
      "[epoch: 20, i:  4999] avg mini-batch loss: 1.653\n",
      "[epoch: 20, i:  5999] avg mini-batch loss: 1.667\n",
      "[epoch: 20, i:  6999] avg mini-batch loss: 1.745\n",
      "[epoch: 20, i:  7999] avg mini-batch loss: 1.661\n",
      "[epoch: 20, i:  8999] avg mini-batch loss: 1.680\n",
      "[epoch: 20, i:  9999] avg mini-batch loss: 1.637\n",
      "[epoch: 20, i: 10999] avg mini-batch loss: 1.724\n",
      "[epoch: 20, i: 11999] avg mini-batch loss: 1.709\n",
      "[epoch: 21, i:   999] avg mini-batch loss: 1.638\n",
      "[epoch: 21, i:  1999] avg mini-batch loss: 1.593\n",
      "[epoch: 21, i:  2999] avg mini-batch loss: 1.629\n",
      "[epoch: 21, i:  3999] avg mini-batch loss: 1.641\n",
      "[epoch: 21, i:  4999] avg mini-batch loss: 1.649\n",
      "[epoch: 21, i:  5999] avg mini-batch loss: 1.629\n",
      "[epoch: 21, i:  6999] avg mini-batch loss: 1.658\n",
      "[epoch: 21, i:  7999] avg mini-batch loss: 1.635\n",
      "[epoch: 21, i:  8999] avg mini-batch loss: 1.685\n",
      "[epoch: 21, i:  9999] avg mini-batch loss: 1.638\n",
      "[epoch: 21, i: 10999] avg mini-batch loss: 1.709\n",
      "[epoch: 21, i: 11999] avg mini-batch loss: 1.687\n",
      "[epoch: 22, i:   999] avg mini-batch loss: 1.593\n",
      "[epoch: 22, i:  1999] avg mini-batch loss: 1.559\n",
      "[epoch: 22, i:  2999] avg mini-batch loss: 1.626\n",
      "[epoch: 22, i:  3999] avg mini-batch loss: 1.606\n",
      "[epoch: 22, i:  4999] avg mini-batch loss: 1.564\n",
      "[epoch: 22, i:  5999] avg mini-batch loss: 1.594\n",
      "[epoch: 22, i:  6999] avg mini-batch loss: 1.532\n",
      "[epoch: 22, i:  7999] avg mini-batch loss: 1.631\n",
      "[epoch: 22, i:  8999] avg mini-batch loss: 1.596\n",
      "[epoch: 22, i:  9999] avg mini-batch loss: 1.674\n",
      "[epoch: 22, i: 10999] avg mini-batch loss: 1.596\n",
      "[epoch: 22, i: 11999] avg mini-batch loss: 1.602\n",
      "[epoch: 23, i:   999] avg mini-batch loss: 1.518\n",
      "[epoch: 23, i:  1999] avg mini-batch loss: 1.590\n",
      "[epoch: 23, i:  2999] avg mini-batch loss: 1.571\n",
      "[epoch: 23, i:  3999] avg mini-batch loss: 1.587\n",
      "[epoch: 23, i:  4999] avg mini-batch loss: 1.578\n",
      "[epoch: 23, i:  5999] avg mini-batch loss: 1.613\n",
      "[epoch: 23, i:  6999] avg mini-batch loss: 1.528\n",
      "[epoch: 23, i:  7999] avg mini-batch loss: 1.599\n",
      "[epoch: 23, i:  8999] avg mini-batch loss: 1.611\n",
      "[epoch: 23, i:  9999] avg mini-batch loss: 1.570\n",
      "[epoch: 23, i: 10999] avg mini-batch loss: 1.573\n",
      "[epoch: 23, i: 11999] avg mini-batch loss: 1.573\n",
      "[epoch: 24, i:   999] avg mini-batch loss: 1.466\n",
      "[epoch: 24, i:  1999] avg mini-batch loss: 1.516\n",
      "[epoch: 24, i:  2999] avg mini-batch loss: 1.463\n",
      "[epoch: 24, i:  3999] avg mini-batch loss: 1.595\n",
      "[epoch: 24, i:  4999] avg mini-batch loss: 1.542\n",
      "[epoch: 24, i:  5999] avg mini-batch loss: 1.583\n",
      "[epoch: 24, i:  6999] avg mini-batch loss: 1.548\n",
      "[epoch: 24, i:  7999] avg mini-batch loss: 1.589\n",
      "[epoch: 24, i:  8999] avg mini-batch loss: 1.503\n",
      "[epoch: 24, i:  9999] avg mini-batch loss: 1.544\n",
      "[epoch: 24, i: 10999] avg mini-batch loss: 1.578\n",
      "[epoch: 24, i: 11999] avg mini-batch loss: 1.586\n",
      "[epoch: 25, i:   999] avg mini-batch loss: 1.477\n",
      "[epoch: 25, i:  1999] avg mini-batch loss: 1.464\n",
      "[epoch: 25, i:  2999] avg mini-batch loss: 1.508\n",
      "[epoch: 25, i:  3999] avg mini-batch loss: 1.509\n",
      "[epoch: 25, i:  4999] avg mini-batch loss: 1.485\n",
      "[epoch: 25, i:  5999] avg mini-batch loss: 1.476\n",
      "[epoch: 25, i:  6999] avg mini-batch loss: 1.537\n",
      "[epoch: 25, i:  7999] avg mini-batch loss: 1.550\n",
      "[epoch: 25, i:  8999] avg mini-batch loss: 1.470\n",
      "[epoch: 25, i:  9999] avg mini-batch loss: 1.567\n",
      "[epoch: 25, i: 10999] avg mini-batch loss: 1.605\n",
      "[epoch: 25, i: 11999] avg mini-batch loss: 1.556\n",
      "[epoch: 26, i:   999] avg mini-batch loss: 1.447\n",
      "[epoch: 26, i:  1999] avg mini-batch loss: 1.454\n",
      "[epoch: 26, i:  2999] avg mini-batch loss: 1.479\n",
      "[epoch: 26, i:  3999] avg mini-batch loss: 1.473\n",
      "[epoch: 26, i:  4999] avg mini-batch loss: 1.487\n",
      "[epoch: 26, i:  5999] avg mini-batch loss: 1.453\n",
      "[epoch: 26, i:  6999] avg mini-batch loss: 1.478\n",
      "[epoch: 26, i:  7999] avg mini-batch loss: 1.475\n",
      "[epoch: 26, i:  8999] avg mini-batch loss: 1.453\n",
      "[epoch: 26, i:  9999] avg mini-batch loss: 1.509\n",
      "[epoch: 26, i: 10999] avg mini-batch loss: 1.532\n",
      "[epoch: 26, i: 11999] avg mini-batch loss: 1.521\n",
      "[epoch: 27, i:   999] avg mini-batch loss: 1.388\n",
      "[epoch: 27, i:  1999] avg mini-batch loss: 1.401\n",
      "[epoch: 27, i:  2999] avg mini-batch loss: 1.403\n",
      "[epoch: 27, i:  3999] avg mini-batch loss: 1.418\n",
      "[epoch: 27, i:  4999] avg mini-batch loss: 1.469\n",
      "[epoch: 27, i:  5999] avg mini-batch loss: 1.476\n",
      "[epoch: 27, i:  6999] avg mini-batch loss: 1.436\n",
      "[epoch: 27, i:  7999] avg mini-batch loss: 1.427\n",
      "[epoch: 27, i:  8999] avg mini-batch loss: 1.418\n",
      "[epoch: 27, i:  9999] avg mini-batch loss: 1.424\n",
      "[epoch: 27, i: 10999] avg mini-batch loss: 1.451\n",
      "[epoch: 27, i: 11999] avg mini-batch loss: 1.488\n",
      "[epoch: 28, i:   999] avg mini-batch loss: 1.374\n",
      "[epoch: 28, i:  1999] avg mini-batch loss: 1.453\n",
      "[epoch: 28, i:  2999] avg mini-batch loss: 1.375\n",
      "[epoch: 28, i:  3999] avg mini-batch loss: 1.409\n",
      "[epoch: 28, i:  4999] avg mini-batch loss: 1.379\n",
      "[epoch: 28, i:  5999] avg mini-batch loss: 1.379\n",
      "[epoch: 28, i:  6999] avg mini-batch loss: 1.420\n",
      "[epoch: 28, i:  7999] avg mini-batch loss: 1.464\n",
      "[epoch: 28, i:  8999] avg mini-batch loss: 1.452\n",
      "[epoch: 28, i:  9999] avg mini-batch loss: 1.412\n",
      "[epoch: 28, i: 10999] avg mini-batch loss: 1.490\n",
      "[epoch: 28, i: 11999] avg mini-batch loss: 1.435\n",
      "[epoch: 29, i:   999] avg mini-batch loss: 1.369\n",
      "[epoch: 29, i:  1999] avg mini-batch loss: 1.395\n",
      "[epoch: 29, i:  2999] avg mini-batch loss: 1.376\n",
      "[epoch: 29, i:  3999] avg mini-batch loss: 1.367\n",
      "[epoch: 29, i:  4999] avg mini-batch loss: 1.448\n",
      "[epoch: 29, i:  5999] avg mini-batch loss: 1.392\n",
      "[epoch: 29, i:  6999] avg mini-batch loss: 1.392\n",
      "[epoch: 29, i:  7999] avg mini-batch loss: 1.387\n",
      "[epoch: 29, i:  8999] avg mini-batch loss: 1.423\n",
      "[epoch: 29, i:  9999] avg mini-batch loss: 1.430\n",
      "[epoch: 29, i: 10999] avg mini-batch loss: 1.356\n",
      "[epoch: 29, i: 11999] avg mini-batch loss: 1.448\n",
      "[epoch: 30, i:   999] avg mini-batch loss: 1.373\n",
      "[epoch: 30, i:  1999] avg mini-batch loss: 1.326\n",
      "[epoch: 30, i:  2999] avg mini-batch loss: 1.418\n",
      "[epoch: 30, i:  3999] avg mini-batch loss: 1.415\n",
      "[epoch: 30, i:  4999] avg mini-batch loss: 1.374\n",
      "[epoch: 30, i:  5999] avg mini-batch loss: 1.374\n",
      "[epoch: 30, i:  6999] avg mini-batch loss: 1.377\n",
      "[epoch: 30, i:  7999] avg mini-batch loss: 1.415\n",
      "[epoch: 30, i:  8999] avg mini-batch loss: 1.394\n",
      "[epoch: 30, i:  9999] avg mini-batch loss: 1.387\n",
      "[epoch: 30, i: 10999] avg mini-batch loss: 1.378\n",
      "[epoch: 30, i: 11999] avg mini-batch loss: 1.369\n",
      "[epoch: 31, i:   999] avg mini-batch loss: 1.324\n",
      "[epoch: 31, i:  1999] avg mini-batch loss: 1.314\n",
      "[epoch: 31, i:  2999] avg mini-batch loss: 1.301\n",
      "[epoch: 31, i:  3999] avg mini-batch loss: 1.337\n",
      "[epoch: 31, i:  4999] avg mini-batch loss: 1.333\n",
      "[epoch: 31, i:  5999] avg mini-batch loss: 1.365\n",
      "[epoch: 31, i:  6999] avg mini-batch loss: 1.396\n",
      "[epoch: 31, i:  7999] avg mini-batch loss: 1.357\n",
      "[epoch: 31, i:  8999] avg mini-batch loss: 1.359\n",
      "[epoch: 31, i:  9999] avg mini-batch loss: 1.388\n",
      "[epoch: 31, i: 10999] avg mini-batch loss: 1.385\n",
      "[epoch: 31, i: 11999] avg mini-batch loss: 1.386\n",
      "[epoch: 32, i:   999] avg mini-batch loss: 1.270\n",
      "[epoch: 32, i:  1999] avg mini-batch loss: 1.320\n",
      "[epoch: 32, i:  2999] avg mini-batch loss: 1.305\n",
      "[epoch: 32, i:  3999] avg mini-batch loss: 1.283\n",
      "[epoch: 32, i:  4999] avg mini-batch loss: 1.298\n",
      "[epoch: 32, i:  5999] avg mini-batch loss: 1.288\n",
      "[epoch: 32, i:  6999] avg mini-batch loss: 1.361\n",
      "[epoch: 32, i:  7999] avg mini-batch loss: 1.345\n",
      "[epoch: 32, i:  8999] avg mini-batch loss: 1.340\n",
      "[epoch: 32, i:  9999] avg mini-batch loss: 1.344\n",
      "[epoch: 32, i: 10999] avg mini-batch loss: 1.360\n",
      "[epoch: 32, i: 11999] avg mini-batch loss: 1.323\n",
      "[epoch: 33, i:   999] avg mini-batch loss: 1.268\n",
      "[epoch: 33, i:  1999] avg mini-batch loss: 1.275\n",
      "[epoch: 33, i:  2999] avg mini-batch loss: 1.305\n",
      "[epoch: 33, i:  3999] avg mini-batch loss: 1.300\n",
      "[epoch: 33, i:  4999] avg mini-batch loss: 1.398\n",
      "[epoch: 33, i:  5999] avg mini-batch loss: 1.297\n",
      "[epoch: 33, i:  6999] avg mini-batch loss: 1.234\n",
      "[epoch: 33, i:  7999] avg mini-batch loss: 1.309\n",
      "[epoch: 33, i:  8999] avg mini-batch loss: 1.372\n",
      "[epoch: 33, i:  9999] avg mini-batch loss: 1.344\n",
      "[epoch: 33, i: 10999] avg mini-batch loss: 1.365\n",
      "[epoch: 33, i: 11999] avg mini-batch loss: 1.378\n",
      "[epoch: 34, i:   999] avg mini-batch loss: 1.302\n",
      "[epoch: 34, i:  1999] avg mini-batch loss: 1.265\n",
      "[epoch: 34, i:  2999] avg mini-batch loss: 1.309\n",
      "[epoch: 34, i:  3999] avg mini-batch loss: 1.297\n",
      "[epoch: 34, i:  4999] avg mini-batch loss: 1.238\n",
      "[epoch: 34, i:  5999] avg mini-batch loss: 1.299\n",
      "[epoch: 34, i:  6999] avg mini-batch loss: 1.297\n",
      "[epoch: 34, i:  7999] avg mini-batch loss: 1.338\n",
      "[epoch: 34, i:  8999] avg mini-batch loss: 1.358\n",
      "[epoch: 34, i:  9999] avg mini-batch loss: 1.285\n",
      "[epoch: 34, i: 10999] avg mini-batch loss: 1.343\n",
      "[epoch: 34, i: 11999] avg mini-batch loss: 1.325\n",
      "[epoch: 35, i:   999] avg mini-batch loss: 1.250\n",
      "[epoch: 35, i:  1999] avg mini-batch loss: 1.305\n",
      "[epoch: 35, i:  2999] avg mini-batch loss: 1.323\n",
      "[epoch: 35, i:  3999] avg mini-batch loss: 1.249\n",
      "[epoch: 35, i:  4999] avg mini-batch loss: 1.302\n",
      "[epoch: 35, i:  5999] avg mini-batch loss: 1.272\n",
      "[epoch: 35, i:  6999] avg mini-batch loss: 1.303\n",
      "[epoch: 35, i:  7999] avg mini-batch loss: 1.251\n",
      "[epoch: 35, i:  8999] avg mini-batch loss: 1.279\n",
      "[epoch: 35, i:  9999] avg mini-batch loss: 1.295\n",
      "[epoch: 35, i: 10999] avg mini-batch loss: 1.323\n",
      "[epoch: 35, i: 11999] avg mini-batch loss: 1.301\n",
      "[epoch: 36, i:   999] avg mini-batch loss: 1.213\n",
      "[epoch: 36, i:  1999] avg mini-batch loss: 1.233\n",
      "[epoch: 36, i:  2999] avg mini-batch loss: 1.251\n",
      "[epoch: 36, i:  3999] avg mini-batch loss: 1.354\n",
      "[epoch: 36, i:  4999] avg mini-batch loss: 1.245\n",
      "[epoch: 36, i:  5999] avg mini-batch loss: 1.262\n",
      "[epoch: 36, i:  6999] avg mini-batch loss: 1.268\n",
      "[epoch: 36, i:  7999] avg mini-batch loss: 1.259\n",
      "[epoch: 36, i:  8999] avg mini-batch loss: 1.273\n",
      "[epoch: 36, i:  9999] avg mini-batch loss: 1.324\n",
      "[epoch: 36, i: 10999] avg mini-batch loss: 1.280\n",
      "[epoch: 36, i: 11999] avg mini-batch loss: 1.287\n",
      "[epoch: 37, i:   999] avg mini-batch loss: 1.210\n",
      "[epoch: 37, i:  1999] avg mini-batch loss: 1.272\n",
      "[epoch: 37, i:  2999] avg mini-batch loss: 1.290\n",
      "[epoch: 37, i:  3999] avg mini-batch loss: 1.277\n",
      "[epoch: 37, i:  4999] avg mini-batch loss: 1.222\n",
      "[epoch: 37, i:  5999] avg mini-batch loss: 1.273\n",
      "[epoch: 37, i:  6999] avg mini-batch loss: 1.318\n",
      "[epoch: 37, i:  7999] avg mini-batch loss: 1.257\n",
      "[epoch: 37, i:  8999] avg mini-batch loss: 1.265\n",
      "[epoch: 37, i:  9999] avg mini-batch loss: 1.282\n",
      "[epoch: 37, i: 10999] avg mini-batch loss: 1.274\n",
      "[epoch: 37, i: 11999] avg mini-batch loss: 1.308\n",
      "[epoch: 38, i:   999] avg mini-batch loss: 1.231\n",
      "[epoch: 38, i:  1999] avg mini-batch loss: 1.239\n",
      "[epoch: 38, i:  2999] avg mini-batch loss: 1.277\n",
      "[epoch: 38, i:  3999] avg mini-batch loss: 1.188\n",
      "[epoch: 38, i:  4999] avg mini-batch loss: 1.200\n",
      "[epoch: 38, i:  5999] avg mini-batch loss: 1.245\n",
      "[epoch: 38, i:  6999] avg mini-batch loss: 1.212\n",
      "[epoch: 38, i:  7999] avg mini-batch loss: 1.275\n",
      "[epoch: 38, i:  8999] avg mini-batch loss: 1.261\n",
      "[epoch: 38, i:  9999] avg mini-batch loss: 1.210\n",
      "[epoch: 38, i: 10999] avg mini-batch loss: 1.307\n",
      "[epoch: 38, i: 11999] avg mini-batch loss: 1.319\n",
      "[epoch: 39, i:   999] avg mini-batch loss: 1.157\n",
      "[epoch: 39, i:  1999] avg mini-batch loss: 1.239\n",
      "[epoch: 39, i:  2999] avg mini-batch loss: 1.178\n",
      "[epoch: 39, i:  3999] avg mini-batch loss: 1.185\n",
      "[epoch: 39, i:  4999] avg mini-batch loss: 1.218\n",
      "[epoch: 39, i:  5999] avg mini-batch loss: 1.258\n",
      "[epoch: 39, i:  6999] avg mini-batch loss: 1.212\n",
      "[epoch: 39, i:  7999] avg mini-batch loss: 1.237\n",
      "[epoch: 39, i:  8999] avg mini-batch loss: 1.250\n",
      "[epoch: 39, i:  9999] avg mini-batch loss: 1.263\n",
      "[epoch: 39, i: 10999] avg mini-batch loss: 1.208\n",
      "[epoch: 39, i: 11999] avg mini-batch loss: 1.217\n",
      "[epoch: 40, i:   999] avg mini-batch loss: 1.145\n",
      "[epoch: 40, i:  1999] avg mini-batch loss: 1.196\n",
      "[epoch: 40, i:  2999] avg mini-batch loss: 1.182\n",
      "[epoch: 40, i:  3999] avg mini-batch loss: 1.213\n",
      "[epoch: 40, i:  4999] avg mini-batch loss: 1.207\n",
      "[epoch: 40, i:  5999] avg mini-batch loss: 1.216\n",
      "[epoch: 40, i:  6999] avg mini-batch loss: 1.183\n",
      "[epoch: 40, i:  7999] avg mini-batch loss: 1.241\n",
      "[epoch: 40, i:  8999] avg mini-batch loss: 1.234\n",
      "[epoch: 40, i:  9999] avg mini-batch loss: 1.208\n",
      "[epoch: 40, i: 10999] avg mini-batch loss: 1.237\n",
      "[epoch: 40, i: 11999] avg mini-batch loss: 1.263\n",
      "[epoch: 41, i:   999] avg mini-batch loss: 1.170\n",
      "[epoch: 41, i:  1999] avg mini-batch loss: 1.191\n",
      "[epoch: 41, i:  2999] avg mini-batch loss: 1.159\n",
      "[epoch: 41, i:  3999] avg mini-batch loss: 1.229\n",
      "[epoch: 41, i:  4999] avg mini-batch loss: 1.225\n",
      "[epoch: 41, i:  5999] avg mini-batch loss: 1.208\n",
      "[epoch: 41, i:  6999] avg mini-batch loss: 1.220\n",
      "[epoch: 41, i:  7999] avg mini-batch loss: 1.214\n",
      "[epoch: 41, i:  8999] avg mini-batch loss: 1.249\n",
      "[epoch: 41, i:  9999] avg mini-batch loss: 1.205\n",
      "[epoch: 41, i: 10999] avg mini-batch loss: 1.236\n",
      "[epoch: 41, i: 11999] avg mini-batch loss: 1.251\n",
      "[epoch: 42, i:   999] avg mini-batch loss: 1.174\n",
      "[epoch: 42, i:  1999] avg mini-batch loss: 1.140\n",
      "[epoch: 42, i:  2999] avg mini-batch loss: 1.180\n",
      "[epoch: 42, i:  3999] avg mini-batch loss: 1.208\n",
      "[epoch: 42, i:  4999] avg mini-batch loss: 1.198\n",
      "[epoch: 42, i:  5999] avg mini-batch loss: 1.203\n",
      "[epoch: 42, i:  6999] avg mini-batch loss: 1.254\n",
      "[epoch: 42, i:  7999] avg mini-batch loss: 1.240\n",
      "[epoch: 42, i:  8999] avg mini-batch loss: 1.184\n",
      "[epoch: 42, i:  9999] avg mini-batch loss: 1.177\n",
      "[epoch: 42, i: 10999] avg mini-batch loss: 1.224\n",
      "[epoch: 42, i: 11999] avg mini-batch loss: 1.200\n",
      "[epoch: 43, i:   999] avg mini-batch loss: 1.093\n",
      "[epoch: 43, i:  1999] avg mini-batch loss: 1.155\n",
      "[epoch: 43, i:  2999] avg mini-batch loss: 1.172\n",
      "[epoch: 43, i:  3999] avg mini-batch loss: 1.176\n",
      "[epoch: 43, i:  4999] avg mini-batch loss: 1.179\n",
      "[epoch: 43, i:  5999] avg mini-batch loss: 1.221\n",
      "[epoch: 43, i:  6999] avg mini-batch loss: 1.167\n",
      "[epoch: 43, i:  7999] avg mini-batch loss: 1.192\n",
      "[epoch: 43, i:  8999] avg mini-batch loss: 1.201\n",
      "[epoch: 43, i:  9999] avg mini-batch loss: 1.218\n",
      "[epoch: 43, i: 10999] avg mini-batch loss: 1.228\n",
      "[epoch: 43, i: 11999] avg mini-batch loss: 1.180\n",
      "[epoch: 44, i:   999] avg mini-batch loss: 1.136\n",
      "[epoch: 44, i:  1999] avg mini-batch loss: 1.157\n",
      "[epoch: 44, i:  2999] avg mini-batch loss: 1.226\n",
      "[epoch: 44, i:  3999] avg mini-batch loss: 1.185\n",
      "[epoch: 44, i:  4999] avg mini-batch loss: 1.173\n",
      "[epoch: 44, i:  5999] avg mini-batch loss: 1.157\n",
      "[epoch: 44, i:  6999] avg mini-batch loss: 1.228\n",
      "[epoch: 44, i:  7999] avg mini-batch loss: 1.174\n",
      "[epoch: 44, i:  8999] avg mini-batch loss: 1.122\n",
      "[epoch: 44, i:  9999] avg mini-batch loss: 1.143\n",
      "[epoch: 44, i: 10999] avg mini-batch loss: 1.205\n",
      "[epoch: 44, i: 11999] avg mini-batch loss: 1.135\n",
      "[epoch: 45, i:   999] avg mini-batch loss: 1.095\n",
      "[epoch: 45, i:  1999] avg mini-batch loss: 1.146\n",
      "[epoch: 45, i:  2999] avg mini-batch loss: 1.189\n",
      "[epoch: 45, i:  3999] avg mini-batch loss: 1.194\n",
      "[epoch: 45, i:  4999] avg mini-batch loss: 1.183\n",
      "[epoch: 45, i:  5999] avg mini-batch loss: 1.180\n",
      "[epoch: 45, i:  6999] avg mini-batch loss: 1.151\n",
      "[epoch: 45, i:  7999] avg mini-batch loss: 1.185\n",
      "[epoch: 45, i:  8999] avg mini-batch loss: 1.116\n",
      "[epoch: 45, i:  9999] avg mini-batch loss: 1.177\n",
      "[epoch: 45, i: 10999] avg mini-batch loss: 1.240\n",
      "[epoch: 45, i: 11999] avg mini-batch loss: 1.265\n",
      "[epoch: 46, i:   999] avg mini-batch loss: 1.098\n",
      "[epoch: 46, i:  1999] avg mini-batch loss: 1.154\n",
      "[epoch: 46, i:  2999] avg mini-batch loss: 1.169\n",
      "[epoch: 46, i:  3999] avg mini-batch loss: 1.125\n",
      "[epoch: 46, i:  4999] avg mini-batch loss: 1.141\n",
      "[epoch: 46, i:  5999] avg mini-batch loss: 1.133\n",
      "[epoch: 46, i:  6999] avg mini-batch loss: 1.159\n",
      "[epoch: 46, i:  7999] avg mini-batch loss: 1.140\n",
      "[epoch: 46, i:  8999] avg mini-batch loss: 1.161\n",
      "[epoch: 46, i:  9999] avg mini-batch loss: 1.252\n",
      "[epoch: 46, i: 10999] avg mini-batch loss: 1.192\n",
      "[epoch: 46, i: 11999] avg mini-batch loss: 1.168\n",
      "[epoch: 47, i:   999] avg mini-batch loss: 1.119\n",
      "[epoch: 47, i:  1999] avg mini-batch loss: 1.099\n",
      "[epoch: 47, i:  2999] avg mini-batch loss: 1.154\n",
      "[epoch: 47, i:  3999] avg mini-batch loss: 1.146\n",
      "[epoch: 47, i:  4999] avg mini-batch loss: 1.174\n",
      "[epoch: 47, i:  5999] avg mini-batch loss: 1.136\n",
      "[epoch: 47, i:  6999] avg mini-batch loss: 1.176\n",
      "[epoch: 47, i:  7999] avg mini-batch loss: 1.189\n",
      "[epoch: 47, i:  8999] avg mini-batch loss: 1.182\n",
      "[epoch: 47, i:  9999] avg mini-batch loss: 1.165\n",
      "[epoch: 47, i: 10999] avg mini-batch loss: 1.155\n",
      "[epoch: 47, i: 11999] avg mini-batch loss: 1.146\n",
      "[epoch: 48, i:   999] avg mini-batch loss: 1.094\n",
      "[epoch: 48, i:  1999] avg mini-batch loss: 1.122\n",
      "[epoch: 48, i:  2999] avg mini-batch loss: 1.178\n",
      "[epoch: 48, i:  3999] avg mini-batch loss: 1.112\n",
      "[epoch: 48, i:  4999] avg mini-batch loss: 1.145\n",
      "[epoch: 48, i:  5999] avg mini-batch loss: 1.182\n",
      "[epoch: 48, i:  6999] avg mini-batch loss: 1.164\n",
      "[epoch: 48, i:  7999] avg mini-batch loss: 1.129\n",
      "[epoch: 48, i:  8999] avg mini-batch loss: 1.138\n",
      "[epoch: 48, i:  9999] avg mini-batch loss: 1.179\n",
      "[epoch: 48, i: 10999] avg mini-batch loss: 1.226\n",
      "[epoch: 48, i: 11999] avg mini-batch loss: 1.078\n",
      "[epoch: 49, i:   999] avg mini-batch loss: 1.106\n",
      "[epoch: 49, i:  1999] avg mini-batch loss: 1.109\n",
      "[epoch: 49, i:  2999] avg mini-batch loss: 1.092\n",
      "[epoch: 49, i:  3999] avg mini-batch loss: 1.138\n",
      "[epoch: 49, i:  4999] avg mini-batch loss: 1.151\n",
      "[epoch: 49, i:  5999] avg mini-batch loss: 1.126\n",
      "[epoch: 49, i:  6999] avg mini-batch loss: 1.112\n",
      "[epoch: 49, i:  7999] avg mini-batch loss: 1.099\n",
      "[epoch: 49, i:  8999] avg mini-batch loss: 1.155\n",
      "[epoch: 49, i:  9999] avg mini-batch loss: 1.154\n",
      "[epoch: 49, i: 10999] avg mini-batch loss: 1.160\n",
      "[epoch: 49, i: 11999] avg mini-batch loss: 1.177\n",
      "[epoch: 50, i:   999] avg mini-batch loss: 1.092\n",
      "[epoch: 50, i:  1999] avg mini-batch loss: 1.052\n",
      "[epoch: 50, i:  2999] avg mini-batch loss: 1.136\n",
      "[epoch: 50, i:  3999] avg mini-batch loss: 1.148\n",
      "[epoch: 50, i:  4999] avg mini-batch loss: 1.092\n",
      "[epoch: 50, i:  5999] avg mini-batch loss: 1.144\n",
      "[epoch: 50, i:  6999] avg mini-batch loss: 1.134\n",
      "[epoch: 50, i:  7999] avg mini-batch loss: 1.148\n",
      "[epoch: 50, i:  8999] avg mini-batch loss: 1.098\n",
      "[epoch: 50, i:  9999] avg mini-batch loss: 1.156\n",
      "[epoch: 50, i: 10999] avg mini-batch loss: 1.159\n",
      "[epoch: 50, i: 11999] avg mini-batch loss: 1.083\n",
      "[epoch: 51, i:   999] avg mini-batch loss: 1.149\n",
      "[epoch: 51, i:  1999] avg mini-batch loss: 1.112\n",
      "[epoch: 51, i:  2999] avg mini-batch loss: 1.123\n",
      "[epoch: 51, i:  3999] avg mini-batch loss: 1.067\n",
      "[epoch: 51, i:  4999] avg mini-batch loss: 1.120\n",
      "[epoch: 51, i:  5999] avg mini-batch loss: 1.057\n",
      "[epoch: 51, i:  6999] avg mini-batch loss: 1.114\n",
      "[epoch: 51, i:  7999] avg mini-batch loss: 1.128\n",
      "[epoch: 51, i:  8999] avg mini-batch loss: 1.201\n",
      "[epoch: 51, i:  9999] avg mini-batch loss: 1.130\n",
      "[epoch: 51, i: 10999] avg mini-batch loss: 1.118\n",
      "[epoch: 51, i: 11999] avg mini-batch loss: 1.103\n",
      "[epoch: 52, i:   999] avg mini-batch loss: 1.062\n",
      "[epoch: 52, i:  1999] avg mini-batch loss: 1.097\n",
      "[epoch: 52, i:  2999] avg mini-batch loss: 1.065\n",
      "[epoch: 52, i:  3999] avg mini-batch loss: 1.092\n",
      "[epoch: 52, i:  4999] avg mini-batch loss: 1.134\n",
      "[epoch: 52, i:  5999] avg mini-batch loss: 1.105\n",
      "[epoch: 52, i:  6999] avg mini-batch loss: 1.146\n",
      "[epoch: 52, i:  7999] avg mini-batch loss: 1.135\n",
      "[epoch: 52, i:  8999] avg mini-batch loss: 1.171\n",
      "[epoch: 52, i:  9999] avg mini-batch loss: 1.061\n",
      "[epoch: 52, i: 10999] avg mini-batch loss: 1.145\n",
      "[epoch: 52, i: 11999] avg mini-batch loss: 1.172\n",
      "[epoch: 53, i:   999] avg mini-batch loss: 1.004\n",
      "[epoch: 53, i:  1999] avg mini-batch loss: 1.104\n",
      "[epoch: 53, i:  2999] avg mini-batch loss: 1.089\n",
      "[epoch: 53, i:  3999] avg mini-batch loss: 1.114\n",
      "[epoch: 53, i:  4999] avg mini-batch loss: 1.102\n",
      "[epoch: 53, i:  5999] avg mini-batch loss: 1.113\n",
      "[epoch: 53, i:  6999] avg mini-batch loss: 1.103\n",
      "[epoch: 53, i:  7999] avg mini-batch loss: 1.129\n",
      "[epoch: 53, i:  8999] avg mini-batch loss: 1.147\n",
      "[epoch: 53, i:  9999] avg mini-batch loss: 1.111\n",
      "[epoch: 53, i: 10999] avg mini-batch loss: 1.138\n",
      "[epoch: 53, i: 11999] avg mini-batch loss: 1.095\n",
      "[epoch: 54, i:   999] avg mini-batch loss: 1.119\n",
      "[epoch: 54, i:  1999] avg mini-batch loss: 1.080\n",
      "[epoch: 54, i:  2999] avg mini-batch loss: 1.040\n",
      "[epoch: 54, i:  3999] avg mini-batch loss: 1.119\n",
      "[epoch: 54, i:  4999] avg mini-batch loss: 1.097\n",
      "[epoch: 54, i:  5999] avg mini-batch loss: 1.028\n",
      "[epoch: 54, i:  6999] avg mini-batch loss: 1.108\n",
      "[epoch: 54, i:  7999] avg mini-batch loss: 1.098\n",
      "[epoch: 54, i:  8999] avg mini-batch loss: 1.087\n",
      "[epoch: 54, i:  9999] avg mini-batch loss: 1.126\n",
      "[epoch: 54, i: 10999] avg mini-batch loss: 1.096\n",
      "[epoch: 54, i: 11999] avg mini-batch loss: 1.061\n",
      "[epoch: 55, i:   999] avg mini-batch loss: 1.092\n",
      "[epoch: 55, i:  1999] avg mini-batch loss: 1.055\n",
      "[epoch: 55, i:  2999] avg mini-batch loss: 1.095\n",
      "[epoch: 55, i:  3999] avg mini-batch loss: 1.042\n",
      "[epoch: 55, i:  4999] avg mini-batch loss: 1.095\n",
      "[epoch: 55, i:  5999] avg mini-batch loss: 1.119\n",
      "[epoch: 55, i:  6999] avg mini-batch loss: 1.147\n",
      "[epoch: 55, i:  7999] avg mini-batch loss: 1.067\n",
      "[epoch: 55, i:  8999] avg mini-batch loss: 1.098\n",
      "[epoch: 55, i:  9999] avg mini-batch loss: 1.085\n",
      "[epoch: 55, i: 10999] avg mini-batch loss: 1.110\n",
      "[epoch: 55, i: 11999] avg mini-batch loss: 1.071\n",
      "[epoch: 56, i:   999] avg mini-batch loss: 1.076\n",
      "[epoch: 56, i:  1999] avg mini-batch loss: 1.042\n",
      "[epoch: 56, i:  2999] avg mini-batch loss: 1.108\n",
      "[epoch: 56, i:  3999] avg mini-batch loss: 1.078\n",
      "[epoch: 56, i:  4999] avg mini-batch loss: 1.092\n",
      "[epoch: 56, i:  5999] avg mini-batch loss: 1.104\n",
      "[epoch: 56, i:  6999] avg mini-batch loss: 1.125\n",
      "[epoch: 56, i:  7999] avg mini-batch loss: 1.070\n",
      "[epoch: 56, i:  8999] avg mini-batch loss: 1.079\n",
      "[epoch: 56, i:  9999] avg mini-batch loss: 1.101\n",
      "[epoch: 56, i: 10999] avg mini-batch loss: 1.105\n",
      "[epoch: 56, i: 11999] avg mini-batch loss: 1.118\n",
      "[epoch: 57, i:   999] avg mini-batch loss: 1.058\n",
      "[epoch: 57, i:  1999] avg mini-batch loss: 1.061\n",
      "[epoch: 57, i:  2999] avg mini-batch loss: 1.121\n",
      "[epoch: 57, i:  3999] avg mini-batch loss: 1.054\n",
      "[epoch: 57, i:  4999] avg mini-batch loss: 1.089\n",
      "[epoch: 57, i:  5999] avg mini-batch loss: 1.084\n",
      "[epoch: 57, i:  6999] avg mini-batch loss: 1.036\n",
      "[epoch: 57, i:  7999] avg mini-batch loss: 1.068\n",
      "[epoch: 57, i:  8999] avg mini-batch loss: 1.104\n",
      "[epoch: 57, i:  9999] avg mini-batch loss: 1.072\n",
      "[epoch: 57, i: 10999] avg mini-batch loss: 1.083\n",
      "[epoch: 57, i: 11999] avg mini-batch loss: 1.074\n",
      "[epoch: 58, i:   999] avg mini-batch loss: 1.063\n",
      "[epoch: 58, i:  1999] avg mini-batch loss: 1.073\n",
      "[epoch: 58, i:  2999] avg mini-batch loss: 1.049\n",
      "[epoch: 58, i:  3999] avg mini-batch loss: 1.077\n",
      "[epoch: 58, i:  4999] avg mini-batch loss: 1.074\n",
      "[epoch: 58, i:  5999] avg mini-batch loss: 1.019\n",
      "[epoch: 58, i:  6999] avg mini-batch loss: 1.045\n",
      "[epoch: 58, i:  7999] avg mini-batch loss: 1.106\n",
      "[epoch: 58, i:  8999] avg mini-batch loss: 1.125\n",
      "[epoch: 58, i:  9999] avg mini-batch loss: 1.054\n",
      "[epoch: 58, i: 10999] avg mini-batch loss: 1.044\n",
      "[epoch: 58, i: 11999] avg mini-batch loss: 1.105\n",
      "[epoch: 59, i:   999] avg mini-batch loss: 1.018\n",
      "[epoch: 59, i:  1999] avg mini-batch loss: 1.103\n",
      "[epoch: 59, i:  2999] avg mini-batch loss: 1.058\n",
      "[epoch: 59, i:  3999] avg mini-batch loss: 1.055\n",
      "[epoch: 59, i:  4999] avg mini-batch loss: 1.045\n",
      "[epoch: 59, i:  5999] avg mini-batch loss: 1.083\n",
      "[epoch: 59, i:  6999] avg mini-batch loss: 1.071\n",
      "[epoch: 59, i:  7999] avg mini-batch loss: 1.036\n",
      "[epoch: 59, i:  8999] avg mini-batch loss: 1.064\n",
      "[epoch: 59, i:  9999] avg mini-batch loss: 1.110\n",
      "[epoch: 59, i: 10999] avg mini-batch loss: 1.037\n",
      "[epoch: 59, i: 11999] avg mini-batch loss: 1.104\n",
      "[epoch: 60, i:   999] avg mini-batch loss: 1.043\n",
      "[epoch: 60, i:  1999] avg mini-batch loss: 0.998\n",
      "[epoch: 60, i:  2999] avg mini-batch loss: 1.002\n",
      "[epoch: 60, i:  3999] avg mini-batch loss: 1.071\n",
      "[epoch: 60, i:  4999] avg mini-batch loss: 1.027\n",
      "[epoch: 60, i:  5999] avg mini-batch loss: 1.084\n",
      "[epoch: 60, i:  6999] avg mini-batch loss: 1.038\n",
      "[epoch: 60, i:  7999] avg mini-batch loss: 1.081\n",
      "[epoch: 60, i:  8999] avg mini-batch loss: 1.147\n",
      "[epoch: 60, i:  9999] avg mini-batch loss: 1.038\n",
      "[epoch: 60, i: 10999] avg mini-batch loss: 1.064\n",
      "[epoch: 60, i: 11999] avg mini-batch loss: 1.083\n",
      "[epoch: 61, i:   999] avg mini-batch loss: 1.041\n",
      "[epoch: 61, i:  1999] avg mini-batch loss: 1.043\n",
      "[epoch: 61, i:  2999] avg mini-batch loss: 1.033\n",
      "[epoch: 61, i:  3999] avg mini-batch loss: 1.042\n",
      "[epoch: 61, i:  4999] avg mini-batch loss: 1.050\n",
      "[epoch: 61, i:  5999] avg mini-batch loss: 1.039\n",
      "[epoch: 61, i:  6999] avg mini-batch loss: 1.145\n",
      "[epoch: 61, i:  7999] avg mini-batch loss: 1.073\n",
      "[epoch: 61, i:  8999] avg mini-batch loss: 1.107\n",
      "[epoch: 61, i:  9999] avg mini-batch loss: 1.073\n",
      "[epoch: 61, i: 10999] avg mini-batch loss: 1.075\n",
      "[epoch: 61, i: 11999] avg mini-batch loss: 1.100\n",
      "[epoch: 62, i:   999] avg mini-batch loss: 1.060\n",
      "[epoch: 62, i:  1999] avg mini-batch loss: 1.028\n",
      "[epoch: 62, i:  2999] avg mini-batch loss: 1.040\n",
      "[epoch: 62, i:  3999] avg mini-batch loss: 1.042\n",
      "[epoch: 62, i:  4999] avg mini-batch loss: 1.061\n",
      "[epoch: 62, i:  5999] avg mini-batch loss: 1.069\n",
      "[epoch: 62, i:  6999] avg mini-batch loss: 1.073\n",
      "[epoch: 62, i:  7999] avg mini-batch loss: 1.019\n",
      "[epoch: 62, i:  8999] avg mini-batch loss: 1.058\n",
      "[epoch: 62, i:  9999] avg mini-batch loss: 1.065\n",
      "[epoch: 62, i: 10999] avg mini-batch loss: 1.103\n",
      "[epoch: 62, i: 11999] avg mini-batch loss: 1.048\n",
      "[epoch: 63, i:   999] avg mini-batch loss: 1.052\n",
      "[epoch: 63, i:  1999] avg mini-batch loss: 1.022\n",
      "[epoch: 63, i:  2999] avg mini-batch loss: 0.997\n",
      "[epoch: 63, i:  3999] avg mini-batch loss: 1.041\n",
      "[epoch: 63, i:  4999] avg mini-batch loss: 1.083\n",
      "[epoch: 63, i:  5999] avg mini-batch loss: 1.059\n",
      "[epoch: 63, i:  6999] avg mini-batch loss: 1.022\n",
      "[epoch: 63, i:  7999] avg mini-batch loss: 1.076\n",
      "[epoch: 63, i:  8999] avg mini-batch loss: 1.046\n",
      "[epoch: 63, i:  9999] avg mini-batch loss: 1.093\n",
      "[epoch: 63, i: 10999] avg mini-batch loss: 1.061\n",
      "[epoch: 63, i: 11999] avg mini-batch loss: 1.089\n",
      "[epoch: 64, i:   999] avg mini-batch loss: 1.002\n",
      "[epoch: 64, i:  1999] avg mini-batch loss: 0.991\n",
      "[epoch: 64, i:  2999] avg mini-batch loss: 0.986\n",
      "[epoch: 64, i:  3999] avg mini-batch loss: 1.050\n",
      "[epoch: 64, i:  4999] avg mini-batch loss: 1.052\n",
      "[epoch: 64, i:  5999] avg mini-batch loss: 1.054\n",
      "[epoch: 64, i:  6999] avg mini-batch loss: 1.037\n",
      "[epoch: 64, i:  7999] avg mini-batch loss: 1.021\n",
      "[epoch: 64, i:  8999] avg mini-batch loss: 1.077\n",
      "[epoch: 64, i:  9999] avg mini-batch loss: 0.995\n",
      "[epoch: 64, i: 10999] avg mini-batch loss: 1.078\n",
      "[epoch: 64, i: 11999] avg mini-batch loss: 1.044\n",
      "[epoch: 65, i:   999] avg mini-batch loss: 0.934\n",
      "[epoch: 65, i:  1999] avg mini-batch loss: 0.986\n",
      "[epoch: 65, i:  2999] avg mini-batch loss: 1.014\n",
      "[epoch: 65, i:  3999] avg mini-batch loss: 1.057\n",
      "[epoch: 65, i:  4999] avg mini-batch loss: 1.036\n",
      "[epoch: 65, i:  5999] avg mini-batch loss: 1.034\n",
      "[epoch: 65, i:  6999] avg mini-batch loss: 1.039\n",
      "[epoch: 65, i:  7999] avg mini-batch loss: 1.033\n",
      "[epoch: 65, i:  8999] avg mini-batch loss: 1.021\n",
      "[epoch: 65, i:  9999] avg mini-batch loss: 1.053\n",
      "[epoch: 65, i: 10999] avg mini-batch loss: 1.073\n",
      "[epoch: 65, i: 11999] avg mini-batch loss: 1.049\n",
      "[epoch: 66, i:   999] avg mini-batch loss: 1.007\n",
      "[epoch: 66, i:  1999] avg mini-batch loss: 1.036\n",
      "[epoch: 66, i:  2999] avg mini-batch loss: 1.019\n",
      "[epoch: 66, i:  3999] avg mini-batch loss: 1.030\n",
      "[epoch: 66, i:  4999] avg mini-batch loss: 1.018\n",
      "[epoch: 66, i:  5999] avg mini-batch loss: 1.000\n",
      "[epoch: 66, i:  6999] avg mini-batch loss: 1.062\n",
      "[epoch: 66, i:  7999] avg mini-batch loss: 1.062\n",
      "[epoch: 66, i:  8999] avg mini-batch loss: 1.035\n",
      "[epoch: 66, i:  9999] avg mini-batch loss: 1.072\n",
      "[epoch: 66, i: 10999] avg mini-batch loss: 0.987\n",
      "[epoch: 66, i: 11999] avg mini-batch loss: 1.071\n",
      "[epoch: 67, i:   999] avg mini-batch loss: 0.990\n",
      "[epoch: 67, i:  1999] avg mini-batch loss: 1.009\n",
      "[epoch: 67, i:  2999] avg mini-batch loss: 1.050\n",
      "[epoch: 67, i:  3999] avg mini-batch loss: 1.025\n",
      "[epoch: 67, i:  4999] avg mini-batch loss: 1.014\n",
      "[epoch: 67, i:  5999] avg mini-batch loss: 1.031\n",
      "[epoch: 67, i:  6999] avg mini-batch loss: 1.012\n",
      "[epoch: 67, i:  7999] avg mini-batch loss: 0.981\n",
      "[epoch: 67, i:  8999] avg mini-batch loss: 1.020\n",
      "[epoch: 67, i:  9999] avg mini-batch loss: 1.023\n",
      "[epoch: 67, i: 10999] avg mini-batch loss: 0.979\n",
      "[epoch: 67, i: 11999] avg mini-batch loss: 0.995\n",
      "[epoch: 68, i:   999] avg mini-batch loss: 0.987\n",
      "[epoch: 68, i:  1999] avg mini-batch loss: 1.001\n",
      "[epoch: 68, i:  2999] avg mini-batch loss: 1.040\n",
      "[epoch: 68, i:  3999] avg mini-batch loss: 1.080\n",
      "[epoch: 68, i:  4999] avg mini-batch loss: 1.013\n",
      "[epoch: 68, i:  5999] avg mini-batch loss: 0.999\n",
      "[epoch: 68, i:  6999] avg mini-batch loss: 0.998\n",
      "[epoch: 68, i:  7999] avg mini-batch loss: 1.016\n",
      "[epoch: 68, i:  8999] avg mini-batch loss: 0.988\n",
      "[epoch: 68, i:  9999] avg mini-batch loss: 0.999\n",
      "[epoch: 68, i: 10999] avg mini-batch loss: 1.062\n",
      "[epoch: 68, i: 11999] avg mini-batch loss: 1.033\n",
      "[epoch: 69, i:   999] avg mini-batch loss: 0.993\n",
      "[epoch: 69, i:  1999] avg mini-batch loss: 1.036\n",
      "[epoch: 69, i:  2999] avg mini-batch loss: 0.971\n",
      "[epoch: 69, i:  3999] avg mini-batch loss: 1.021\n",
      "[epoch: 69, i:  4999] avg mini-batch loss: 0.958\n",
      "[epoch: 69, i:  5999] avg mini-batch loss: 1.048\n",
      "[epoch: 69, i:  6999] avg mini-batch loss: 1.021\n",
      "[epoch: 69, i:  7999] avg mini-batch loss: 1.048\n",
      "[epoch: 69, i:  8999] avg mini-batch loss: 1.069\n",
      "[epoch: 69, i:  9999] avg mini-batch loss: 1.024\n",
      "[epoch: 69, i: 10999] avg mini-batch loss: 1.015\n",
      "[epoch: 69, i: 11999] avg mini-batch loss: 1.006\n",
      "[epoch: 70, i:   999] avg mini-batch loss: 0.997\n",
      "[epoch: 70, i:  1999] avg mini-batch loss: 1.035\n",
      "[epoch: 70, i:  2999] avg mini-batch loss: 0.986\n",
      "[epoch: 70, i:  3999] avg mini-batch loss: 0.996\n",
      "[epoch: 70, i:  4999] avg mini-batch loss: 0.987\n",
      "[epoch: 70, i:  5999] avg mini-batch loss: 0.957\n",
      "[epoch: 70, i:  6999] avg mini-batch loss: 1.015\n",
      "[epoch: 70, i:  7999] avg mini-batch loss: 1.001\n",
      "[epoch: 70, i:  8999] avg mini-batch loss: 0.988\n",
      "[epoch: 70, i:  9999] avg mini-batch loss: 0.996\n",
      "[epoch: 70, i: 10999] avg mini-batch loss: 0.991\n",
      "[epoch: 70, i: 11999] avg mini-batch loss: 1.026\n",
      "[epoch: 71, i:   999] avg mini-batch loss: 1.004\n",
      "[epoch: 71, i:  1999] avg mini-batch loss: 0.946\n",
      "[epoch: 71, i:  2999] avg mini-batch loss: 1.026\n",
      "[epoch: 71, i:  3999] avg mini-batch loss: 1.074\n",
      "[epoch: 71, i:  4999] avg mini-batch loss: 1.014\n",
      "[epoch: 71, i:  5999] avg mini-batch loss: 0.996\n",
      "[epoch: 71, i:  6999] avg mini-batch loss: 1.017\n",
      "[epoch: 71, i:  7999] avg mini-batch loss: 1.005\n",
      "[epoch: 71, i:  8999] avg mini-batch loss: 0.979\n",
      "[epoch: 71, i:  9999] avg mini-batch loss: 1.000\n",
      "[epoch: 71, i: 10999] avg mini-batch loss: 1.020\n",
      "[epoch: 71, i: 11999] avg mini-batch loss: 1.002\n",
      "[epoch: 72, i:   999] avg mini-batch loss: 0.962\n",
      "[epoch: 72, i:  1999] avg mini-batch loss: 0.995\n",
      "[epoch: 72, i:  2999] avg mini-batch loss: 0.970\n",
      "[epoch: 72, i:  3999] avg mini-batch loss: 1.020\n",
      "[epoch: 72, i:  4999] avg mini-batch loss: 0.982\n",
      "[epoch: 72, i:  5999] avg mini-batch loss: 0.978\n",
      "[epoch: 72, i:  6999] avg mini-batch loss: 1.036\n",
      "[epoch: 72, i:  7999] avg mini-batch loss: 1.034\n",
      "[epoch: 72, i:  8999] avg mini-batch loss: 1.047\n",
      "[epoch: 72, i:  9999] avg mini-batch loss: 0.961\n",
      "[epoch: 72, i: 10999] avg mini-batch loss: 1.023\n",
      "[epoch: 72, i: 11999] avg mini-batch loss: 1.005\n",
      "[epoch: 73, i:   999] avg mini-batch loss: 0.980\n",
      "[epoch: 73, i:  1999] avg mini-batch loss: 0.958\n",
      "[epoch: 73, i:  2999] avg mini-batch loss: 0.976\n",
      "[epoch: 73, i:  3999] avg mini-batch loss: 0.984\n",
      "[epoch: 73, i:  4999] avg mini-batch loss: 1.007\n",
      "[epoch: 73, i:  5999] avg mini-batch loss: 0.960\n",
      "[epoch: 73, i:  6999] avg mini-batch loss: 1.060\n",
      "[epoch: 73, i:  7999] avg mini-batch loss: 1.024\n",
      "[epoch: 73, i:  8999] avg mini-batch loss: 1.040\n",
      "[epoch: 73, i:  9999] avg mini-batch loss: 0.975\n",
      "[epoch: 73, i: 10999] avg mini-batch loss: 1.045\n",
      "[epoch: 73, i: 11999] avg mini-batch loss: 0.995\n",
      "[epoch: 74, i:   999] avg mini-batch loss: 0.958\n",
      "[epoch: 74, i:  1999] avg mini-batch loss: 0.956\n",
      "[epoch: 74, i:  2999] avg mini-batch loss: 1.020\n",
      "[epoch: 74, i:  3999] avg mini-batch loss: 1.025\n",
      "[epoch: 74, i:  4999] avg mini-batch loss: 1.018\n",
      "[epoch: 74, i:  5999] avg mini-batch loss: 0.983\n",
      "[epoch: 74, i:  6999] avg mini-batch loss: 0.988\n",
      "[epoch: 74, i:  7999] avg mini-batch loss: 0.982\n",
      "[epoch: 74, i:  8999] avg mini-batch loss: 1.002\n",
      "[epoch: 74, i:  9999] avg mini-batch loss: 0.940\n",
      "[epoch: 74, i: 10999] avg mini-batch loss: 0.996\n",
      "[epoch: 74, i: 11999] avg mini-batch loss: 0.996\n",
      "[epoch: 75, i:   999] avg mini-batch loss: 0.956\n",
      "[epoch: 75, i:  1999] avg mini-batch loss: 1.021\n",
      "[epoch: 75, i:  2999] avg mini-batch loss: 0.961\n",
      "[epoch: 75, i:  3999] avg mini-batch loss: 1.042\n",
      "[epoch: 75, i:  4999] avg mini-batch loss: 0.997\n",
      "[epoch: 75, i:  5999] avg mini-batch loss: 1.015\n",
      "[epoch: 75, i:  6999] avg mini-batch loss: 1.006\n",
      "[epoch: 75, i:  7999] avg mini-batch loss: 0.991\n",
      "[epoch: 75, i:  8999] avg mini-batch loss: 0.963\n",
      "[epoch: 75, i:  9999] avg mini-batch loss: 1.020\n",
      "[epoch: 75, i: 10999] avg mini-batch loss: 1.026\n",
      "[epoch: 75, i: 11999] avg mini-batch loss: 0.974\n",
      "[epoch: 76, i:   999] avg mini-batch loss: 0.948\n",
      "[epoch: 76, i:  1999] avg mini-batch loss: 1.003\n",
      "[epoch: 76, i:  2999] avg mini-batch loss: 0.998\n",
      "[epoch: 76, i:  3999] avg mini-batch loss: 0.917\n",
      "[epoch: 76, i:  4999] avg mini-batch loss: 0.953\n",
      "[epoch: 76, i:  5999] avg mini-batch loss: 0.992\n",
      "[epoch: 76, i:  6999] avg mini-batch loss: 1.007\n",
      "[epoch: 76, i:  7999] avg mini-batch loss: 0.965\n",
      "[epoch: 76, i:  8999] avg mini-batch loss: 0.981\n",
      "[epoch: 76, i:  9999] avg mini-batch loss: 1.045\n",
      "[epoch: 76, i: 10999] avg mini-batch loss: 0.982\n",
      "[epoch: 76, i: 11999] avg mini-batch loss: 0.982\n",
      "[epoch: 77, i:   999] avg mini-batch loss: 0.973\n",
      "[epoch: 77, i:  1999] avg mini-batch loss: 0.958\n",
      "[epoch: 77, i:  2999] avg mini-batch loss: 0.927\n",
      "[epoch: 77, i:  3999] avg mini-batch loss: 0.996\n",
      "[epoch: 77, i:  4999] avg mini-batch loss: 0.956\n",
      "[epoch: 77, i:  5999] avg mini-batch loss: 1.008\n",
      "[epoch: 77, i:  6999] avg mini-batch loss: 0.975\n",
      "[epoch: 77, i:  7999] avg mini-batch loss: 0.952\n",
      "[epoch: 77, i:  8999] avg mini-batch loss: 0.973\n",
      "[epoch: 77, i:  9999] avg mini-batch loss: 0.979\n",
      "[epoch: 77, i: 10999] avg mini-batch loss: 1.008\n",
      "[epoch: 77, i: 11999] avg mini-batch loss: 1.054\n",
      "[epoch: 78, i:   999] avg mini-batch loss: 0.922\n",
      "[epoch: 78, i:  1999] avg mini-batch loss: 0.992\n",
      "[epoch: 78, i:  2999] avg mini-batch loss: 0.954\n",
      "[epoch: 78, i:  3999] avg mini-batch loss: 0.973\n",
      "[epoch: 78, i:  4999] avg mini-batch loss: 0.966\n",
      "[epoch: 78, i:  5999] avg mini-batch loss: 0.961\n",
      "[epoch: 78, i:  6999] avg mini-batch loss: 0.946\n",
      "[epoch: 78, i:  7999] avg mini-batch loss: 0.975\n",
      "[epoch: 78, i:  8999] avg mini-batch loss: 1.013\n",
      "[epoch: 78, i:  9999] avg mini-batch loss: 0.988\n",
      "[epoch: 78, i: 10999] avg mini-batch loss: 1.014\n",
      "[epoch: 78, i: 11999] avg mini-batch loss: 1.011\n",
      "[epoch: 79, i:   999] avg mini-batch loss: 0.965\n",
      "[epoch: 79, i:  1999] avg mini-batch loss: 0.945\n",
      "[epoch: 79, i:  2999] avg mini-batch loss: 1.004\n",
      "[epoch: 79, i:  3999] avg mini-batch loss: 0.981\n",
      "[epoch: 79, i:  4999] avg mini-batch loss: 0.941\n",
      "[epoch: 79, i:  5999] avg mini-batch loss: 0.965\n",
      "[epoch: 79, i:  6999] avg mini-batch loss: 0.981\n",
      "[epoch: 79, i:  7999] avg mini-batch loss: 1.008\n",
      "[epoch: 79, i:  8999] avg mini-batch loss: 0.989\n",
      "[epoch: 79, i:  9999] avg mini-batch loss: 0.982\n",
      "[epoch: 79, i: 10999] avg mini-batch loss: 0.944\n",
      "[epoch: 79, i: 11999] avg mini-batch loss: 1.014\n",
      "[epoch: 80, i:   999] avg mini-batch loss: 0.912\n",
      "[epoch: 80, i:  1999] avg mini-batch loss: 0.942\n",
      "[epoch: 80, i:  2999] avg mini-batch loss: 0.968\n",
      "[epoch: 80, i:  3999] avg mini-batch loss: 0.953\n",
      "[epoch: 80, i:  4999] avg mini-batch loss: 0.954\n",
      "[epoch: 80, i:  5999] avg mini-batch loss: 0.988\n",
      "[epoch: 80, i:  6999] avg mini-batch loss: 0.984\n",
      "[epoch: 80, i:  7999] avg mini-batch loss: 0.981\n",
      "[epoch: 80, i:  8999] avg mini-batch loss: 0.988\n",
      "[epoch: 80, i:  9999] avg mini-batch loss: 1.015\n",
      "[epoch: 80, i: 10999] avg mini-batch loss: 0.934\n",
      "[epoch: 80, i: 11999] avg mini-batch loss: 1.032\n",
      "[epoch: 81, i:   999] avg mini-batch loss: 0.956\n",
      "[epoch: 81, i:  1999] avg mini-batch loss: 0.926\n",
      "[epoch: 81, i:  2999] avg mini-batch loss: 0.968\n",
      "[epoch: 81, i:  3999] avg mini-batch loss: 0.971\n",
      "[epoch: 81, i:  4999] avg mini-batch loss: 0.994\n",
      "[epoch: 81, i:  5999] avg mini-batch loss: 0.984\n",
      "[epoch: 81, i:  6999] avg mini-batch loss: 0.957\n",
      "[epoch: 81, i:  7999] avg mini-batch loss: 0.959\n",
      "[epoch: 81, i:  8999] avg mini-batch loss: 0.987\n",
      "[epoch: 81, i:  9999] avg mini-batch loss: 1.021\n",
      "[epoch: 81, i: 10999] avg mini-batch loss: 0.919\n",
      "[epoch: 81, i: 11999] avg mini-batch loss: 0.981\n",
      "[epoch: 82, i:   999] avg mini-batch loss: 0.971\n",
      "[epoch: 82, i:  1999] avg mini-batch loss: 0.948\n",
      "[epoch: 82, i:  2999] avg mini-batch loss: 0.928\n",
      "[epoch: 82, i:  3999] avg mini-batch loss: 0.993\n",
      "[epoch: 82, i:  4999] avg mini-batch loss: 0.969\n",
      "[epoch: 82, i:  5999] avg mini-batch loss: 0.963\n",
      "[epoch: 82, i:  6999] avg mini-batch loss: 0.918\n",
      "[epoch: 82, i:  7999] avg mini-batch loss: 0.913\n",
      "[epoch: 82, i:  8999] avg mini-batch loss: 0.953\n",
      "[epoch: 82, i:  9999] avg mini-batch loss: 0.974\n",
      "[epoch: 82, i: 10999] avg mini-batch loss: 0.949\n",
      "[epoch: 82, i: 11999] avg mini-batch loss: 0.992\n",
      "[epoch: 83, i:   999] avg mini-batch loss: 0.897\n",
      "[epoch: 83, i:  1999] avg mini-batch loss: 0.996\n",
      "[epoch: 83, i:  2999] avg mini-batch loss: 0.973\n",
      "[epoch: 83, i:  3999] avg mini-batch loss: 0.953\n",
      "[epoch: 83, i:  4999] avg mini-batch loss: 0.933\n",
      "[epoch: 83, i:  5999] avg mini-batch loss: 0.982\n",
      "[epoch: 83, i:  6999] avg mini-batch loss: 0.906\n",
      "[epoch: 83, i:  7999] avg mini-batch loss: 0.970\n",
      "[epoch: 83, i:  8999] avg mini-batch loss: 0.923\n",
      "[epoch: 83, i:  9999] avg mini-batch loss: 0.962\n",
      "[epoch: 83, i: 10999] avg mini-batch loss: 0.973\n",
      "[epoch: 83, i: 11999] avg mini-batch loss: 0.898\n",
      "[epoch: 84, i:   999] avg mini-batch loss: 0.921\n",
      "[epoch: 84, i:  1999] avg mini-batch loss: 0.931\n",
      "[epoch: 84, i:  2999] avg mini-batch loss: 0.931\n",
      "[epoch: 84, i:  3999] avg mini-batch loss: 0.992\n",
      "[epoch: 84, i:  4999] avg mini-batch loss: 0.938\n",
      "[epoch: 84, i:  5999] avg mini-batch loss: 0.931\n",
      "[epoch: 84, i:  6999] avg mini-batch loss: 0.959\n",
      "[epoch: 84, i:  7999] avg mini-batch loss: 1.001\n",
      "[epoch: 84, i:  8999] avg mini-batch loss: 0.980\n",
      "[epoch: 84, i:  9999] avg mini-batch loss: 0.891\n",
      "[epoch: 84, i: 10999] avg mini-batch loss: 1.020\n",
      "[epoch: 84, i: 11999] avg mini-batch loss: 0.965\n",
      "[epoch: 85, i:   999] avg mini-batch loss: 0.933\n",
      "[epoch: 85, i:  1999] avg mini-batch loss: 0.948\n",
      "[epoch: 85, i:  2999] avg mini-batch loss: 0.937\n",
      "[epoch: 85, i:  3999] avg mini-batch loss: 0.999\n",
      "[epoch: 85, i:  4999] avg mini-batch loss: 0.961\n",
      "[epoch: 85, i:  5999] avg mini-batch loss: 0.955\n",
      "[epoch: 85, i:  6999] avg mini-batch loss: 0.917\n",
      "[epoch: 85, i:  7999] avg mini-batch loss: 0.929\n",
      "[epoch: 85, i:  8999] avg mini-batch loss: 0.957\n",
      "[epoch: 85, i:  9999] avg mini-batch loss: 0.947\n",
      "[epoch: 85, i: 10999] avg mini-batch loss: 1.053\n",
      "[epoch: 85, i: 11999] avg mini-batch loss: 0.946\n",
      "[epoch: 86, i:   999] avg mini-batch loss: 0.927\n",
      "[epoch: 86, i:  1999] avg mini-batch loss: 0.933\n",
      "[epoch: 86, i:  2999] avg mini-batch loss: 0.961\n",
      "[epoch: 86, i:  3999] avg mini-batch loss: 0.940\n",
      "[epoch: 86, i:  4999] avg mini-batch loss: 0.934\n",
      "[epoch: 86, i:  5999] avg mini-batch loss: 0.928\n",
      "[epoch: 86, i:  6999] avg mini-batch loss: 0.980\n",
      "[epoch: 86, i:  7999] avg mini-batch loss: 0.935\n",
      "[epoch: 86, i:  8999] avg mini-batch loss: 1.001\n",
      "[epoch: 86, i:  9999] avg mini-batch loss: 0.936\n",
      "[epoch: 86, i: 10999] avg mini-batch loss: 0.913\n",
      "[epoch: 86, i: 11999] avg mini-batch loss: 0.921\n",
      "[epoch: 87, i:   999] avg mini-batch loss: 0.949\n",
      "[epoch: 87, i:  1999] avg mini-batch loss: 0.968\n",
      "[epoch: 87, i:  2999] avg mini-batch loss: 0.935\n",
      "[epoch: 87, i:  3999] avg mini-batch loss: 0.902\n",
      "[epoch: 87, i:  4999] avg mini-batch loss: 0.913\n",
      "[epoch: 87, i:  5999] avg mini-batch loss: 0.885\n",
      "[epoch: 87, i:  6999] avg mini-batch loss: 0.978\n",
      "[epoch: 87, i:  7999] avg mini-batch loss: 0.980\n",
      "[epoch: 87, i:  8999] avg mini-batch loss: 0.930\n",
      "[epoch: 87, i:  9999] avg mini-batch loss: 0.967\n",
      "[epoch: 87, i: 10999] avg mini-batch loss: 0.945\n",
      "[epoch: 87, i: 11999] avg mini-batch loss: 0.976\n",
      "[epoch: 88, i:   999] avg mini-batch loss: 0.937\n",
      "[epoch: 88, i:  1999] avg mini-batch loss: 0.910\n",
      "[epoch: 88, i:  2999] avg mini-batch loss: 0.950\n",
      "[epoch: 88, i:  3999] avg mini-batch loss: 0.938\n",
      "[epoch: 88, i:  4999] avg mini-batch loss: 0.966\n",
      "[epoch: 88, i:  5999] avg mini-batch loss: 0.999\n",
      "[epoch: 88, i:  6999] avg mini-batch loss: 0.972\n",
      "[epoch: 88, i:  7999] avg mini-batch loss: 0.950\n",
      "[epoch: 88, i:  8999] avg mini-batch loss: 0.972\n",
      "[epoch: 88, i:  9999] avg mini-batch loss: 0.980\n",
      "[epoch: 88, i: 10999] avg mini-batch loss: 1.008\n",
      "[epoch: 88, i: 11999] avg mini-batch loss: 1.063\n",
      "[epoch: 89, i:   999] avg mini-batch loss: 0.932\n",
      "[epoch: 89, i:  1999] avg mini-batch loss: 0.939\n",
      "[epoch: 89, i:  2999] avg mini-batch loss: 0.977\n",
      "[epoch: 89, i:  3999] avg mini-batch loss: 0.933\n",
      "[epoch: 89, i:  4999] avg mini-batch loss: 0.973\n",
      "[epoch: 89, i:  5999] avg mini-batch loss: 0.928\n",
      "[epoch: 89, i:  6999] avg mini-batch loss: 0.938\n",
      "[epoch: 89, i:  7999] avg mini-batch loss: 0.968\n",
      "[epoch: 89, i:  8999] avg mini-batch loss: 0.943\n",
      "[epoch: 89, i:  9999] avg mini-batch loss: 0.964\n",
      "[epoch: 89, i: 10999] avg mini-batch loss: 0.923\n",
      "[epoch: 89, i: 11999] avg mini-batch loss: 0.964\n",
      "[epoch: 90, i:   999] avg mini-batch loss: 0.973\n",
      "[epoch: 90, i:  1999] avg mini-batch loss: 0.945\n",
      "[epoch: 90, i:  2999] avg mini-batch loss: 0.884\n",
      "[epoch: 90, i:  3999] avg mini-batch loss: 0.902\n",
      "[epoch: 90, i:  4999] avg mini-batch loss: 0.963\n",
      "[epoch: 90, i:  5999] avg mini-batch loss: 0.936\n",
      "[epoch: 90, i:  6999] avg mini-batch loss: 0.938\n",
      "[epoch: 90, i:  7999] avg mini-batch loss: 0.928\n",
      "[epoch: 90, i:  8999] avg mini-batch loss: 0.994\n",
      "[epoch: 90, i:  9999] avg mini-batch loss: 0.907\n",
      "[epoch: 90, i: 10999] avg mini-batch loss: 0.944\n",
      "[epoch: 90, i: 11999] avg mini-batch loss: 0.936\n",
      "[epoch: 91, i:   999] avg mini-batch loss: 0.945\n",
      "[epoch: 91, i:  1999] avg mini-batch loss: 0.931\n",
      "[epoch: 91, i:  2999] avg mini-batch loss: 0.920\n",
      "[epoch: 91, i:  3999] avg mini-batch loss: 0.934\n",
      "[epoch: 91, i:  4999] avg mini-batch loss: 0.935\n",
      "[epoch: 91, i:  5999] avg mini-batch loss: 0.939\n",
      "[epoch: 91, i:  6999] avg mini-batch loss: 0.936\n",
      "[epoch: 91, i:  7999] avg mini-batch loss: 0.904\n",
      "[epoch: 91, i:  8999] avg mini-batch loss: 0.922\n",
      "[epoch: 91, i:  9999] avg mini-batch loss: 1.007\n",
      "[epoch: 91, i: 10999] avg mini-batch loss: 0.951\n",
      "[epoch: 91, i: 11999] avg mini-batch loss: 0.946\n",
      "[epoch: 92, i:   999] avg mini-batch loss: 0.896\n",
      "[epoch: 92, i:  1999] avg mini-batch loss: 0.922\n",
      "[epoch: 92, i:  2999] avg mini-batch loss: 0.981\n",
      "[epoch: 92, i:  3999] avg mini-batch loss: 0.949\n",
      "[epoch: 92, i:  4999] avg mini-batch loss: 0.913\n",
      "[epoch: 92, i:  5999] avg mini-batch loss: 0.965\n",
      "[epoch: 92, i:  6999] avg mini-batch loss: 0.917\n",
      "[epoch: 92, i:  7999] avg mini-batch loss: 0.913\n",
      "[epoch: 92, i:  8999] avg mini-batch loss: 0.953\n",
      "[epoch: 92, i:  9999] avg mini-batch loss: 0.924\n",
      "[epoch: 92, i: 10999] avg mini-batch loss: 0.925\n",
      "[epoch: 92, i: 11999] avg mini-batch loss: 0.960\n",
      "[epoch: 93, i:   999] avg mini-batch loss: 0.934\n",
      "[epoch: 93, i:  1999] avg mini-batch loss: 0.961\n",
      "[epoch: 93, i:  2999] avg mini-batch loss: 0.931\n",
      "[epoch: 93, i:  3999] avg mini-batch loss: 0.901\n",
      "[epoch: 93, i:  4999] avg mini-batch loss: 0.952\n",
      "[epoch: 93, i:  5999] avg mini-batch loss: 0.948\n",
      "[epoch: 93, i:  6999] avg mini-batch loss: 0.902\n",
      "[epoch: 93, i:  7999] avg mini-batch loss: 0.958\n",
      "[epoch: 93, i:  8999] avg mini-batch loss: 0.901\n",
      "[epoch: 93, i:  9999] avg mini-batch loss: 0.980\n",
      "[epoch: 93, i: 10999] avg mini-batch loss: 0.920\n",
      "[epoch: 93, i: 11999] avg mini-batch loss: 0.957\n",
      "[epoch: 94, i:   999] avg mini-batch loss: 0.911\n",
      "[epoch: 94, i:  1999] avg mini-batch loss: 0.889\n",
      "[epoch: 94, i:  2999] avg mini-batch loss: 0.931\n",
      "[epoch: 94, i:  3999] avg mini-batch loss: 0.947\n",
      "[epoch: 94, i:  4999] avg mini-batch loss: 0.950\n",
      "[epoch: 94, i:  5999] avg mini-batch loss: 0.949\n",
      "[epoch: 94, i:  6999] avg mini-batch loss: 0.929\n",
      "[epoch: 94, i:  7999] avg mini-batch loss: 0.942\n",
      "[epoch: 94, i:  8999] avg mini-batch loss: 0.978\n",
      "[epoch: 94, i:  9999] avg mini-batch loss: 0.959\n",
      "[epoch: 94, i: 10999] avg mini-batch loss: 0.966\n",
      "[epoch: 94, i: 11999] avg mini-batch loss: 0.937\n",
      "[epoch: 95, i:   999] avg mini-batch loss: 0.959\n",
      "[epoch: 95, i:  1999] avg mini-batch loss: 0.934\n",
      "[epoch: 95, i:  2999] avg mini-batch loss: 0.940\n",
      "[epoch: 95, i:  3999] avg mini-batch loss: 0.920\n",
      "[epoch: 95, i:  4999] avg mini-batch loss: 0.914\n",
      "[epoch: 95, i:  5999] avg mini-batch loss: 0.948\n",
      "[epoch: 95, i:  6999] avg mini-batch loss: 0.940\n",
      "[epoch: 95, i:  7999] avg mini-batch loss: 0.928\n",
      "[epoch: 95, i:  8999] avg mini-batch loss: 0.963\n",
      "[epoch: 95, i:  9999] avg mini-batch loss: 0.978\n",
      "[epoch: 95, i: 10999] avg mini-batch loss: 1.007\n",
      "[epoch: 95, i: 11999] avg mini-batch loss: 0.981\n",
      "[epoch: 96, i:   999] avg mini-batch loss: 0.911\n",
      "[epoch: 96, i:  1999] avg mini-batch loss: 0.955\n",
      "[epoch: 96, i:  2999] avg mini-batch loss: 0.913\n",
      "[epoch: 96, i:  3999] avg mini-batch loss: 0.932\n",
      "[epoch: 96, i:  4999] avg mini-batch loss: 0.888\n",
      "[epoch: 96, i:  5999] avg mini-batch loss: 0.885\n",
      "[epoch: 96, i:  6999] avg mini-batch loss: 0.904\n",
      "[epoch: 96, i:  7999] avg mini-batch loss: 0.939\n",
      "[epoch: 96, i:  8999] avg mini-batch loss: 0.930\n",
      "[epoch: 96, i:  9999] avg mini-batch loss: 0.938\n",
      "[epoch: 96, i: 10999] avg mini-batch loss: 0.942\n",
      "[epoch: 96, i: 11999] avg mini-batch loss: 0.925\n",
      "[epoch: 97, i:   999] avg mini-batch loss: 0.902\n",
      "[epoch: 97, i:  1999] avg mini-batch loss: 0.908\n",
      "[epoch: 97, i:  2999] avg mini-batch loss: 0.886\n",
      "[epoch: 97, i:  3999] avg mini-batch loss: 0.898\n",
      "[epoch: 97, i:  4999] avg mini-batch loss: 0.931\n",
      "[epoch: 97, i:  5999] avg mini-batch loss: 0.928\n",
      "[epoch: 97, i:  6999] avg mini-batch loss: 0.904\n",
      "[epoch: 97, i:  7999] avg mini-batch loss: 0.896\n",
      "[epoch: 97, i:  8999] avg mini-batch loss: 0.920\n",
      "[epoch: 97, i:  9999] avg mini-batch loss: 0.950\n",
      "[epoch: 97, i: 10999] avg mini-batch loss: 0.950\n",
      "[epoch: 97, i: 11999] avg mini-batch loss: 0.927\n",
      "[epoch: 98, i:   999] avg mini-batch loss: 0.946\n",
      "[epoch: 98, i:  1999] avg mini-batch loss: 0.905\n",
      "[epoch: 98, i:  2999] avg mini-batch loss: 0.961\n",
      "[epoch: 98, i:  3999] avg mini-batch loss: 0.934\n",
      "[epoch: 98, i:  4999] avg mini-batch loss: 0.911\n",
      "[epoch: 98, i:  5999] avg mini-batch loss: 0.902\n",
      "[epoch: 98, i:  6999] avg mini-batch loss: 0.906\n",
      "[epoch: 98, i:  7999] avg mini-batch loss: 0.925\n",
      "[epoch: 98, i:  8999] avg mini-batch loss: 0.948\n",
      "[epoch: 98, i:  9999] avg mini-batch loss: 0.939\n",
      "[epoch: 98, i: 10999] avg mini-batch loss: 0.900\n",
      "[epoch: 98, i: 11999] avg mini-batch loss: 0.926\n",
      "[epoch: 99, i:   999] avg mini-batch loss: 0.910\n",
      "[epoch: 99, i:  1999] avg mini-batch loss: 0.911\n",
      "[epoch: 99, i:  2999] avg mini-batch loss: 0.898\n",
      "[epoch: 99, i:  3999] avg mini-batch loss: 0.973\n",
      "[epoch: 99, i:  4999] avg mini-batch loss: 0.936\n",
      "[epoch: 99, i:  5999] avg mini-batch loss: 0.954\n",
      "[epoch: 99, i:  6999] avg mini-batch loss: 0.900\n",
      "[epoch: 99, i:  7999] avg mini-batch loss: 0.910\n",
      "[epoch: 99, i:  8999] avg mini-batch loss: 0.971\n",
      "[epoch: 99, i:  9999] avg mini-batch loss: 0.940\n",
      "[epoch: 99, i: 10999] avg mini-batch loss: 0.978\n",
      "[epoch: 99, i: 11999] avg mini-batch loss: 0.903\n",
      "[epoch: 100, i:   999] avg mini-batch loss: 0.917\n",
      "[epoch: 100, i:  1999] avg mini-batch loss: 0.920\n",
      "[epoch: 100, i:  2999] avg mini-batch loss: 0.922\n",
      "[epoch: 100, i:  3999] avg mini-batch loss: 0.929\n",
      "[epoch: 100, i:  4999] avg mini-batch loss: 0.905\n",
      "[epoch: 100, i:  5999] avg mini-batch loss: 0.931\n",
      "[epoch: 100, i:  6999] avg mini-batch loss: 0.913\n",
      "[epoch: 100, i:  7999] avg mini-batch loss: 0.896\n",
      "[epoch: 100, i:  8999] avg mini-batch loss: 0.916\n",
      "[epoch: 100, i:  9999] avg mini-batch loss: 0.935\n",
      "[epoch: 100, i: 10999] avg mini-batch loss: 0.932\n",
      "[epoch: 100, i: 11999] avg mini-batch loss: 0.932\n",
      "[epoch: 101, i:   999] avg mini-batch loss: 0.939\n",
      "[epoch: 101, i:  1999] avg mini-batch loss: 0.925\n",
      "[epoch: 101, i:  2999] avg mini-batch loss: 0.882\n",
      "[epoch: 101, i:  3999] avg mini-batch loss: 0.880\n",
      "[epoch: 101, i:  4999] avg mini-batch loss: 0.885\n",
      "[epoch: 101, i:  5999] avg mini-batch loss: 0.926\n",
      "[epoch: 101, i:  6999] avg mini-batch loss: 0.905\n",
      "[epoch: 101, i:  7999] avg mini-batch loss: 0.954\n",
      "[epoch: 101, i:  8999] avg mini-batch loss: 0.922\n",
      "[epoch: 101, i:  9999] avg mini-batch loss: 0.893\n",
      "[epoch: 101, i: 10999] avg mini-batch loss: 0.941\n",
      "[epoch: 101, i: 11999] avg mini-batch loss: 0.924\n",
      "[epoch: 102, i:   999] avg mini-batch loss: 0.878\n",
      "[epoch: 102, i:  1999] avg mini-batch loss: 0.911\n",
      "[epoch: 102, i:  2999] avg mini-batch loss: 0.897\n",
      "[epoch: 102, i:  3999] avg mini-batch loss: 0.887\n",
      "[epoch: 102, i:  4999] avg mini-batch loss: 0.892\n",
      "[epoch: 102, i:  5999] avg mini-batch loss: 0.941\n",
      "[epoch: 102, i:  6999] avg mini-batch loss: 0.883\n",
      "[epoch: 102, i:  7999] avg mini-batch loss: 0.901\n",
      "[epoch: 102, i:  8999] avg mini-batch loss: 0.981\n",
      "[epoch: 102, i:  9999] avg mini-batch loss: 0.942\n",
      "[epoch: 102, i: 10999] avg mini-batch loss: 0.903\n",
      "[epoch: 102, i: 11999] avg mini-batch loss: 0.924\n",
      "[epoch: 103, i:   999] avg mini-batch loss: 0.916\n",
      "[epoch: 103, i:  1999] avg mini-batch loss: 0.928\n",
      "[epoch: 103, i:  2999] avg mini-batch loss: 0.895\n",
      "[epoch: 103, i:  3999] avg mini-batch loss: 0.897\n",
      "[epoch: 103, i:  4999] avg mini-batch loss: 0.872\n",
      "[epoch: 103, i:  5999] avg mini-batch loss: 0.910\n",
      "[epoch: 103, i:  6999] avg mini-batch loss: 0.956\n",
      "[epoch: 103, i:  7999] avg mini-batch loss: 0.885\n",
      "[epoch: 103, i:  8999] avg mini-batch loss: 0.968\n",
      "[epoch: 103, i:  9999] avg mini-batch loss: 0.914\n",
      "[epoch: 103, i: 10999] avg mini-batch loss: 0.922\n",
      "[epoch: 103, i: 11999] avg mini-batch loss: 0.954\n",
      "[epoch: 104, i:   999] avg mini-batch loss: 0.925\n",
      "[epoch: 104, i:  1999] avg mini-batch loss: 0.873\n",
      "[epoch: 104, i:  2999] avg mini-batch loss: 0.877\n",
      "[epoch: 104, i:  3999] avg mini-batch loss: 0.956\n",
      "[epoch: 104, i:  4999] avg mini-batch loss: 0.892\n",
      "[epoch: 104, i:  5999] avg mini-batch loss: 0.932\n",
      "[epoch: 104, i:  6999] avg mini-batch loss: 0.961\n",
      "[epoch: 104, i:  7999] avg mini-batch loss: 0.883\n",
      "[epoch: 104, i:  8999] avg mini-batch loss: 0.939\n",
      "[epoch: 104, i:  9999] avg mini-batch loss: 0.866\n",
      "[epoch: 104, i: 10999] avg mini-batch loss: 0.953\n",
      "[epoch: 104, i: 11999] avg mini-batch loss: 0.944\n",
      "[epoch: 105, i:   999] avg mini-batch loss: 0.847\n",
      "[epoch: 105, i:  1999] avg mini-batch loss: 0.827\n",
      "[epoch: 105, i:  2999] avg mini-batch loss: 0.917\n",
      "[epoch: 105, i:  3999] avg mini-batch loss: 0.887\n",
      "[epoch: 105, i:  4999] avg mini-batch loss: 0.918\n",
      "[epoch: 105, i:  5999] avg mini-batch loss: 0.884\n",
      "[epoch: 105, i:  6999] avg mini-batch loss: 0.872\n",
      "[epoch: 105, i:  7999] avg mini-batch loss: 0.954\n",
      "[epoch: 105, i:  8999] avg mini-batch loss: 0.893\n",
      "[epoch: 105, i:  9999] avg mini-batch loss: 0.904\n",
      "[epoch: 105, i: 10999] avg mini-batch loss: 0.902\n",
      "[epoch: 105, i: 11999] avg mini-batch loss: 0.934\n",
      "[epoch: 106, i:   999] avg mini-batch loss: 0.855\n",
      "[epoch: 106, i:  1999] avg mini-batch loss: 0.896\n",
      "[epoch: 106, i:  2999] avg mini-batch loss: 0.892\n",
      "[epoch: 106, i:  3999] avg mini-batch loss: 0.928\n",
      "[epoch: 106, i:  4999] avg mini-batch loss: 0.891\n",
      "[epoch: 106, i:  5999] avg mini-batch loss: 0.907\n",
      "[epoch: 106, i:  6999] avg mini-batch loss: 0.940\n",
      "[epoch: 106, i:  7999] avg mini-batch loss: 0.929\n",
      "[epoch: 106, i:  8999] avg mini-batch loss: 0.895\n",
      "[epoch: 106, i:  9999] avg mini-batch loss: 0.941\n",
      "[epoch: 106, i: 10999] avg mini-batch loss: 0.902\n",
      "[epoch: 106, i: 11999] avg mini-batch loss: 0.937\n",
      "[epoch: 107, i:   999] avg mini-batch loss: 0.871\n",
      "[epoch: 107, i:  1999] avg mini-batch loss: 0.940\n",
      "[epoch: 107, i:  2999] avg mini-batch loss: 0.955\n",
      "[epoch: 107, i:  3999] avg mini-batch loss: 0.913\n",
      "[epoch: 107, i:  4999] avg mini-batch loss: 0.932\n",
      "[epoch: 107, i:  5999] avg mini-batch loss: 0.947\n",
      "[epoch: 107, i:  6999] avg mini-batch loss: 0.914\n",
      "[epoch: 107, i:  7999] avg mini-batch loss: 0.931\n",
      "[epoch: 107, i:  8999] avg mini-batch loss: 0.920\n",
      "[epoch: 107, i:  9999] avg mini-batch loss: 0.913\n",
      "[epoch: 107, i: 10999] avg mini-batch loss: 0.888\n",
      "[epoch: 107, i: 11999] avg mini-batch loss: 0.934\n",
      "[epoch: 108, i:   999] avg mini-batch loss: 0.906\n",
      "[epoch: 108, i:  1999] avg mini-batch loss: 0.878\n",
      "[epoch: 108, i:  2999] avg mini-batch loss: 0.853\n",
      "[epoch: 108, i:  3999] avg mini-batch loss: 0.889\n",
      "[epoch: 108, i:  4999] avg mini-batch loss: 0.891\n",
      "[epoch: 108, i:  5999] avg mini-batch loss: 0.937\n",
      "[epoch: 108, i:  6999] avg mini-batch loss: 0.962\n",
      "[epoch: 108, i:  7999] avg mini-batch loss: 0.897\n",
      "[epoch: 108, i:  8999] avg mini-batch loss: 0.904\n",
      "[epoch: 108, i:  9999] avg mini-batch loss: 0.931\n",
      "[epoch: 108, i: 10999] avg mini-batch loss: 0.909\n",
      "[epoch: 108, i: 11999] avg mini-batch loss: 0.888\n",
      "[epoch: 109, i:   999] avg mini-batch loss: 0.888\n",
      "[epoch: 109, i:  1999] avg mini-batch loss: 0.848\n",
      "[epoch: 109, i:  2999] avg mini-batch loss: 0.854\n",
      "[epoch: 109, i:  3999] avg mini-batch loss: 0.906\n",
      "[epoch: 109, i:  4999] avg mini-batch loss: 0.939\n",
      "[epoch: 109, i:  5999] avg mini-batch loss: 0.932\n",
      "[epoch: 109, i:  6999] avg mini-batch loss: 0.948\n",
      "[epoch: 109, i:  7999] avg mini-batch loss: 0.907\n",
      "[epoch: 109, i:  8999] avg mini-batch loss: 0.932\n",
      "[epoch: 109, i:  9999] avg mini-batch loss: 0.950\n",
      "[epoch: 109, i: 10999] avg mini-batch loss: 0.941\n",
      "[epoch: 109, i: 11999] avg mini-batch loss: 0.925\n",
      "[epoch: 110, i:   999] avg mini-batch loss: 0.861\n",
      "[epoch: 110, i:  1999] avg mini-batch loss: 0.869\n",
      "[epoch: 110, i:  2999] avg mini-batch loss: 0.876\n",
      "[epoch: 110, i:  3999] avg mini-batch loss: 0.973\n",
      "[epoch: 110, i:  4999] avg mini-batch loss: 0.847\n",
      "[epoch: 110, i:  5999] avg mini-batch loss: 0.881\n",
      "[epoch: 110, i:  6999] avg mini-batch loss: 0.874\n",
      "[epoch: 110, i:  7999] avg mini-batch loss: 0.893\n",
      "[epoch: 110, i:  8999] avg mini-batch loss: 0.934\n",
      "[epoch: 110, i:  9999] avg mini-batch loss: 0.921\n",
      "[epoch: 110, i: 10999] avg mini-batch loss: 0.895\n",
      "[epoch: 110, i: 11999] avg mini-batch loss: 0.932\n",
      "[epoch: 111, i:   999] avg mini-batch loss: 0.868\n",
      "[epoch: 111, i:  1999] avg mini-batch loss: 0.848\n",
      "[epoch: 111, i:  2999] avg mini-batch loss: 0.892\n",
      "[epoch: 111, i:  3999] avg mini-batch loss: 0.872\n",
      "[epoch: 111, i:  4999] avg mini-batch loss: 0.860\n",
      "[epoch: 111, i:  5999] avg mini-batch loss: 0.932\n",
      "[epoch: 111, i:  6999] avg mini-batch loss: 0.907\n",
      "[epoch: 111, i:  7999] avg mini-batch loss: 0.938\n",
      "[epoch: 111, i:  8999] avg mini-batch loss: 0.914\n",
      "[epoch: 111, i:  9999] avg mini-batch loss: 0.924\n",
      "[epoch: 111, i: 10999] avg mini-batch loss: 0.926\n",
      "[epoch: 111, i: 11999] avg mini-batch loss: 0.892\n",
      "[epoch: 112, i:   999] avg mini-batch loss: 0.907\n",
      "[epoch: 112, i:  1999] avg mini-batch loss: 0.920\n",
      "[epoch: 112, i:  2999] avg mini-batch loss: 0.876\n",
      "[epoch: 112, i:  3999] avg mini-batch loss: 0.889\n",
      "[epoch: 112, i:  4999] avg mini-batch loss: 0.904\n",
      "[epoch: 112, i:  5999] avg mini-batch loss: 0.841\n",
      "[epoch: 112, i:  6999] avg mini-batch loss: 0.875\n",
      "[epoch: 112, i:  7999] avg mini-batch loss: 0.918\n",
      "[epoch: 112, i:  8999] avg mini-batch loss: 0.877\n",
      "[epoch: 112, i:  9999] avg mini-batch loss: 0.942\n",
      "[epoch: 112, i: 10999] avg mini-batch loss: 0.907\n",
      "[epoch: 112, i: 11999] avg mini-batch loss: 0.918\n",
      "[epoch: 113, i:   999] avg mini-batch loss: 0.916\n",
      "[epoch: 113, i:  1999] avg mini-batch loss: 0.860\n",
      "[epoch: 113, i:  2999] avg mini-batch loss: 0.900\n",
      "[epoch: 113, i:  3999] avg mini-batch loss: 0.910\n",
      "[epoch: 113, i:  4999] avg mini-batch loss: 0.860\n",
      "[epoch: 113, i:  5999] avg mini-batch loss: 0.903\n",
      "[epoch: 113, i:  6999] avg mini-batch loss: 0.887\n",
      "[epoch: 113, i:  7999] avg mini-batch loss: 0.900\n",
      "[epoch: 113, i:  8999] avg mini-batch loss: 0.887\n",
      "[epoch: 113, i:  9999] avg mini-batch loss: 0.922\n",
      "[epoch: 113, i: 10999] avg mini-batch loss: 0.901\n",
      "[epoch: 113, i: 11999] avg mini-batch loss: 0.901\n",
      "[epoch: 114, i:   999] avg mini-batch loss: 0.844\n",
      "[epoch: 114, i:  1999] avg mini-batch loss: 0.872\n",
      "[epoch: 114, i:  2999] avg mini-batch loss: 0.851\n",
      "[epoch: 114, i:  3999] avg mini-batch loss: 0.896\n",
      "[epoch: 114, i:  4999] avg mini-batch loss: 0.902\n",
      "[epoch: 114, i:  5999] avg mini-batch loss: 0.936\n",
      "[epoch: 114, i:  6999] avg mini-batch loss: 0.909\n",
      "[epoch: 114, i:  7999] avg mini-batch loss: 0.901\n",
      "[epoch: 114, i:  8999] avg mini-batch loss: 0.892\n",
      "[epoch: 114, i:  9999] avg mini-batch loss: 0.923\n",
      "[epoch: 114, i: 10999] avg mini-batch loss: 0.891\n",
      "[epoch: 114, i: 11999] avg mini-batch loss: 0.878\n",
      "[epoch: 115, i:   999] avg mini-batch loss: 0.869\n",
      "[epoch: 115, i:  1999] avg mini-batch loss: 0.858\n",
      "[epoch: 115, i:  2999] avg mini-batch loss: 0.858\n",
      "[epoch: 115, i:  3999] avg mini-batch loss: 0.874\n",
      "[epoch: 115, i:  4999] avg mini-batch loss: 0.876\n",
      "[epoch: 115, i:  5999] avg mini-batch loss: 0.869\n",
      "[epoch: 115, i:  6999] avg mini-batch loss: 0.874\n",
      "[epoch: 115, i:  7999] avg mini-batch loss: 0.965\n",
      "[epoch: 115, i:  8999] avg mini-batch loss: 0.913\n",
      "[epoch: 115, i:  9999] avg mini-batch loss: 0.908\n",
      "[epoch: 115, i: 10999] avg mini-batch loss: 0.922\n",
      "[epoch: 115, i: 11999] avg mini-batch loss: 0.921\n",
      "[epoch: 116, i:   999] avg mini-batch loss: 0.893\n",
      "[epoch: 116, i:  1999] avg mini-batch loss: 0.879\n",
      "[epoch: 116, i:  2999] avg mini-batch loss: 0.938\n",
      "[epoch: 116, i:  3999] avg mini-batch loss: 0.886\n",
      "[epoch: 116, i:  4999] avg mini-batch loss: 0.863\n",
      "[epoch: 116, i:  5999] avg mini-batch loss: 0.859\n",
      "[epoch: 116, i:  6999] avg mini-batch loss: 0.854\n",
      "[epoch: 116, i:  7999] avg mini-batch loss: 0.937\n",
      "[epoch: 116, i:  8999] avg mini-batch loss: 0.880\n",
      "[epoch: 116, i:  9999] avg mini-batch loss: 0.914\n",
      "[epoch: 116, i: 10999] avg mini-batch loss: 0.890\n",
      "[epoch: 116, i: 11999] avg mini-batch loss: 0.879\n",
      "[epoch: 117, i:   999] avg mini-batch loss: 0.935\n",
      "[epoch: 117, i:  1999] avg mini-batch loss: 0.872\n",
      "[epoch: 117, i:  2999] avg mini-batch loss: 0.909\n",
      "[epoch: 117, i:  3999] avg mini-batch loss: 0.873\n",
      "[epoch: 117, i:  4999] avg mini-batch loss: 0.895\n",
      "[epoch: 117, i:  5999] avg mini-batch loss: 0.945\n",
      "[epoch: 117, i:  6999] avg mini-batch loss: 0.881\n",
      "[epoch: 117, i:  7999] avg mini-batch loss: 0.894\n",
      "[epoch: 117, i:  8999] avg mini-batch loss: 0.887\n",
      "[epoch: 117, i:  9999] avg mini-batch loss: 0.895\n",
      "[epoch: 117, i: 10999] avg mini-batch loss: 0.895\n",
      "[epoch: 117, i: 11999] avg mini-batch loss: 0.879\n",
      "[epoch: 118, i:   999] avg mini-batch loss: 0.813\n",
      "[epoch: 118, i:  1999] avg mini-batch loss: 0.899\n",
      "[epoch: 118, i:  2999] avg mini-batch loss: 0.897\n",
      "[epoch: 118, i:  3999] avg mini-batch loss: 0.877\n",
      "[epoch: 118, i:  4999] avg mini-batch loss: 0.883\n",
      "[epoch: 118, i:  5999] avg mini-batch loss: 0.914\n",
      "[epoch: 118, i:  6999] avg mini-batch loss: 0.919\n",
      "[epoch: 118, i:  7999] avg mini-batch loss: 0.870\n",
      "[epoch: 118, i:  8999] avg mini-batch loss: 0.896\n",
      "[epoch: 118, i:  9999] avg mini-batch loss: 0.884\n",
      "[epoch: 118, i: 10999] avg mini-batch loss: 0.856\n",
      "[epoch: 118, i: 11999] avg mini-batch loss: 0.901\n",
      "[epoch: 119, i:   999] avg mini-batch loss: 0.900\n",
      "[epoch: 119, i:  1999] avg mini-batch loss: 0.877\n",
      "[epoch: 119, i:  2999] avg mini-batch loss: 0.855\n",
      "[epoch: 119, i:  3999] avg mini-batch loss: 0.834\n",
      "[epoch: 119, i:  4999] avg mini-batch loss: 0.907\n",
      "[epoch: 119, i:  5999] avg mini-batch loss: 0.917\n",
      "[epoch: 119, i:  6999] avg mini-batch loss: 0.891\n",
      "[epoch: 119, i:  7999] avg mini-batch loss: 0.913\n",
      "[epoch: 119, i:  8999] avg mini-batch loss: 0.865\n",
      "[epoch: 119, i:  9999] avg mini-batch loss: 0.908\n",
      "[epoch: 119, i: 10999] avg mini-batch loss: 0.918\n",
      "[epoch: 119, i: 11999] avg mini-batch loss: 0.978\n",
      "[epoch: 120, i:   999] avg mini-batch loss: 0.883\n",
      "[epoch: 120, i:  1999] avg mini-batch loss: 0.867\n",
      "[epoch: 120, i:  2999] avg mini-batch loss: 0.862\n",
      "[epoch: 120, i:  3999] avg mini-batch loss: 0.902\n",
      "[epoch: 120, i:  4999] avg mini-batch loss: 0.932\n",
      "[epoch: 120, i:  5999] avg mini-batch loss: 0.919\n",
      "[epoch: 120, i:  6999] avg mini-batch loss: 0.887\n",
      "[epoch: 120, i:  7999] avg mini-batch loss: 0.883\n",
      "[epoch: 120, i:  8999] avg mini-batch loss: 0.915\n",
      "[epoch: 120, i:  9999] avg mini-batch loss: 0.887\n",
      "[epoch: 120, i: 10999] avg mini-batch loss: 0.924\n",
      "[epoch: 120, i: 11999] avg mini-batch loss: 0.911\n",
      "[epoch: 121, i:   999] avg mini-batch loss: 0.878\n",
      "[epoch: 121, i:  1999] avg mini-batch loss: 0.901\n",
      "[epoch: 121, i:  2999] avg mini-batch loss: 0.873\n",
      "[epoch: 121, i:  3999] avg mini-batch loss: 0.866\n",
      "[epoch: 121, i:  4999] avg mini-batch loss: 0.849\n",
      "[epoch: 121, i:  5999] avg mini-batch loss: 0.898\n",
      "[epoch: 121, i:  6999] avg mini-batch loss: 0.862\n",
      "[epoch: 121, i:  7999] avg mini-batch loss: 0.872\n",
      "[epoch: 121, i:  8999] avg mini-batch loss: 0.883\n",
      "[epoch: 121, i:  9999] avg mini-batch loss: 0.920\n",
      "[epoch: 121, i: 10999] avg mini-batch loss: 0.889\n",
      "[epoch: 121, i: 11999] avg mini-batch loss: 0.905\n",
      "[epoch: 122, i:   999] avg mini-batch loss: 0.864\n",
      "[epoch: 122, i:  1999] avg mini-batch loss: 0.815\n",
      "[epoch: 122, i:  2999] avg mini-batch loss: 0.889\n",
      "[epoch: 122, i:  3999] avg mini-batch loss: 0.873\n",
      "[epoch: 122, i:  4999] avg mini-batch loss: 0.898\n",
      "[epoch: 122, i:  5999] avg mini-batch loss: 0.863\n",
      "[epoch: 122, i:  6999] avg mini-batch loss: 0.888\n",
      "[epoch: 122, i:  7999] avg mini-batch loss: 0.873\n",
      "[epoch: 122, i:  8999] avg mini-batch loss: 0.852\n",
      "[epoch: 122, i:  9999] avg mini-batch loss: 0.880\n",
      "[epoch: 122, i: 10999] avg mini-batch loss: 0.882\n",
      "[epoch: 122, i: 11999] avg mini-batch loss: 0.878\n",
      "[epoch: 123, i:   999] avg mini-batch loss: 0.861\n",
      "[epoch: 123, i:  1999] avg mini-batch loss: 0.895\n",
      "[epoch: 123, i:  2999] avg mini-batch loss: 0.833\n",
      "[epoch: 123, i:  3999] avg mini-batch loss: 0.838\n",
      "[epoch: 123, i:  4999] avg mini-batch loss: 0.849\n",
      "[epoch: 123, i:  5999] avg mini-batch loss: 0.867\n",
      "[epoch: 123, i:  6999] avg mini-batch loss: 0.902\n",
      "[epoch: 123, i:  7999] avg mini-batch loss: 0.892\n",
      "[epoch: 123, i:  8999] avg mini-batch loss: 0.894\n",
      "[epoch: 123, i:  9999] avg mini-batch loss: 0.879\n",
      "[epoch: 123, i: 10999] avg mini-batch loss: 0.895\n",
      "[epoch: 123, i: 11999] avg mini-batch loss: 0.917\n",
      "[epoch: 124, i:   999] avg mini-batch loss: 0.884\n",
      "[epoch: 124, i:  1999] avg mini-batch loss: 0.872\n",
      "[epoch: 124, i:  2999] avg mini-batch loss: 0.867\n",
      "[epoch: 124, i:  3999] avg mini-batch loss: 0.910\n",
      "[epoch: 124, i:  4999] avg mini-batch loss: 0.859\n",
      "[epoch: 124, i:  5999] avg mini-batch loss: 0.828\n",
      "[epoch: 124, i:  6999] avg mini-batch loss: 0.934\n",
      "[epoch: 124, i:  7999] avg mini-batch loss: 0.842\n",
      "[epoch: 124, i:  8999] avg mini-batch loss: 0.892\n",
      "[epoch: 124, i:  9999] avg mini-batch loss: 0.904\n",
      "[epoch: 124, i: 10999] avg mini-batch loss: 0.923\n",
      "[epoch: 124, i: 11999] avg mini-batch loss: 0.847\n",
      "[epoch: 125, i:   999] avg mini-batch loss: 0.842\n",
      "[epoch: 125, i:  1999] avg mini-batch loss: 0.898\n",
      "[epoch: 125, i:  2999] avg mini-batch loss: 0.823\n",
      "[epoch: 125, i:  3999] avg mini-batch loss: 0.920\n",
      "[epoch: 125, i:  4999] avg mini-batch loss: 0.929\n",
      "[epoch: 125, i:  5999] avg mini-batch loss: 0.834\n",
      "[epoch: 125, i:  6999] avg mini-batch loss: 0.881\n",
      "[epoch: 125, i:  7999] avg mini-batch loss: 0.845\n",
      "[epoch: 125, i:  8999] avg mini-batch loss: 0.917\n",
      "[epoch: 125, i:  9999] avg mini-batch loss: 0.910\n",
      "[epoch: 125, i: 10999] avg mini-batch loss: 0.906\n",
      "[epoch: 125, i: 11999] avg mini-batch loss: 0.920\n",
      "[epoch: 126, i:   999] avg mini-batch loss: 0.909\n",
      "[epoch: 126, i:  1999] avg mini-batch loss: 0.845\n",
      "[epoch: 126, i:  2999] avg mini-batch loss: 0.838\n",
      "[epoch: 126, i:  3999] avg mini-batch loss: 0.826\n",
      "[epoch: 126, i:  4999] avg mini-batch loss: 0.871\n",
      "[epoch: 126, i:  5999] avg mini-batch loss: 0.916\n",
      "[epoch: 126, i:  6999] avg mini-batch loss: 0.887\n",
      "[epoch: 126, i:  7999] avg mini-batch loss: 0.893\n",
      "[epoch: 126, i:  8999] avg mini-batch loss: 0.847\n",
      "[epoch: 126, i:  9999] avg mini-batch loss: 0.896\n",
      "[epoch: 126, i: 10999] avg mini-batch loss: 0.894\n",
      "[epoch: 126, i: 11999] avg mini-batch loss: 0.873\n",
      "[epoch: 127, i:   999] avg mini-batch loss: 0.868\n",
      "[epoch: 127, i:  1999] avg mini-batch loss: 0.918\n",
      "[epoch: 127, i:  2999] avg mini-batch loss: 0.837\n",
      "[epoch: 127, i:  3999] avg mini-batch loss: 0.841\n",
      "[epoch: 127, i:  4999] avg mini-batch loss: 0.877\n",
      "[epoch: 127, i:  5999] avg mini-batch loss: 0.862\n",
      "[epoch: 127, i:  6999] avg mini-batch loss: 0.898\n",
      "[epoch: 127, i:  7999] avg mini-batch loss: 0.884\n",
      "[epoch: 127, i:  8999] avg mini-batch loss: 0.902\n",
      "[epoch: 127, i:  9999] avg mini-batch loss: 0.912\n",
      "[epoch: 127, i: 10999] avg mini-batch loss: 0.882\n",
      "[epoch: 127, i: 11999] avg mini-batch loss: 0.950\n",
      "[epoch: 128, i:   999] avg mini-batch loss: 0.896\n",
      "[epoch: 128, i:  1999] avg mini-batch loss: 0.821\n",
      "[epoch: 128, i:  2999] avg mini-batch loss: 0.865\n",
      "[epoch: 128, i:  3999] avg mini-batch loss: 0.895\n",
      "[epoch: 128, i:  4999] avg mini-batch loss: 0.875\n",
      "[epoch: 128, i:  5999] avg mini-batch loss: 0.895\n",
      "[epoch: 128, i:  6999] avg mini-batch loss: 0.868\n",
      "[epoch: 128, i:  7999] avg mini-batch loss: 0.869\n",
      "[epoch: 128, i:  8999] avg mini-batch loss: 0.872\n",
      "[epoch: 128, i:  9999] avg mini-batch loss: 0.869\n",
      "[epoch: 128, i: 10999] avg mini-batch loss: 0.912\n",
      "[epoch: 128, i: 11999] avg mini-batch loss: 0.891\n",
      "[epoch: 129, i:   999] avg mini-batch loss: 0.863\n",
      "[epoch: 129, i:  1999] avg mini-batch loss: 0.873\n",
      "[epoch: 129, i:  2999] avg mini-batch loss: 0.865\n",
      "[epoch: 129, i:  3999] avg mini-batch loss: 0.875\n",
      "[epoch: 129, i:  4999] avg mini-batch loss: 0.857\n",
      "[epoch: 129, i:  5999] avg mini-batch loss: 0.829\n",
      "[epoch: 129, i:  6999] avg mini-batch loss: 0.863\n",
      "[epoch: 129, i:  7999] avg mini-batch loss: 0.837\n",
      "[epoch: 129, i:  8999] avg mini-batch loss: 0.870\n",
      "[epoch: 129, i:  9999] avg mini-batch loss: 0.859\n",
      "[epoch: 129, i: 10999] avg mini-batch loss: 0.937\n",
      "[epoch: 129, i: 11999] avg mini-batch loss: 0.883\n",
      "[epoch: 130, i:   999] avg mini-batch loss: 0.856\n",
      "[epoch: 130, i:  1999] avg mini-batch loss: 0.884\n",
      "[epoch: 130, i:  2999] avg mini-batch loss: 0.837\n",
      "[epoch: 130, i:  3999] avg mini-batch loss: 0.879\n",
      "[epoch: 130, i:  4999] avg mini-batch loss: 0.929\n",
      "[epoch: 130, i:  5999] avg mini-batch loss: 0.897\n",
      "[epoch: 130, i:  6999] avg mini-batch loss: 0.834\n",
      "[epoch: 130, i:  7999] avg mini-batch loss: 0.879\n",
      "[epoch: 130, i:  8999] avg mini-batch loss: 0.842\n",
      "[epoch: 130, i:  9999] avg mini-batch loss: 0.891\n",
      "[epoch: 130, i: 10999] avg mini-batch loss: 0.841\n",
      "[epoch: 130, i: 11999] avg mini-batch loss: 0.868\n",
      "[epoch: 131, i:   999] avg mini-batch loss: 0.830\n",
      "[epoch: 131, i:  1999] avg mini-batch loss: 0.875\n",
      "[epoch: 131, i:  2999] avg mini-batch loss: 0.845\n",
      "[epoch: 131, i:  3999] avg mini-batch loss: 0.860\n",
      "[epoch: 131, i:  4999] avg mini-batch loss: 0.870\n",
      "[epoch: 131, i:  5999] avg mini-batch loss: 0.894\n",
      "[epoch: 131, i:  6999] avg mini-batch loss: 0.850\n",
      "[epoch: 131, i:  7999] avg mini-batch loss: 0.876\n",
      "[epoch: 131, i:  8999] avg mini-batch loss: 0.915\n",
      "[epoch: 131, i:  9999] avg mini-batch loss: 0.885\n",
      "[epoch: 131, i: 10999] avg mini-batch loss: 0.923\n",
      "[epoch: 131, i: 11999] avg mini-batch loss: 0.913\n",
      "[epoch: 132, i:   999] avg mini-batch loss: 0.850\n",
      "[epoch: 132, i:  1999] avg mini-batch loss: 0.846\n",
      "[epoch: 132, i:  2999] avg mini-batch loss: 0.824\n",
      "[epoch: 132, i:  3999] avg mini-batch loss: 0.833\n",
      "[epoch: 132, i:  4999] avg mini-batch loss: 0.835\n",
      "[epoch: 132, i:  5999] avg mini-batch loss: 0.832\n",
      "[epoch: 132, i:  6999] avg mini-batch loss: 0.898\n",
      "[epoch: 132, i:  7999] avg mini-batch loss: 0.880\n",
      "[epoch: 132, i:  8999] avg mini-batch loss: 0.834\n",
      "[epoch: 132, i:  9999] avg mini-batch loss: 0.838\n",
      "[epoch: 132, i: 10999] avg mini-batch loss: 0.910\n",
      "[epoch: 132, i: 11999] avg mini-batch loss: 0.909\n",
      "[epoch: 133, i:   999] avg mini-batch loss: 0.856\n",
      "[epoch: 133, i:  1999] avg mini-batch loss: 0.861\n",
      "[epoch: 133, i:  2999] avg mini-batch loss: 0.920\n",
      "[epoch: 133, i:  3999] avg mini-batch loss: 0.874\n",
      "[epoch: 133, i:  4999] avg mini-batch loss: 0.853\n",
      "[epoch: 133, i:  5999] avg mini-batch loss: 0.841\n",
      "[epoch: 133, i:  6999] avg mini-batch loss: 0.880\n",
      "[epoch: 133, i:  7999] avg mini-batch loss: 0.826\n",
      "[epoch: 133, i:  8999] avg mini-batch loss: 0.943\n",
      "[epoch: 133, i:  9999] avg mini-batch loss: 0.966\n",
      "[epoch: 133, i: 10999] avg mini-batch loss: 0.890\n",
      "[epoch: 133, i: 11999] avg mini-batch loss: 0.897\n",
      "[epoch: 134, i:   999] avg mini-batch loss: 0.897\n",
      "[epoch: 134, i:  1999] avg mini-batch loss: 0.846\n",
      "[epoch: 134, i:  2999] avg mini-batch loss: 0.876\n",
      "[epoch: 134, i:  3999] avg mini-batch loss: 0.880\n",
      "[epoch: 134, i:  4999] avg mini-batch loss: 0.914\n",
      "[epoch: 134, i:  5999] avg mini-batch loss: 0.894\n",
      "[epoch: 134, i:  6999] avg mini-batch loss: 0.837\n",
      "[epoch: 134, i:  7999] avg mini-batch loss: 0.885\n",
      "[epoch: 134, i:  8999] avg mini-batch loss: 0.865\n",
      "[epoch: 134, i:  9999] avg mini-batch loss: 0.901\n",
      "[epoch: 134, i: 10999] avg mini-batch loss: 0.881\n",
      "[epoch: 134, i: 11999] avg mini-batch loss: 0.846\n",
      "[epoch: 135, i:   999] avg mini-batch loss: 0.874\n",
      "[epoch: 135, i:  1999] avg mini-batch loss: 0.837\n",
      "[epoch: 135, i:  2999] avg mini-batch loss: 0.869\n",
      "[epoch: 135, i:  3999] avg mini-batch loss: 0.870\n",
      "[epoch: 135, i:  4999] avg mini-batch loss: 0.840\n",
      "[epoch: 135, i:  5999] avg mini-batch loss: 0.863\n",
      "[epoch: 135, i:  6999] avg mini-batch loss: 0.833\n",
      "[epoch: 135, i:  7999] avg mini-batch loss: 0.820\n",
      "[epoch: 135, i:  8999] avg mini-batch loss: 0.886\n",
      "[epoch: 135, i:  9999] avg mini-batch loss: 0.885\n",
      "[epoch: 135, i: 10999] avg mini-batch loss: 0.850\n",
      "[epoch: 135, i: 11999] avg mini-batch loss: 0.891\n",
      "[epoch: 136, i:   999] avg mini-batch loss: 0.871\n",
      "[epoch: 136, i:  1999] avg mini-batch loss: 0.862\n",
      "[epoch: 136, i:  2999] avg mini-batch loss: 0.868\n",
      "[epoch: 136, i:  3999] avg mini-batch loss: 0.860\n",
      "[epoch: 136, i:  4999] avg mini-batch loss: 0.827\n",
      "[epoch: 136, i:  5999] avg mini-batch loss: 0.897\n",
      "[epoch: 136, i:  6999] avg mini-batch loss: 0.825\n",
      "[epoch: 136, i:  7999] avg mini-batch loss: 0.843\n",
      "[epoch: 136, i:  8999] avg mini-batch loss: 0.851\n",
      "[epoch: 136, i:  9999] avg mini-batch loss: 0.895\n",
      "[epoch: 136, i: 10999] avg mini-batch loss: 0.866\n",
      "[epoch: 136, i: 11999] avg mini-batch loss: 0.895\n",
      "[epoch: 137, i:   999] avg mini-batch loss: 0.859\n",
      "[epoch: 137, i:  1999] avg mini-batch loss: 0.837\n",
      "[epoch: 137, i:  2999] avg mini-batch loss: 0.853\n",
      "[epoch: 137, i:  3999] avg mini-batch loss: 0.860\n",
      "[epoch: 137, i:  4999] avg mini-batch loss: 0.871\n",
      "[epoch: 137, i:  5999] avg mini-batch loss: 0.847\n",
      "[epoch: 137, i:  6999] avg mini-batch loss: 0.890\n",
      "[epoch: 137, i:  7999] avg mini-batch loss: 0.895\n",
      "[epoch: 137, i:  8999] avg mini-batch loss: 0.872\n",
      "[epoch: 137, i:  9999] avg mini-batch loss: 0.876\n",
      "[epoch: 137, i: 10999] avg mini-batch loss: 0.844\n",
      "[epoch: 137, i: 11999] avg mini-batch loss: 0.864\n",
      "[epoch: 138, i:   999] avg mini-batch loss: 0.813\n",
      "[epoch: 138, i:  1999] avg mini-batch loss: 0.833\n",
      "[epoch: 138, i:  2999] avg mini-batch loss: 0.857\n",
      "[epoch: 138, i:  3999] avg mini-batch loss: 0.813\n",
      "[epoch: 138, i:  4999] avg mini-batch loss: 0.840\n",
      "[epoch: 138, i:  5999] avg mini-batch loss: 0.858\n",
      "[epoch: 138, i:  6999] avg mini-batch loss: 0.850\n",
      "[epoch: 138, i:  7999] avg mini-batch loss: 0.830\n",
      "[epoch: 138, i:  8999] avg mini-batch loss: 0.875\n",
      "[epoch: 138, i:  9999] avg mini-batch loss: 0.877\n",
      "[epoch: 138, i: 10999] avg mini-batch loss: 0.957\n",
      "[epoch: 138, i: 11999] avg mini-batch loss: 0.892\n",
      "[epoch: 139, i:   999] avg mini-batch loss: 0.865\n",
      "[epoch: 139, i:  1999] avg mini-batch loss: 0.875\n",
      "[epoch: 139, i:  2999] avg mini-batch loss: 0.897\n",
      "[epoch: 139, i:  3999] avg mini-batch loss: 0.870\n",
      "[epoch: 139, i:  4999] avg mini-batch loss: 0.852\n",
      "[epoch: 139, i:  5999] avg mini-batch loss: 0.866\n",
      "[epoch: 139, i:  6999] avg mini-batch loss: 0.901\n",
      "[epoch: 139, i:  7999] avg mini-batch loss: 0.821\n",
      "[epoch: 139, i:  8999] avg mini-batch loss: 0.855\n",
      "[epoch: 139, i:  9999] avg mini-batch loss: 0.824\n",
      "[epoch: 139, i: 10999] avg mini-batch loss: 0.880\n",
      "[epoch: 139, i: 11999] avg mini-batch loss: 0.866\n",
      "[epoch: 140, i:   999] avg mini-batch loss: 0.845\n",
      "[epoch: 140, i:  1999] avg mini-batch loss: 0.909\n",
      "[epoch: 140, i:  2999] avg mini-batch loss: 0.879\n",
      "[epoch: 140, i:  3999] avg mini-batch loss: 0.865\n",
      "[epoch: 140, i:  4999] avg mini-batch loss: 0.873\n",
      "[epoch: 140, i:  5999] avg mini-batch loss: 0.856\n",
      "[epoch: 140, i:  6999] avg mini-batch loss: 0.860\n",
      "[epoch: 140, i:  7999] avg mini-batch loss: 0.842\n",
      "[epoch: 140, i:  8999] avg mini-batch loss: 0.876\n",
      "[epoch: 140, i:  9999] avg mini-batch loss: 0.883\n",
      "[epoch: 140, i: 10999] avg mini-batch loss: 0.877\n",
      "[epoch: 140, i: 11999] avg mini-batch loss: 0.905\n",
      "[epoch: 141, i:   999] avg mini-batch loss: 0.861\n",
      "[epoch: 141, i:  1999] avg mini-batch loss: 0.833\n",
      "[epoch: 141, i:  2999] avg mini-batch loss: 0.837\n",
      "[epoch: 141, i:  3999] avg mini-batch loss: 0.868\n",
      "[epoch: 141, i:  4999] avg mini-batch loss: 0.879\n",
      "[epoch: 141, i:  5999] avg mini-batch loss: 0.851\n",
      "[epoch: 141, i:  6999] avg mini-batch loss: 0.852\n",
      "[epoch: 141, i:  7999] avg mini-batch loss: 0.860\n",
      "[epoch: 141, i:  8999] avg mini-batch loss: 0.926\n",
      "[epoch: 141, i:  9999] avg mini-batch loss: 0.881\n",
      "[epoch: 141, i: 10999] avg mini-batch loss: 0.827\n",
      "[epoch: 141, i: 11999] avg mini-batch loss: 0.898\n",
      "[epoch: 142, i:   999] avg mini-batch loss: 0.838\n",
      "[epoch: 142, i:  1999] avg mini-batch loss: 0.850\n",
      "[epoch: 142, i:  2999] avg mini-batch loss: 0.843\n",
      "[epoch: 142, i:  3999] avg mini-batch loss: 0.862\n",
      "[epoch: 142, i:  4999] avg mini-batch loss: 0.859\n",
      "[epoch: 142, i:  5999] avg mini-batch loss: 0.858\n",
      "[epoch: 142, i:  6999] avg mini-batch loss: 0.838\n",
      "[epoch: 142, i:  7999] avg mini-batch loss: 0.853\n",
      "[epoch: 142, i:  8999] avg mini-batch loss: 0.960\n",
      "[epoch: 142, i:  9999] avg mini-batch loss: 0.838\n",
      "[epoch: 142, i: 10999] avg mini-batch loss: 0.907\n",
      "[epoch: 142, i: 11999] avg mini-batch loss: 0.916\n",
      "[epoch: 143, i:   999] avg mini-batch loss: 0.817\n",
      "[epoch: 143, i:  1999] avg mini-batch loss: 0.896\n",
      "[epoch: 143, i:  2999] avg mini-batch loss: 0.851\n",
      "[epoch: 143, i:  3999] avg mini-batch loss: 0.849\n",
      "[epoch: 143, i:  4999] avg mini-batch loss: 0.844\n",
      "[epoch: 143, i:  5999] avg mini-batch loss: 0.833\n",
      "[epoch: 143, i:  6999] avg mini-batch loss: 0.855\n",
      "[epoch: 143, i:  7999] avg mini-batch loss: 0.867\n",
      "[epoch: 143, i:  8999] avg mini-batch loss: 0.897\n",
      "[epoch: 143, i:  9999] avg mini-batch loss: 0.910\n",
      "[epoch: 143, i: 10999] avg mini-batch loss: 0.872\n",
      "[epoch: 143, i: 11999] avg mini-batch loss: 0.889\n",
      "[epoch: 144, i:   999] avg mini-batch loss: 0.808\n",
      "[epoch: 144, i:  1999] avg mini-batch loss: 0.850\n",
      "[epoch: 144, i:  2999] avg mini-batch loss: 0.853\n",
      "[epoch: 144, i:  3999] avg mini-batch loss: 0.830\n",
      "[epoch: 144, i:  4999] avg mini-batch loss: 0.866\n",
      "[epoch: 144, i:  5999] avg mini-batch loss: 0.878\n",
      "[epoch: 144, i:  6999] avg mini-batch loss: 0.831\n",
      "[epoch: 144, i:  7999] avg mini-batch loss: 0.875\n",
      "[epoch: 144, i:  8999] avg mini-batch loss: 0.863\n",
      "[epoch: 144, i:  9999] avg mini-batch loss: 0.865\n",
      "[epoch: 144, i: 10999] avg mini-batch loss: 0.842\n",
      "[epoch: 144, i: 11999] avg mini-batch loss: 0.851\n",
      "[epoch: 145, i:   999] avg mini-batch loss: 0.853\n",
      "[epoch: 145, i:  1999] avg mini-batch loss: 0.876\n",
      "[epoch: 145, i:  2999] avg mini-batch loss: 0.886\n",
      "[epoch: 145, i:  3999] avg mini-batch loss: 0.847\n",
      "[epoch: 145, i:  4999] avg mini-batch loss: 0.879\n",
      "[epoch: 145, i:  5999] avg mini-batch loss: 0.900\n",
      "[epoch: 145, i:  6999] avg mini-batch loss: 0.820\n",
      "[epoch: 145, i:  7999] avg mini-batch loss: 0.876\n",
      "[epoch: 145, i:  8999] avg mini-batch loss: 0.856\n",
      "[epoch: 145, i:  9999] avg mini-batch loss: 0.847\n",
      "[epoch: 145, i: 10999] avg mini-batch loss: 0.834\n",
      "[epoch: 145, i: 11999] avg mini-batch loss: 0.865\n",
      "[epoch: 146, i:   999] avg mini-batch loss: 0.815\n",
      "[epoch: 146, i:  1999] avg mini-batch loss: 0.860\n",
      "[epoch: 146, i:  2999] avg mini-batch loss: 0.874\n",
      "[epoch: 146, i:  3999] avg mini-batch loss: 0.889\n",
      "[epoch: 146, i:  4999] avg mini-batch loss: 0.857\n",
      "[epoch: 146, i:  5999] avg mini-batch loss: 0.914\n",
      "[epoch: 146, i:  6999] avg mini-batch loss: 0.835\n",
      "[epoch: 146, i:  7999] avg mini-batch loss: 0.854\n",
      "[epoch: 146, i:  8999] avg mini-batch loss: 0.882\n",
      "[epoch: 146, i:  9999] avg mini-batch loss: 0.847\n",
      "[epoch: 146, i: 10999] avg mini-batch loss: 0.898\n",
      "[epoch: 146, i: 11999] avg mini-batch loss: 0.880\n",
      "[epoch: 147, i:   999] avg mini-batch loss: 0.828\n",
      "[epoch: 147, i:  1999] avg mini-batch loss: 0.874\n",
      "[epoch: 147, i:  2999] avg mini-batch loss: 0.905\n",
      "[epoch: 147, i:  3999] avg mini-batch loss: 0.882\n",
      "[epoch: 147, i:  4999] avg mini-batch loss: 0.821\n",
      "[epoch: 147, i:  5999] avg mini-batch loss: 0.824\n",
      "[epoch: 147, i:  6999] avg mini-batch loss: 0.857\n",
      "[epoch: 147, i:  7999] avg mini-batch loss: 0.814\n",
      "[epoch: 147, i:  8999] avg mini-batch loss: 0.844\n",
      "[epoch: 147, i:  9999] avg mini-batch loss: 0.891\n",
      "[epoch: 147, i: 10999] avg mini-batch loss: 0.893\n",
      "[epoch: 147, i: 11999] avg mini-batch loss: 0.872\n",
      "[epoch: 148, i:   999] avg mini-batch loss: 0.799\n",
      "[epoch: 148, i:  1999] avg mini-batch loss: 0.864\n",
      "[epoch: 148, i:  2999] avg mini-batch loss: 0.867\n",
      "[epoch: 148, i:  3999] avg mini-batch loss: 0.855\n",
      "[epoch: 148, i:  4999] avg mini-batch loss: 0.872\n",
      "[epoch: 148, i:  5999] avg mini-batch loss: 0.854\n",
      "[epoch: 148, i:  6999] avg mini-batch loss: 0.839\n",
      "[epoch: 148, i:  7999] avg mini-batch loss: 0.812\n",
      "[epoch: 148, i:  8999] avg mini-batch loss: 0.858\n",
      "[epoch: 148, i:  9999] avg mini-batch loss: 0.920\n",
      "[epoch: 148, i: 10999] avg mini-batch loss: 0.919\n",
      "[epoch: 148, i: 11999] avg mini-batch loss: 0.876\n",
      "[epoch: 149, i:   999] avg mini-batch loss: 0.784\n",
      "[epoch: 149, i:  1999] avg mini-batch loss: 0.799\n",
      "[epoch: 149, i:  2999] avg mini-batch loss: 0.858\n",
      "[epoch: 149, i:  3999] avg mini-batch loss: 0.851\n",
      "[epoch: 149, i:  4999] avg mini-batch loss: 0.839\n",
      "[epoch: 149, i:  5999] avg mini-batch loss: 0.809\n",
      "[epoch: 149, i:  6999] avg mini-batch loss: 0.864\n",
      "[epoch: 149, i:  7999] avg mini-batch loss: 0.920\n",
      "[epoch: 149, i:  8999] avg mini-batch loss: 0.877\n",
      "[epoch: 149, i:  9999] avg mini-batch loss: 0.835\n",
      "[epoch: 149, i: 10999] avg mini-batch loss: 0.864\n",
      "[epoch: 149, i: 11999] avg mini-batch loss: 0.844\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 150       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e936ee",
   "metadata": {},
   "source": [
    "## Plotting Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ef7844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09a649",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1f3a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 45 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d758a2bd",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "I used the original AlexNet architecture, but removed dropout and instead used two layers of batch normalization. Everything else remains similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79694e82",
   "metadata": {},
   "source": [
    "## Results\n",
    "After running the model over 150 epochs, we achieve a test accuracy of 45%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
