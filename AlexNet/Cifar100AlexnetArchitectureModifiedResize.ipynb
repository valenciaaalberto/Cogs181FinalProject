{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f8043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c48cef",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a702576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Resize((224,224),antialias=True),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', \n",
    "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', \n",
    "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', \n",
    "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', \n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', \n",
    "    'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "    'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "    'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "    'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', \n",
    "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n",
    "    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', \n",
    "    'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', \n",
    "    'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', \n",
    "    'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', \n",
    "    'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0e50d",
   "metadata": {},
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e6776c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e7ed3f",
   "metadata": {},
   "source": [
    "## Modified AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2102b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_layer_one): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
       "  (conv_layer_two): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv_layer_three): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_four): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_layer_five): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (fc3): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  (fc4): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (fc5): Linear(in_features=500, out_features=100, bias=True)\n",
       "  (batchNorm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchNorm2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11 , stride=4, padding=1)\n",
    "        self.conv_layer_two = nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5, stride=1, padding=2)\n",
    "        self.conv_layer_three = nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_four = nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer_five = nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(6400, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 1000)\n",
    "        self.fc4 = nn.Linear(1000, 500)\n",
    "        self.fc5 = nn.Linear(500, 100)\n",
    "        \n",
    "        self.batchNorm1 = nn.BatchNorm2d(3)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(384)\n",
    "  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batchNorm1(x)\n",
    "        x = self.conv_layer_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(3,3),stride=2)\n",
    "        \n",
    "        x = self.conv_layer_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(3,3),stride=2)\n",
    "        \n",
    "        x = self.conv_layer_three(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.batchNorm2(x)\n",
    "        x = self.conv_layer_four(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv_layer_five(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,(3,3),stride=2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.fc5(x)    \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12d8556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d17361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:   999] avg mini-batch loss: 4.604\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 4.601\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 4.517\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 4.331\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 4.222\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 4.149\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 4.108\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 4.060\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 3.991\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 3.961\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 3.896\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 3.856\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 3.749\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 3.670\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 3.631\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 3.554\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 3.511\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 3.501\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 3.488\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 3.386\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 3.343\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 3.358\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 3.310\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 3.257\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 3.124\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 3.086\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 3.051\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 3.029\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 2.974\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 2.966\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 2.950\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 2.895\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 2.834\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 2.843\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 2.787\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 2.757\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 2.571\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 2.546\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 2.554\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 2.515\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 2.516\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 2.485\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 2.481\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 2.479\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 2.434\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 2.384\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 2.387\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 2.402\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 2.034\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 2.126\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 2.060\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 2.054\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 2.098\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 2.076\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 2.084\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 2.069\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 2.036\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 2.040\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 2.064\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 2.072\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 1.583\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 1.641\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 1.636\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 1.636\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 1.690\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 1.697\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 1.667\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 1.674\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 1.703\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 1.722\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 1.715\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 1.713\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 1.161\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 1.238\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 1.224\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 1.248\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 1.272\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 1.310\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 1.266\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 1.374\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 1.338\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 1.358\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 1.368\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 1.369\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 0.808\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 0.812\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 0.882\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 0.926\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 0.936\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 0.938\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 0.987\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 1.017\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 0.987\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 1.019\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 1.018\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 1.039\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 0.592\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 0.612\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 0.601\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 0.613\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 0.632\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 0.664\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 0.701\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 0.725\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 0.777\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 0.741\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 0.781\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 0.773\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 0.396\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 0.386\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 0.427\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 0.468\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 0.427\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 0.493\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 0.546\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 0.560\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 0.564\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 0.544\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 0.568\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 0.569\n",
      "[epoch: 10, i:   999] avg mini-batch loss: 0.291\n",
      "[epoch: 10, i:  1999] avg mini-batch loss: 0.295\n",
      "[epoch: 10, i:  2999] avg mini-batch loss: 0.496\n",
      "[epoch: 10, i:  3999] avg mini-batch loss: 0.407\n",
      "[epoch: 10, i:  4999] avg mini-batch loss: 0.388\n",
      "[epoch: 10, i:  5999] avg mini-batch loss: 0.421\n",
      "[epoch: 10, i:  6999] avg mini-batch loss: 0.454\n",
      "[epoch: 10, i:  7999] avg mini-batch loss: 0.427\n",
      "[epoch: 10, i:  8999] avg mini-batch loss: 0.447\n",
      "[epoch: 10, i:  9999] avg mini-batch loss: 0.469\n",
      "[epoch: 10, i: 10999] avg mini-batch loss: 0.508\n",
      "[epoch: 10, i: 11999] avg mini-batch loss: 0.498\n",
      "[epoch: 11, i:   999] avg mini-batch loss: 0.236\n",
      "[epoch: 11, i:  1999] avg mini-batch loss: 0.242\n",
      "[epoch: 11, i:  2999] avg mini-batch loss: 0.268\n",
      "[epoch: 11, i:  3999] avg mini-batch loss: 0.261\n",
      "[epoch: 11, i:  4999] avg mini-batch loss: 0.264\n",
      "[epoch: 11, i:  5999] avg mini-batch loss: 0.252\n",
      "[epoch: 11, i:  6999] avg mini-batch loss: 0.283\n",
      "[epoch: 11, i:  7999] avg mini-batch loss: 0.265\n",
      "[epoch: 11, i:  8999] avg mini-batch loss: 0.287\n",
      "[epoch: 11, i:  9999] avg mini-batch loss: 0.330\n",
      "[epoch: 11, i: 10999] avg mini-batch loss: 0.327\n",
      "[epoch: 11, i: 11999] avg mini-batch loss: 0.330\n",
      "[epoch: 12, i:   999] avg mini-batch loss: 0.172\n",
      "[epoch: 12, i:  1999] avg mini-batch loss: 0.166\n",
      "[epoch: 12, i:  2999] avg mini-batch loss: 0.172\n",
      "[epoch: 12, i:  3999] avg mini-batch loss: 0.214\n",
      "[epoch: 12, i:  4999] avg mini-batch loss: 0.209\n",
      "[epoch: 12, i:  5999] avg mini-batch loss: 0.165\n",
      "[epoch: 12, i:  6999] avg mini-batch loss: 0.218\n",
      "[epoch: 12, i:  7999] avg mini-batch loss: 0.236\n",
      "[epoch: 12, i:  8999] avg mini-batch loss: 0.213\n",
      "[epoch: 12, i:  9999] avg mini-batch loss: 0.236\n",
      "[epoch: 12, i: 10999] avg mini-batch loss: 0.242\n",
      "[epoch: 12, i: 11999] avg mini-batch loss: 0.264\n",
      "[epoch: 13, i:   999] avg mini-batch loss: 0.129\n",
      "[epoch: 13, i:  1999] avg mini-batch loss: 0.138\n",
      "[epoch: 13, i:  2999] avg mini-batch loss: 0.160\n",
      "[epoch: 13, i:  3999] avg mini-batch loss: 0.149\n",
      "[epoch: 13, i:  4999] avg mini-batch loss: 0.158\n",
      "[epoch: 13, i:  5999] avg mini-batch loss: 0.174\n",
      "[epoch: 13, i:  6999] avg mini-batch loss: 0.199\n",
      "[epoch: 13, i:  7999] avg mini-batch loss: 0.204\n",
      "[epoch: 13, i:  8999] avg mini-batch loss: 0.174\n",
      "[epoch: 13, i:  9999] avg mini-batch loss: 0.208\n",
      "[epoch: 13, i: 10999] avg mini-batch loss: 0.196\n",
      "[epoch: 13, i: 11999] avg mini-batch loss: 0.234\n",
      "[epoch: 14, i:   999] avg mini-batch loss: 0.118\n",
      "[epoch: 14, i:  1999] avg mini-batch loss: 0.154\n",
      "[epoch: 14, i:  2999] avg mini-batch loss: 0.109\n",
      "[epoch: 14, i:  3999] avg mini-batch loss: 0.153\n",
      "[epoch: 14, i:  4999] avg mini-batch loss: 0.144\n",
      "[epoch: 14, i:  5999] avg mini-batch loss: 0.146\n",
      "[epoch: 14, i:  6999] avg mini-batch loss: 0.144\n",
      "[epoch: 14, i:  7999] avg mini-batch loss: 0.160\n",
      "[epoch: 14, i:  8999] avg mini-batch loss: 0.154\n",
      "[epoch: 14, i:  9999] avg mini-batch loss: 0.144\n",
      "[epoch: 14, i: 10999] avg mini-batch loss: 0.153\n",
      "[epoch: 14, i: 11999] avg mini-batch loss: 0.145\n",
      "[epoch: 15, i:   999] avg mini-batch loss: 0.078\n",
      "[epoch: 15, i:  1999] avg mini-batch loss: 0.082\n",
      "[epoch: 15, i:  2999] avg mini-batch loss: 0.126\n",
      "[epoch: 15, i:  3999] avg mini-batch loss: 0.129\n",
      "[epoch: 15, i:  4999] avg mini-batch loss: 0.124\n",
      "[epoch: 15, i:  5999] avg mini-batch loss: 0.131\n",
      "[epoch: 15, i:  6999] avg mini-batch loss: 0.123\n",
      "[epoch: 15, i:  7999] avg mini-batch loss: 0.133\n",
      "[epoch: 15, i:  8999] avg mini-batch loss: 0.123\n",
      "[epoch: 15, i:  9999] avg mini-batch loss: 0.116\n",
      "[epoch: 15, i: 10999] avg mini-batch loss: 0.122\n",
      "[epoch: 15, i: 11999] avg mini-batch loss: 0.132\n",
      "[epoch: 16, i:   999] avg mini-batch loss: 0.094\n",
      "[epoch: 16, i:  1999] avg mini-batch loss: 0.098\n",
      "[epoch: 16, i:  2999] avg mini-batch loss: 0.092\n",
      "[epoch: 16, i:  3999] avg mini-batch loss: 0.080\n",
      "[epoch: 16, i:  4999] avg mini-batch loss: 0.097\n",
      "[epoch: 16, i:  5999] avg mini-batch loss: 0.111\n",
      "[epoch: 16, i:  6999] avg mini-batch loss: 0.099\n",
      "[epoch: 16, i:  7999] avg mini-batch loss: 0.104\n",
      "[epoch: 16, i:  8999] avg mini-batch loss: 0.103\n",
      "[epoch: 16, i:  9999] avg mini-batch loss: 0.105\n",
      "[epoch: 16, i: 10999] avg mini-batch loss: 0.100\n",
      "[epoch: 16, i: 11999] avg mini-batch loss: 0.114\n",
      "[epoch: 17, i:   999] avg mini-batch loss: 0.054\n",
      "[epoch: 17, i:  1999] avg mini-batch loss: 0.090\n",
      "[epoch: 17, i:  2999] avg mini-batch loss: 0.073\n",
      "[epoch: 17, i:  3999] avg mini-batch loss: 0.125\n",
      "[epoch: 17, i:  4999] avg mini-batch loss: 0.098\n",
      "[epoch: 17, i:  5999] avg mini-batch loss: 0.093\n",
      "[epoch: 17, i:  6999] avg mini-batch loss: 0.096\n",
      "[epoch: 17, i:  7999] avg mini-batch loss: 0.084\n",
      "[epoch: 17, i:  8999] avg mini-batch loss: 0.104\n",
      "[epoch: 17, i:  9999] avg mini-batch loss: 0.106\n",
      "[epoch: 17, i: 10999] avg mini-batch loss: 0.085\n",
      "[epoch: 17, i: 11999] avg mini-batch loss: 0.120\n",
      "[epoch: 18, i:   999] avg mini-batch loss: 0.069\n",
      "[epoch: 18, i:  1999] avg mini-batch loss: 0.078\n",
      "[epoch: 18, i:  2999] avg mini-batch loss: 0.094\n",
      "[epoch: 18, i:  3999] avg mini-batch loss: 0.069\n",
      "[epoch: 18, i:  4999] avg mini-batch loss: 0.101\n",
      "[epoch: 18, i:  5999] avg mini-batch loss: 0.076\n",
      "[epoch: 18, i:  6999] avg mini-batch loss: 0.100\n",
      "[epoch: 18, i:  7999] avg mini-batch loss: 0.090\n",
      "[epoch: 18, i:  8999] avg mini-batch loss: 0.084\n",
      "[epoch: 18, i:  9999] avg mini-batch loss: 0.104\n",
      "[epoch: 18, i: 10999] avg mini-batch loss: 0.090\n",
      "[epoch: 18, i: 11999] avg mini-batch loss: 0.098\n",
      "[epoch: 19, i:   999] avg mini-batch loss: 0.042\n",
      "[epoch: 19, i:  1999] avg mini-batch loss: 0.064\n",
      "[epoch: 19, i:  2999] avg mini-batch loss: 0.044\n",
      "[epoch: 19, i:  3999] avg mini-batch loss: 0.051\n",
      "[epoch: 19, i:  4999] avg mini-batch loss: 0.064\n",
      "[epoch: 19, i:  5999] avg mini-batch loss: 0.073\n",
      "[epoch: 19, i:  6999] avg mini-batch loss: 0.047\n",
      "[epoch: 19, i:  7999] avg mini-batch loss: 0.066\n",
      "[epoch: 19, i:  8999] avg mini-batch loss: 0.081\n",
      "[epoch: 19, i:  9999] avg mini-batch loss: 0.086\n",
      "[epoch: 19, i: 10999] avg mini-batch loss: 0.070\n",
      "[epoch: 19, i: 11999] avg mini-batch loss: 0.079\n",
      "[epoch: 20, i:   999] avg mini-batch loss: 0.045\n",
      "[epoch: 20, i:  1999] avg mini-batch loss: 0.073\n",
      "[epoch: 20, i:  2999] avg mini-batch loss: 0.075\n",
      "[epoch: 20, i:  3999] avg mini-batch loss: 0.068\n",
      "[epoch: 20, i:  4999] avg mini-batch loss: 0.083\n",
      "[epoch: 20, i:  5999] avg mini-batch loss: 0.070\n",
      "[epoch: 20, i:  6999] avg mini-batch loss: 0.079\n",
      "[epoch: 20, i:  7999] avg mini-batch loss: 0.064\n",
      "[epoch: 20, i:  8999] avg mini-batch loss: 0.084\n",
      "[epoch: 20, i:  9999] avg mini-batch loss: 0.078\n",
      "[epoch: 20, i: 10999] avg mini-batch loss: 0.086\n",
      "[epoch: 20, i: 11999] avg mini-batch loss: 0.061\n",
      "[epoch: 21, i:   999] avg mini-batch loss: 0.054\n",
      "[epoch: 21, i:  1999] avg mini-batch loss: 0.045\n",
      "[epoch: 21, i:  2999] avg mini-batch loss: 0.066\n",
      "[epoch: 21, i:  3999] avg mini-batch loss: 0.058\n",
      "[epoch: 21, i:  4999] avg mini-batch loss: 0.062\n",
      "[epoch: 21, i:  5999] avg mini-batch loss: 0.055\n",
      "[epoch: 21, i:  6999] avg mini-batch loss: 0.056\n",
      "[epoch: 21, i:  7999] avg mini-batch loss: 0.058\n",
      "[epoch: 21, i:  8999] avg mini-batch loss: 0.079\n",
      "[epoch: 21, i:  9999] avg mini-batch loss: 0.093\n",
      "[epoch: 21, i: 10999] avg mini-batch loss: 0.060\n",
      "[epoch: 21, i: 11999] avg mini-batch loss: 0.043\n",
      "[epoch: 22, i:   999] avg mini-batch loss: 0.045\n",
      "[epoch: 22, i:  1999] avg mini-batch loss: 0.053\n",
      "[epoch: 22, i:  2999] avg mini-batch loss: 0.056\n",
      "[epoch: 22, i:  3999] avg mini-batch loss: 0.050\n",
      "[epoch: 22, i:  4999] avg mini-batch loss: 0.055\n",
      "[epoch: 22, i:  5999] avg mini-batch loss: 0.049\n",
      "[epoch: 22, i:  6999] avg mini-batch loss: 0.061\n",
      "[epoch: 22, i:  7999] avg mini-batch loss: 0.064\n",
      "[epoch: 22, i:  8999] avg mini-batch loss: 0.061\n",
      "[epoch: 22, i:  9999] avg mini-batch loss: 0.060\n",
      "[epoch: 22, i: 10999] avg mini-batch loss: 0.048\n",
      "[epoch: 22, i: 11999] avg mini-batch loss: 0.039\n",
      "[epoch: 23, i:   999] avg mini-batch loss: 0.062\n",
      "[epoch: 23, i:  1999] avg mini-batch loss: 0.048\n",
      "[epoch: 23, i:  2999] avg mini-batch loss: 0.047\n",
      "[epoch: 23, i:  3999] avg mini-batch loss: 0.033\n",
      "[epoch: 23, i:  4999] avg mini-batch loss: 0.064\n",
      "[epoch: 23, i:  5999] avg mini-batch loss: 0.041\n",
      "[epoch: 23, i:  6999] avg mini-batch loss: 0.068\n",
      "[epoch: 23, i:  7999] avg mini-batch loss: 0.048\n",
      "[epoch: 23, i:  8999] avg mini-batch loss: 0.077\n",
      "[epoch: 23, i:  9999] avg mini-batch loss: 0.052\n",
      "[epoch: 23, i: 10999] avg mini-batch loss: 0.073\n",
      "[epoch: 23, i: 11999] avg mini-batch loss: 0.059\n",
      "[epoch: 24, i:   999] avg mini-batch loss: 0.040\n",
      "[epoch: 24, i:  1999] avg mini-batch loss: 0.032\n",
      "[epoch: 24, i:  2999] avg mini-batch loss: 0.043\n",
      "[epoch: 24, i:  3999] avg mini-batch loss: 0.052\n",
      "[epoch: 24, i:  4999] avg mini-batch loss: 0.059\n",
      "[epoch: 24, i:  5999] avg mini-batch loss: 0.060\n",
      "[epoch: 24, i:  6999] avg mini-batch loss: 0.060\n",
      "[epoch: 24, i:  7999] avg mini-batch loss: 0.062\n",
      "[epoch: 24, i:  8999] avg mini-batch loss: 0.044\n",
      "[epoch: 24, i:  9999] avg mini-batch loss: 0.061\n",
      "[epoch: 24, i: 10999] avg mini-batch loss: 0.055\n",
      "[epoch: 24, i: 11999] avg mini-batch loss: 0.053\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 25       # Total epochs.\n",
    "print_freq = 1000  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e936ee",
   "metadata": {},
   "source": [
    "## Plotting Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef7844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09a649",
   "metadata": {},
   "source": [
    "## Evaluate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f3a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 46 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8696347",
   "metadata": {},
   "source": [
    "## Evaluate Test Set Across Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce1c7aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of apple : 70 %\n",
      "Accuracy of aquarium_fish : 56 %\n",
      "Accuracy of  baby : 30 %\n",
      "Accuracy of  bear : 24 %\n",
      "Accuracy of beaver : 34 %\n",
      "Accuracy of   bed : 50 %\n",
      "Accuracy of   bee : 62 %\n",
      "Accuracy of beetle : 44 %\n",
      "Accuracy of bicycle : 67 %\n",
      "Accuracy of bottle : 63 %\n",
      "Accuracy of  bowl : 26 %\n",
      "Accuracy of   boy : 25 %\n",
      "Accuracy of bridge : 36 %\n",
      "Accuracy of   bus : 35 %\n",
      "Accuracy of butterfly : 54 %\n",
      "Accuracy of camel : 45 %\n",
      "Accuracy of   can : 46 %\n",
      "Accuracy of castle : 67 %\n",
      "Accuracy of caterpillar : 35 %\n",
      "Accuracy of cattle : 39 %\n",
      "Accuracy of chair : 76 %\n",
      "Accuracy of chimpanzee : 61 %\n",
      "Accuracy of clock : 43 %\n",
      "Accuracy of cloud : 56 %\n",
      "Accuracy of cockroach : 72 %\n",
      "Accuracy of couch : 32 %\n",
      "Accuracy of  crab : 46 %\n",
      "Accuracy of crocodile : 27 %\n",
      "Accuracy of   cup : 62 %\n",
      "Accuracy of dinosaur : 51 %\n",
      "Accuracy of dolphin : 37 %\n",
      "Accuracy of elephant : 36 %\n",
      "Accuracy of flatfish : 44 %\n",
      "Accuracy of forest : 25 %\n",
      "Accuracy of   fox : 45 %\n",
      "Accuracy of  girl : 35 %\n",
      "Accuracy of hamster : 57 %\n",
      "Accuracy of house : 38 %\n",
      "Accuracy of kangaroo : 36 %\n",
      "Accuracy of keyboard : 62 %\n",
      "Accuracy of  lamp : 40 %\n",
      "Accuracy of lawn_mower : 65 %\n",
      "Accuracy of leopard : 39 %\n",
      "Accuracy of  lion : 54 %\n",
      "Accuracy of lizard : 16 %\n",
      "Accuracy of lobster : 29 %\n",
      "Accuracy of   man : 20 %\n",
      "Accuracy of maple_tree : 52 %\n",
      "Accuracy of motorcycle : 61 %\n",
      "Accuracy of mountain : 67 %\n",
      "Accuracy of mouse : 25 %\n",
      "Accuracy of mushroom : 46 %\n",
      "Accuracy of oak_tree : 54 %\n",
      "Accuracy of orange : 66 %\n",
      "Accuracy of orchid : 62 %\n",
      "Accuracy of otter : 14 %\n",
      "Accuracy of palm_tree : 66 %\n",
      "Accuracy of  pear : 59 %\n",
      "Accuracy of pickup_truck : 62 %\n",
      "Accuracy of pine_tree : 47 %\n",
      "Accuracy of plain : 60 %\n",
      "Accuracy of plate : 54 %\n",
      "Accuracy of poppy : 57 %\n",
      "Accuracy of porcupine : 46 %\n",
      "Accuracy of possum : 28 %\n",
      "Accuracy of rabbit : 19 %\n",
      "Accuracy of raccoon : 35 %\n",
      "Accuracy of   ray : 36 %\n",
      "Accuracy of  road : 85 %\n",
      "Accuracy of rocket : 59 %\n",
      "Accuracy of  rose : 56 %\n",
      "Accuracy of   sea : 73 %\n",
      "Accuracy of  seal : 10 %\n",
      "Accuracy of shark : 32 %\n",
      "Accuracy of shrew : 33 %\n",
      "Accuracy of skunk : 60 %\n",
      "Accuracy of skyscraper : 74 %\n",
      "Accuracy of snail : 38 %\n",
      "Accuracy of snake : 33 %\n",
      "Accuracy of spider : 50 %\n",
      "Accuracy of squirrel : 28 %\n",
      "Accuracy of streetcar : 47 %\n",
      "Accuracy of sunflower : 73 %\n",
      "Accuracy of sweet_pepper : 33 %\n",
      "Accuracy of table : 27 %\n",
      "Accuracy of  tank : 51 %\n",
      "Accuracy of telephone : 57 %\n",
      "Accuracy of television : 52 %\n",
      "Accuracy of tiger : 44 %\n",
      "Accuracy of tractor : 51 %\n",
      "Accuracy of train : 52 %\n",
      "Accuracy of trout : 57 %\n",
      "Accuracy of tulip : 36 %\n",
      "Accuracy of turtle : 29 %\n",
      "Accuracy of wardrobe : 79 %\n",
      "Accuracy of whale : 47 %\n",
      "Accuracy of willow_tree : 46 %\n",
      "Accuracy of  wolf : 55 %\n",
      "Accuracy of woman : 17 %\n",
      "Accuracy of  worm : 57 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(100))\n",
    "class_total = list(0. for i in range(100))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(100):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
