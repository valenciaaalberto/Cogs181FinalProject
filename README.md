# Cogs181FinalProject
This repository contains the code to our multiple attempts of creating a sophisticated model that yields the best test accuracy on the Cifar-100 datset. Our experiment included multiple variations of different convolutional neural networks with changes to the number of convolutional layers, activation functions, optimizers and pooling functions. After creating a baseline model that achieved an accuracy of 47% on our test set, we explored state of the art models, such Alexnet and Resnet-18, to improve our baseline modelâ€™s prediction. Given the poor result on the Cifar 100 dataset, we used these models in conjunction with the self attention mechanism, attaching it to different convolutional neural network models. Using Chat-Gpt 4, we developed different attention mechanisms to compare results. These models still failed to give the results we hoped for so we created an ensemble model.